<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://norlab.ulaval.ca/atom.xml" rel="self" type="application/atom+xml" /><link href="https://norlab.ulaval.ca/" rel="alternate" type="text/html" /><updated>2019-09-09T15:18:59+02:00</updated><id>https://norlab.ulaval.ca/atom.xml</id><title type="html">Northern Robotics Laboratory</title><subtitle>Website showcasing research and news from the Northern Robotics Laboratory, Laval University</subtitle><entry><title type="html">Lambda-Field: A Continuous Counterpart of the Bayesian Occupancy Grid for Risk Assessment</title><link href="https://norlab.ulaval.ca/publications/lambda-field/" rel="alternate" type="text/html" title="Lambda-Field: A Continuous Counterpart of the Bayesian Occupancy Grid for Risk Assessment" /><published>2019-09-02T00:00:00+02:00</published><updated>2019-09-02T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/publications/lambda-field</id><content type="html" xml:base="https://norlab.ulaval.ca/publications/lambda-field/">&lt;p&gt;In a context of autonomous robots, one of the most important tasks is to ensure the safety of the robot and its surrounding.
The risk of navigation is usually said to be the probability of collision.
This notion of risk is not well defined in the literature, especially when dealing with occupancy grids.
The Bayesian occupancy grid is the most used method to deal with complex environments.
However, this is not fitted to compute the risk along a path by its discrete nature.
In this article, we present a new way to store the occupancy of the environment that allows the computation of risk along a given path.
We then define the risk as the force of collision that would occur for a given obstacle.
Using this framework, we are able to generate navigation paths ensuring the safety of the robot.&lt;/p&gt;

&lt;h1 id=&quot;contributions&quot;&gt;Contributions&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;A novel type of map, called Lambda-Field, specially conceived to allow path integrals and thus probabilities of collision;&lt;/li&gt;
  &lt;li&gt;A definition of the risk encountered over a path, specified as the expected force of collision along a path.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;results-in-images&quot;&gt;Results in Images&lt;/h1&gt;

&lt;p&gt;Using the lambda-field, we are able to construct maps where the probability of collision along a path logically arises from the theory.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/publications/lambda-field/maps.png&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The robot (trajectory in blue) maps an urban-like environment and creates a Bayesian Grid as well as a Lambda-Field.
Although the maps are almost the same, the Lambda-Field tends to better store the unstructured obstacles (bushes in this example).&lt;/p&gt;

&lt;h1 id=&quot;in-video&quot;&gt;In Video&lt;/h1&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/ybj8NWWbzAo&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;

&lt;p&gt;&lt;span id=&quot;Laconte2019a&quot;&gt;Laconte, J., Debain, C., Chapuis, R., Pomerleau, F., &amp;amp; Aufrere, R. (2019). Lambda-Field: A Continuous Counterpart of the Bayesian Occupancy Grid for Risk Assessment. In &lt;i&gt;Proceedings of the IEEE International Conference on Intelligent Robots and Systems (IROS)&lt;/i&gt;.&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;links&quot;&gt;Links&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.researchgate.net/publication/331565267_Lambda-Field_A_Continuous_Counterpart_of_the_Bayesian_Occupancy_Grid_for_Risk_Assessment&quot;&gt;Download link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Johann Laconte</name></author><category term="publications" /><category term="traversability" /><category term="lidar" /><category term="mapping" /><summary type="html">In a context of autonomous robots, one of the most important tasks is to ensure the safety of the robot and its surrounding. The risk of navigation is usually said to be the probability of collision. This notion of risk is not well defined in the literature, especially when dealing with occupancy grids. The Bayesian occupancy grid is the most used method to deal with complex environments. However, this is not fitted to compute the risk along a path by its discrete nature. In this article, we present a new way to store the occupancy of the environment that allows the computation of risk along a given path. We then define the risk as the force of collision that would occur for a given obstacle. Using this framework, we are able to generate navigation paths ensuring the safety of the robot.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22publications/lambda-field_teaser.png%22,%20%22feature%22=%3E%22publications/lambda-field_feature.png%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">Norlab is going to Asia!</title><link href="https://norlab.ulaval.ca/news/iros-fsr19/" rel="alternate" type="text/html" title="Norlab is going to Asia!" /><published>2019-06-24T00:00:00+02:00</published><updated>2019-06-24T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/news/iros-fsr19</id><content type="html" xml:base="https://norlab.ulaval.ca/news/iros-fsr19/">&lt;p&gt;We are going to Tokyo (Japan) and Macau (China) with four accepted publications at the &lt;a href=&quot;http://www.srg.mech.keio.ac.jp/fsr2019/&quot;&gt;2019 International Conference on Field and Service Robotics&lt;/a&gt; and one at the &lt;a href=&quot;https://www.iros2019.org/&quot;&gt;2019 IEEE/RSJ International Conference on Intelligent Robots and Systems&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We will present our latest results on lambda-field maps for continuous and risk-aware path planning &lt;a href=&quot;#Laconte2019a&quot;&gt;(Laconte, Debain, Chapuis, Pomerleau, &amp;amp; Aufrere, 2019)&lt;/a&gt;, 3D mapping in subarctic environments &lt;a href=&quot;#Babin2019a&quot;&gt;(Babin, Dandurand, Kubelka, Giguère, &amp;amp; Pomerleau, 2019)&lt;/a&gt;, estimation of GPS satellite visibility given 3D maps &lt;a href=&quot;#Dandurand2019&quot;&gt;(Dandurand, Babin, Kubelka, Giguère, &amp;amp; Pomerleau, 2019)&lt;/a&gt;, automatic forestry inventory based on 3D maps&lt;a href=&quot;#Tremblay2019&quot;&gt;(Tremblay, Béland, Pomerleau, Gagnon, &amp;amp; Giguère, 2019)&lt;/a&gt;, and multi-session lake-shore monitoring based on lidar &lt;a href=&quot;#Pradalier2019&quot;&gt;(Pradalier, Aravecchia, &amp;amp; Pomerleau, 2019)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;More details, and hopefully videos to come!&lt;/p&gt;

&lt;h1 id=&quot;our-articles&quot;&gt;Our articles&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Laconte2019a&quot;&gt;Laconte, J., Debain, C., Chapuis, R., Pomerleau, F., &amp;amp; Aufrere, R. (2019). Lambda-Field: A Continuous Counterpart of the Bayesian Occupancy Grid for Risk Assessment. In &lt;i&gt;Proceedings of the IEEE International Conference on Intelligent Robots and Systems (IROS)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Laconte2019a/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Dandurand2019&quot;&gt;Dandurand, P., Babin, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Predicting GNSS satellite visibility from dense point clouds. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Dandurand2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Babin2019a&quot;&gt;Babin, P., Dandurand, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Large-scale 3D Mapping of Sub-arctic Forests. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2019a/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Tremblay2019&quot;&gt;Tremblay, J.-F., Béland, M., Pomerleau, F., Gagnon, R., &amp;amp; Giguère, P. (2019). Automatic 3D Mapping for Tree Diameter Measurements in Inventory Operations. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Tremblay2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Pradalier2019&quot;&gt;Pradalier, C., Aravecchia, S., &amp;amp; Pomerleau, F. (2019). Multi-session lake-shore monitoring in visually challenging conditions. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Pradalier2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="conference" /><summary type="html">We are going to Tokyo (Japan) and Macau (China) with four accepted publications at the 2019 International Conference on Field and Service Robotics and one at the 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22/news/iros_fsr19/iros_fsr19_teaser.jpg%22%7D" /></entry><entry><title type="html">Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping</title><link href="https://norlab.ulaval.ca/publications/lidar-bias/" rel="alternate" type="text/html" title="Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping" /><published>2019-05-27T00:00:00+02:00</published><updated>2019-05-27T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/publications/lidar-bias</id><content type="html" xml:base="https://norlab.ulaval.ca/publications/lidar-bias/">&lt;p&gt;In a context of 3D mapping, it is very important to obtain accurate measurements from sensors.
In particular, LIDAR measurements are typically treated as a zero-mean Gaussian distribution.
We show that this assumption leads to predictable localisation drifts, especially when a bias related to measuring obstacles with high incidence angles is not taken into consideration.
Moreover, we present a way to physically understand and model this bias, which generalizes to multiple sensors.
Using an experimental setup, we measured the bias of the Sick LMS-151, Velodyne HDL-32E, and Robosense RS-LiDAR-16 as a function of depth and incidence angle, and showed that the bias can reach 20 cm for high incidence angles.
We then used our model to remove the bias from the measurements, leading to more accurate maps and a reduced localisation drift.&lt;/p&gt;
&lt;h1 id=&quot;contributions&quot;&gt;Contributions&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Physical explanation of a lidar bias caused by the incidence angle of the laser beam on a surface&lt;/li&gt;
  &lt;li&gt;A way to quantify and correct this bias for common LIDARs used in mobile robotics&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;results-in-images&quot;&gt;Results in Images&lt;/h1&gt;

&lt;p&gt;Using our model, we found the following bias for three commonly used LIDARs:
&lt;img src=&quot;/images/publications/lidar-bias/isocurves.jpg&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We were able to remove the bias from the measurements, leading to more accurate maps.
In blue, the map of a tunnel without taking into account the bias.
In red, the same map taking into account the bias and removing it from the measurements.
&lt;img src=&quot;/images/publications/lidar-bias/tunnels.jpg&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;in-video&quot;&gt;In Video&lt;/h1&gt;

&lt;!--&lt;iframe src=&quot;https://www.youtube.com/watch?v=YE-oL7do2HM&quot; style=&quot;width: 100%&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;--&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/YE-oL7do2HM&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;

&lt;p&gt;&lt;span id=&quot;Laconte2019&quot;&gt;Laconte, J., Deschênes, S.-P., Labussière, M., &amp;amp; Pomerleau, F. (2019). Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;links&quot;&gt;Links&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.researchgate.net/publication/328063232_Lidar_Measurement_Bias_Estimation_via_Return_Waveform_Modelling_in_a_Context_of_3D_Mapping&quot;&gt;Download link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Johann Laconte</name></author><category term="publications" /><category term="ICP" /><category term="bias estimation" /><category term="sensor error modelling" /><category term="lidar" /><category term="mapping" /><summary type="html">In a context of 3D mapping, it is very important to obtain accurate measurements from sensors. In particular, LIDAR measurements are typically treated as a zero-mean Gaussian distribution. We show that this assumption leads to predictable localisation drifts, especially when a bias related to measuring obstacles with high incidence angles is not taken into consideration. Moreover, we present a way to physically understand and model this bias, which generalizes to multiple sensors. Using an experimental setup, we measured the bias of the Sick LMS-151, Velodyne HDL-32E, and Robosense RS-LiDAR-16 as a function of depth and incidence angle, and showed that the bias can reach 20 cm for high incidence angles. We then used our model to remove the bias from the measurements, leading to more accurate maps and a reduced localisation drift. Contributions</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22publications/lidar-bias_feature.jpg%22,%20%22teaser%22=%3E%22publications/lidar-bias_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">Satellite Visibility Prediction</title><link href="https://norlab.ulaval.ca/research/satellite-visibility/" rel="alternate" type="text/html" title="Satellite Visibility Prediction" /><published>2019-05-09T00:00:00+02:00</published><updated>2019-05-09T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/research/satellite-visibility</id><content type="html" xml:base="https://norlab.ulaval.ca/research/satellite-visibility/">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;To help future mobile agents plan their movement in harsh environments,a predictive model has been designed to determine what areas would be favorable for Global Navigation Satellite System (GNSS) positioning. The model is able to predict the number of viable satellites for a GNSS receiver, based on a 3D point cloud map and a satellite constellation. Both occlusion and absorption effects of the environment are considered. A rugged mobile platform was designed to collect data in order to generate the point cloud maps. It was deployed during the Canadian winter known for large amounts of snow and extremely low temperatures. The test environments include a highly dense boreal forest and a university campus with high buildings. The experiment results indicate that the model performs well in both structured and unstructured environments.&lt;/p&gt;

&lt;h1 id=&quot;quick-facts&quot;&gt;Quick facts:&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;This method has been tested in diverse environments such has a highly dense boreal forest and a university campus with high buildings&lt;/li&gt;
  &lt;li&gt;This method is able to differentiate between forest and buildings&lt;/li&gt;
  &lt;li&gt;The hardware used in the paper has been proven to work in sub-arctic environment&lt;/li&gt;
  &lt;li&gt;Our preprint is available &lt;a href=&quot;https://arxiv.org/abs/1904.07837&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;video&quot;&gt;Video&lt;/h1&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/5LdxV1-9rEE&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Dandurand2019&quot;&gt;Dandurand, P., Babin, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Predicting GNSS satellite visibility from dense point clouds. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Dandurand2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Philippe Dandurand</name></author><category term="project" /><category term="GNSS" /><category term="GPS" /><category term="lidar" /><category term="RTK" /><category term="DGNSS" /><category term="winter" /><category term="mapping" /><category term="uncertainty" /><summary type="html">Abstract To help future mobile agents plan their movement in harsh environments,a predictive model has been designed to determine what areas would be favorable for Global Navigation Satellite System (GNSS) positioning. The model is able to predict the number of viable satellites for a GNSS receiver, based on a 3D point cloud map and a satellite constellation. Both occlusion and absorption effects of the environment are considered. A rugged mobile platform was designed to collect data in order to generate the point cloud maps. It was deployed during the Canadian winter known for large amounts of snow and extremely low temperatures. The test environments include a highly dense boreal forest and a university campus with high buildings. The experiment results indicate that the model performs well in both structured and unstructured environments.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22projects/sat_vis_feature.jpg%22,%20%22teaser%22=%3E%22projects/sat_vis_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">First appearance of the lab in IEEE Spectrum</title><link href="https://norlab.ulaval.ca/news/ieee-spectrum/" rel="alternate" type="text/html" title="First appearance of the lab in IEEE Spectrum" /><published>2019-05-07T00:00:00+02:00</published><updated>2019-05-07T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/news/ieee-spectrum</id><content type="html" xml:base="https://norlab.ulaval.ca/news/ieee-spectrum/">&lt;p&gt;Norlab appears in the online version of the magazine IEEE Spectrum with the title &lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/darpa-subt-meet-the-first-nine-teams&quot;&gt;DARPA Subterranean Challenge: Meet the First 9 Teams&lt;/a&gt;.
They confuse our French and English name, but at least the URL is correct.&lt;/p&gt;

&lt;p&gt;Our lab is supporting the mapping capability of the Team CRAS (Center for Robotics and Autonomous Systems) leaded by the Czech Technical University in Prague, Czech Republic.&lt;/p&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="media" /><summary type="html">Norlab appears in the online version of the magazine IEEE Spectrum with the title DARPA Subterranean Challenge: Meet the First 9 Teams. They confuse our French and English name, but at least the URL is correct.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22/logos/ieeeSpectrum.jpg%22%7D" /></entry><entry><title type="html">Information for New Students</title><link href="https://norlab.ulaval.ca/research/new-students/" rel="alternate" type="text/html" title="Information for New Students" /><published>2019-05-07T00:00:00+02:00</published><updated>2019-05-07T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/research/new-students</id><content type="html" xml:base="https://norlab.ulaval.ca/research/new-students/">&lt;p&gt;Welcome to the laboratory!
It will take a couple of weeks to get you up and running in the lab, so why not use that time to explore different sources of information that will save you time later.&lt;/p&gt;

&lt;h1 id=&quot;register-to-news-feeds&quot;&gt;Register to news feeds&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Register to the magazine &lt;a href=&quot;https://www.universityaffairs.ca&quot;&gt;University Affairs&lt;/a&gt; (free) for general information about the academic life.&lt;/li&gt;
  &lt;li&gt;Register to &lt;a href=&quot;https://www.eu-robotics.net/eurobotics/newsroom/mailing-list&quot;&gt;euRobotics mailing list&lt;/a&gt;  for jobs, software release, call for journal special issues, etc.&lt;/li&gt;
  &lt;li&gt;Register to &lt;a href=&quot;http://duerer.usc.edu/mailman/listinfo.cgi/robotics-worldwide&quot;&gt;robotics-worldwide mailing list&lt;/a&gt;. Same information as euRobotics with a larger audience.&lt;/li&gt;
  &lt;li&gt;Don’t take your work &lt;a href=&quot;http://phdcomics.com/&quot;&gt;too seriously&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;explore-our-github-repo&quot;&gt;Explore our GitHub repo&lt;/h1&gt;

&lt;p&gt;You will need an account on GitHub, so you can be added to the members of&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;
&lt;a href=&quot;https://github.com/norlab-ulaval&quot; target=&quot;_blank&quot; class=&quot;btn&quot;&gt;
&lt;img src=&quot;/images/logos/github.svg&quot; style=&quot;padding-right: 1em; width: 4em; -webkit-filter: invert(100%); filter: invert(100%);&quot; /&gt;
norlab-ulaval
&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;Then, explore the following:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval?utf8=%E2%9C%93&amp;amp;q=poster&amp;amp;type=&amp;amp;language=&quot;&gt;Scientific posters&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval?utf8=%E2%9C%93&amp;amp;q=publication&amp;amp;type=&amp;amp;language=&quot;&gt;Scientific publications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval?utf8=%E2%9C%93&amp;amp;q=mastersProposal&amp;amp;type=&amp;amp;language=&quot;&gt;Master’s proposal&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval?utf8=%E2%9C%93&amp;amp;q=mastersThesis&amp;amp;type=&amp;amp;language=&quot;&gt;Master’s thesis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval/visualIdentity&quot;&gt;Different logos of the lab&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Read our &lt;a href=&quot;https://github.com/norlab-ulaval/latexGoodPractices/blob/master/preamble.tex&quot;&gt;Latex good practices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;little-tip-to-save-you-some-time&quot;&gt;Little tip to save you some time&lt;/h1&gt;
&lt;p&gt;Create a new bookmark on you favorite web browser and copy-paste this script as the url:&lt;/p&gt;
&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;javascript&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;href&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'https://acces.bibl.ulaval.ca/login?qurl='&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+%&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;encodeURIComponent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;href&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);})());&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If you click the bookmark when you are on a scientific article publisher website (e.g. Springer), it will log you into Ariane automatically. Ariane grants you access to the article without having to pay if the university has an agreement with the publisher.&lt;/p&gt;

&lt;h1 id=&quot;be-social&quot;&gt;Be social&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Like our Facebook page &lt;a href=&quot;https://www.facebook.com/norlab.ulaval/&quot;&gt;norlab.ulaval&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Follow the LinkedIn page &lt;a href=&quot;https://www.linkedin.com/company/norlab/&quot;&gt;Norlab&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Subscribe to our YouTube channel &lt;a href=&quot;https://www.youtube.com/channel/UCh9G8xpr72lBiyWyBKXBTXA&quot;&gt;norlab&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Ask to be added on our ResearchGate &lt;a href=&quot;https://www.researchgate.net/lab/Northern-Robotics-Laboratory-Norlab-Francois-Pomerleau&quot;&gt;laboratory page&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;In general, reshare news from the lab to ensure maximum impact of our work&lt;/li&gt;
&lt;/ul&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="howto" /><category term="grants" /><category term="salary" /><category term="students" /><summary type="html">Welcome to the laboratory! It will take a couple of weeks to get you up and running in the lab, so why not use that time to explore different sources of information that will save you time later.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3Enil,%20%22feature%22=%3Enil%7D" /></entry><entry><title type="html">Dominic Baril</title><link href="https://norlab.ulaval.ca/people/d_baril/" rel="alternate" type="text/html" title="Dominic Baril" /><published>2019-05-05T00:00:00+02:00</published><updated>2019-05-05T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/people/d_baril</id><content type="html" xml:base="https://norlab.ulaval.ca/people/d_baril/">&lt;p&gt;Dominic Baril is a master’s student at Norlab.
He graduated in mechanical engineering at Sherbrooke University in 2018. To complete his bachelor’s, he worked on a major robotic project in collaboration with &lt;a href=&quot;https://www.exonetik.com/&quot; target=&quot;_blank&quot;&gt;Exonetik&lt;/a&gt;, a company that produces magnetorheological actuators. The project (named &lt;a href=&quot;https://www.facebook.com/expomegageniale/videos/2039870909411790/&quot; target=&quot;_blank&quot;&gt;ASIMOV&lt;/a&gt;) consisted in designing, manufacturing and controlling 2 identic and mechanically independent robotic arms. The arms are able to simultaneously reprodouce a haptic feeling in the other when touching objects. He also realised an internship in the &lt;a href=&quot;https://https://www.createk.co/&quot; target=&quot;_blank&quot;&gt;Createk&lt;/a&gt; laboratory under the supervision of Pr. &lt;a href=&quot;https://alexandregirard.ca/&quot; target=&quot;_blank&quot;&gt;Alexandre Girard&lt;/a&gt;. He was tasked with integrating a 1:10 scaled robotic car (based on the MIT’s &lt;a href=&quot;http://fast.scripts.mit.edu/racecar/&quot; target=&quot;_blank&quot;&gt;RACECAR&lt;/a&gt;). The car was outfitted with the standard autonomous car sensors and Dominic created a control architecture (using ROS) for the robot. 
His work in Norlab will be related to the control of an autonomous robot in a harsh winter environment.&lt;/p&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Bachelor’s degree in mechanical Engineering at Sherbrooke University, 2018&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Dominic Baril</name><email>dominic.baril.1@ulaval.ca</email></author><summary type="html">Dominic Baril is a master’s student at Norlab. He graduated in mechanical engineering at Sherbrooke University in 2018. To complete his bachelor’s, he worked on a major robotic project in collaboration with Exonetik, a company that produces magnetorheological actuators. The project (named ASIMOV) consisted in designing, manufacturing and controlling 2 identic and mechanically independent robotic arms. The arms are able to simultaneously reprodouce a haptic feeling in the other when touching objects. He also realised an internship in the Createk laboratory under the supervision of Pr. Alexandre Girard. He was tasked with integrating a 1:10 scaled robotic car (based on the MIT’s RACECAR). The car was outfitted with the standard autonomous car sensors and Dominic created a control architecture (using ROS) for the robot. His work in Norlab will be related to the control of an autonomous robot in a harsh winter environment.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/d_baril.jpg%22,%20%22teaser%22=%3E%22/people/d_baril_avatar.jpg%22%7D" /></entry><entry><title type="html">Dominic Baril</title><link href="https://norlab.ulaval.ca/people/d_baril_fr/" rel="alternate" type="text/html" title="Dominic Baril" /><published>2019-05-05T00:00:00+02:00</published><updated>2019-05-05T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/people/d_baril_fr</id><content type="html" xml:base="https://norlab.ulaval.ca/people/d_baril_fr/">&lt;p&gt;Dominic Baril est un étudiant à la maîtrise au sein du Norlab.
Il a gardué du baccalauréat en génie mécanique à l’Université de Sherbrooke en 2018. Afin de compléter son baccalauréat, il a participé à un projet majeur en robotique en collaboration avec &lt;a href=&quot;https://www.exonetik.com/&quot; target=&quot;_blank&quot;&gt;Exonetik&lt;/a&gt;, une entreprise qui produit des actionneurs à fluides magnétorhéologiques. Le projet (dénommé &lt;a href=&quot;https://www.facebook.com/expomegageniale/videos/2039870909411790/&quot; target=&quot;_blank&quot;&gt;ASIMOV&lt;/a&gt;) consistait en la conception, la fabrication et le contrôle de 2 bras robotiques identiques et mécaniquement indépendants. Les bras sont capables de simultanément reproduire un sentiment haptique dans l’autre lorsqu’ils touchent à des objets. Il a également réalisé un stage au sein du laboratoire &lt;a href=&quot;https://https://www.createk.co/&quot; target=&quot;_blank&quot;&gt;Createk&lt;/a&gt; sous la supervision du Pr. &lt;a href=&quot;https://alexandregirard.ca/&quot; target=&quot;_blank&quot;&gt;Alexandre Girard&lt;/a&gt;. Il avait la tâche d’intégrer une voiture robotique à échelle 1:10 (basée sur le &lt;a href=&quot;http://fast.scripts.mit.edu/racecar/&quot; target=&quot;_blank&quot;&gt;RACECAR&lt;/a&gt; du MIT). La voiture a été équipée avec les capteurs standards des voitures autonomes et Dominic a réalisé un architecture de contrôle (fonctionnant avec ROS) pour le robot.
Son travail au Norlab sera en lien avec le contrôle d’un robot autonome en environnement hivernal difficile.&lt;/p&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Baccalauréat en génie mécanique à l’Université de Sherbrooke, 2018&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Dominic Baril</name><email>dominic.baril.1@ulaval.ca</email></author><summary type="html">Dominic Baril est un étudiant à la maîtrise au sein du Norlab. Il a gardué du baccalauréat en génie mécanique à l’Université de Sherbrooke en 2018. Afin de compléter son baccalauréat, il a participé à un projet majeur en robotique en collaboration avec Exonetik, une entreprise qui produit des actionneurs à fluides magnétorhéologiques. Le projet (dénommé ASIMOV) consistait en la conception, la fabrication et le contrôle de 2 bras robotiques identiques et mécaniquement indépendants. Les bras sont capables de simultanément reproduire un sentiment haptique dans l’autre lorsqu’ils touchent à des objets. Il a également réalisé un stage au sein du laboratoire Createk sous la supervision du Pr. Alexandre Girard. Il avait la tâche d’intégrer une voiture robotique à échelle 1:10 (basée sur le RACECAR du MIT). La voiture a été équipée avec les capteurs standards des voitures autonomes et Dominic a réalisé un architecture de contrôle (fonctionnant avec ROS) pour le robot. Son travail au Norlab sera en lien avec le contrôle d’un robot autonome en environnement hivernal difficile.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/d_baril.jpg%22,%20%22teaser%22=%3E%22/people/d_baril_avatar.jpg%22%7D" /></entry><entry><title type="html">How to set a static transform with our interactive RVIZ tool</title><link href="https://norlab.ulaval.ca/research/how-to-visually-setup-static-tf/" rel="alternate" type="text/html" title="How to set a static transform with our interactive RVIZ tool" /><published>2019-04-30T00:00:00+02:00</published><updated>2019-04-30T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/research/how-to-visually-setup-static-tf</id><content type="html" xml:base="https://norlab.ulaval.ca/research/how-to-visually-setup-static-tf/">&lt;p&gt;Sometimes, there is a need to quickly set up a static transform in ROS.
To avoid manually searching for translation and rotation parameters, we have written this minimalistic tool that allows us to do it a more convenient, click-and-drag way.&lt;/p&gt;

&lt;h1 id=&quot;the-problem&quot;&gt;The Problem&lt;/h1&gt;

&lt;p&gt;The physical configuration of a robot can change or a new sensor is added.
Since this configuration is reflected by the ROS TF system, the corresponding static transform needs to be updated.
The classical approach would be trial-and-error with the comand line &lt;code class=&quot;highlighter-rouge&quot;&gt;rosrun tf static_transform_publisher [params]&lt;/code&gt;, looking for the right numbers.
It is tedious, unnecessary and there is a better way to do this.&lt;/p&gt;

&lt;h1 id=&quot;solution---interactive-static-transform-tool&quot;&gt;Solution - Interactive Static Transform tool&lt;/h1&gt;

&lt;p&gt;Following the &lt;a href=&quot;http://wiki.ros.org/rviz/Tutorials/Interactive%20Markers%3A%20Getting%20Started&quot;&gt;RVIZ Interactive Marker Tutorial&lt;/a&gt;, a simple tool was written.
It helps in finding a transformation between two TF frames by providing
an RVIZ interactive marker. 
Its usage is straightforward:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Set your parent and child frame names in the &lt;a href=&quot;https://github.com/norlab-ulaval/norlab_imu_tools/blob/master/launch/interactive_static_transform_publisher.launch&quot;&gt;launch file&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Run the launch file and also open the RVIZ.&lt;/li&gt;
  &lt;li&gt;The initial transformation is an identity, but you can modify it by displaying
the interactive marker and moving it around.&lt;/li&gt;
  &lt;li&gt;The marker also offers a context menu, the only command which is there
prints the current transform value in the form of the &lt;code class=&quot;highlighter-rouge&quot;&gt;static_transform_publisher&lt;/code&gt;
rosrun command.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The launch file and the code is placed within the &lt;a href=&quot;https://github.com/norlab-ulaval/norlab_imu_tools&quot;&gt;norlab_imu_tools&lt;/a&gt; package:&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;launch&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;node&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;pkg=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;norlab_imu_tools&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;interactive_static_transform_publisher.py&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;interactive_static_transform_publisher_node&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;output=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;screen&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;child_frame&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;moving_frame&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;parent_frame&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;base_link&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tf_publish_period_in_sec&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.1&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/node&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/launch&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The final transform output can be copied and pasted into a terminal or just used to set a new launch file:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[INFO] [1556661102.899894]: The equivalent static transform command:
[INFO] [1556661102.902316]: rosrun tf static_transform_publisher 1.92549085617 0.0 1.12673556805 0.327530413866 -0.155546739697 -0.399795621634 0.841839015484 base_link moving_frame 100
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Vladimír Kubelka</name><email>vladimir.kubelka.1@ulaval.ca</email></author><category term="howto" /><category term="ros" /><category term="transform" /><category term="rviz" /><summary type="html">Sometimes, there is a need to quickly set up a static transform in ROS. To avoid manually searching for translation and rotation parameters, we have written this minimalistic tool that allows us to do it a more convenient, click-and-drag way.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22/rviz_interactive_tf_tool_teaser.jpg%22,%20%22feature%22=%3E%22/rviz_interactive_tf_tool.jpg%22%7D" /></entry><entry><title type="html">Forest Mapping</title><link href="https://norlab.ulaval.ca/research/forest-mapping/" rel="alternate" type="text/html" title="Forest Mapping" /><published>2019-04-17T00:00:00+02:00</published><updated>2019-04-17T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/research/forest-mapping</id><content type="html" xml:base="https://norlab.ulaval.ca/research/forest-mapping/">&lt;h1 id=&quot;quick-facts&quot;&gt;Quick facts:&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;1.4 hectares of forest mapped with a &lt;a href=&quot;https://www.clearpathrobotics.com/husky-unmanned-ground-vehicle-robot/&quot;&gt;Clearpath Husky&lt;/a&gt; and a &lt;a href=&quot;https://velodynelidar.com/hdl-32e.html&quot;&gt;Velodyne HDL-32E&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;943 trees were manually segmented in point clouds, and their diameter and species was identified on the field.&lt;/li&gt;
  &lt;li&gt;Biggest dataset for 3D forest mapping and tree diameter measurements&lt;/li&gt;
  &lt;li&gt;We tested various diameter estimation methods&lt;/li&gt;
  &lt;li&gt;Part of the &lt;a href=&quot;https://www.researchgate.net/project/Automated-forestry-and-logging-operations&quot;&gt;Automated Forestry and Logging Operations project&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Our preprint is available &lt;a href=&quot;https://arxiv.org/abs/1904.05281&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;video&quot;&gt;Video&lt;/h1&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/dJ8eIOvcGPw&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Tremblay2019&quot;&gt;Tremblay, J.-F., Béland, M., Pomerleau, F., Gagnon, R., &amp;amp; Giguère, P. (2019). Automatic 3D Mapping for Tree Diameter Measurements in Inventory Operations. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Tremblay2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Jean-François Tremblay</name></author><category term="project" /><category term="mapping" /><category term="forestry" /><category term="lidar" /><summary type="html">Quick facts: 1.4 hectares of forest mapped with a Clearpath Husky and a Velodyne HDL-32E 943 trees were manually segmented in point clouds, and their diameter and species was identified on the field. Biggest dataset for 3D forest mapping and tree diameter measurements We tested various diameter estimation methods Part of the Automated Forestry and Logging Operations project Our preprint is available here</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22projects/forest_mapping_feature.jpg%22,%20%22teaser%22=%3E%22projects/forest_mapping_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry></feed>