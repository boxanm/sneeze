<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://norlab.ulaval.ca/atom.xml" rel="self" type="application/atom+xml" /><link href="https://norlab.ulaval.ca/" rel="alternate" type="text/html" /><updated>2020-05-21T10:33:07-04:00</updated><id>https://norlab.ulaval.ca/atom.xml</id><title type="html">Northern Robotics Laboratory</title><subtitle>Website showcasing research and news from the Northern Robotics Laboratory, Laval University</subtitle><entry><title type="html">How to synchronize an Overleaf Project with a GitHub repository</title><link href="https://norlab.ulaval.ca/research/latex-github-overleaf/" rel="alternate" type="text/html" title="How to synchronize an Overleaf Project with a GitHub repository" /><published>2020-05-20T00:00:00-04:00</published><updated>2020-05-20T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/research/latex-github-overleaf</id><content type="html" xml:base="https://norlab.ulaval.ca/research/latex-github-overleaf/">&lt;p&gt;Writing papers with a large number of co-authors can be complicated endeavour. This why &lt;a href=&quot;https://www.overleaf.com/&quot;&gt;Overleaf&lt;/a&gt; is an interesting choice, as it allows for multiple people to edit a same LaTeX document simultaneously. However, online compiling on Overleaf requires time and you will also want to have access to your files on your laptop and use your favorite LaTeX editor. This is why synchronizing your paper in an Overleaf project as well as in a GitHub repository &lt;a href=&quot;https://github.com/&quot;&gt;GitHub&lt;/a&gt;. This will also grant you access to the laboratory’s &lt;a href=&quot;https://github.com/norlab-ulaval/latexGoodPractices&quot;&gt;LaTeX good practices repository&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;main-reasons-why-you-will-want-to-synchronize-your-paper-on-github-and-overleaf&quot;&gt;Main reasons why you will want to synchronize your paper on Github and Overleaf&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Allows for multiple contributors to work on a project simultaneously&lt;/li&gt;
  &lt;li&gt;Allows to backup and archive your paper in the common laboratory repository&lt;/li&gt;
  &lt;li&gt;Allows to easily export your paper in &lt;a href=&quot;https://arxiv.org/&quot;&gt;arXiv&lt;/a&gt; friendly format&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;procedure&quot;&gt;Procedure&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;In your Overleaf dashboard, create a new blank project using &lt;img src=&quot;/images/github_overleaf_sync/overleaf_new_project.png&quot; style=&quot;width: 20%&quot; /&gt; and give it a relevant name (e.g., publication_conference/journal_name_firstnameLastname)&lt;/li&gt;
  &lt;li&gt;In the project page on Overleaf, select &lt;img src=&quot;/images/github_overleaf_sync/overleaf_menu.png&quot; style=&quot;width: 12%&quot; /&gt; and &lt;img src=&quot;/images/github_overleaf_sync/overleaf_github.png&quot; style=&quot;width: 30%&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Select “Create a Github repository”&lt;/li&gt;
  &lt;li&gt;Select “norlab-ulaval” as Owner and select the “Private” option so you can choose who can commit to the repository&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The repository should now be visible on the laboratory’s GitHub page :&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;
&lt;a href=&quot;https://github.com/norlab-ulaval&quot; target=&quot;_blank&quot; class=&quot;btn&quot;&gt;
&lt;img src=&quot;/images/logos/github.svg&quot; style=&quot;padding-right: 1em; width: 4em; -webkit-filter: invert(100%); filter: invert(100%);&quot; /&gt;
norlab-ulaval
&lt;/a&gt;
&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Clone the repository on you computer&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone &amp;lt;github_repo_url&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Add the &lt;a href=&quot;https://github.com/norlab-ulaval/latexGoodPractices&quot;&gt;LaTeX good practices repository&lt;/a&gt; as a &lt;a href=&quot;https://git-scm.com/book/en/v2/Git-Tools-Submodules&quot;&gt;Git submodule&lt;/a&gt;, as shown below :&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git submodule add https://github.com/norlab-ulaval/latexGoodPractices.git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Push the changes from your local repository to the remote GitHub repository&lt;/li&gt;
  &lt;li&gt;Pull the changes from the Overleaf project page by selecting &lt;img src=&quot;/images/github_overleaf_sync/overleaf_menu.png&quot; style=&quot;width: 12%&quot; /&gt; , &lt;img src=&quot;/images/github_overleaf_sync/overleaf_github.png&quot; style=&quot;width: 30%&quot; /&gt; and &lt;img src=&quot;/images/github_overleaf_sync/pull_overleaf.png&quot; style=&quot;width: 35%&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Your project is now synchronized between the two platforms and you can now push or pull changes directly from the Overleaf project page. Be careful when editing the document on your laptop at the same time as it is being changed on Overleaf as this may cause merging conflicts.&lt;/p&gt;

&lt;h1 id=&quot;exporting-an-article-using-overleaf&quot;&gt;Exporting an article using Overleaf&lt;/h1&gt;

&lt;p&gt;One of the main advantages of using this method for your projects is that Overleaf offers a tool to export your project for numerous publishing platforms, notably &lt;a href=&quot;https://arxiv.org/&quot;&gt;arXiv&lt;/a&gt;. Simply compile your project once it is completed and select &lt;img src=&quot;/images/github_overleaf_sync/overleaf_submit.png&quot; style=&quot;width: 12%&quot; /&gt; tab on the top left of the project page. Then select the platform where you wish to publish and Overleaf will create the necessary files.&lt;/p&gt;

&lt;p&gt;It should be noted that an issue related to the biblatex file format is likely to happen when compiling the project on arXiv. This issue can be resolved by cloning &lt;a href=&quot;https://github.com/djsutherland/arxiv-collector&quot;&gt;this Python script&lt;/a&gt; in your local repository and following the instructions to create a biblatex file that is compatible with arXiv. More details on this issue can be found &lt;a href=&quot;https://github.com/plk/biblatex/wiki/biblatex-and-the-arXiv#uploading-the-relevant-parts-of-biblatex&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content><author><name>Dominic Baril</name><email>dominic.baril@norlab.ulaval.ca</email></author><category term="howto" /><category term="Overleaf" /><category term="GitHub" /><category term="LaTeX" /><category term="writing" /><summary type="html">Writing papers with a large number of co-authors can be complicated endeavour. This why Overleaf is an interesting choice, as it allows for multiple people to edit a same LaTeX document simultaneously. However, online compiling on Overleaf requires time and you will also want to have access to your files on your laptop and use your favorite LaTeX editor. This is why synchronizing your paper in an Overleaf project as well as in a GitHub repository GitHub. This will also grant you access to the laboratory’s LaTeX good practices repository.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22/logos/github_overleaf.png%22,%20%22feature%22=%3Enil%7D" /></entry><entry><title type="html">Evaluation of Skid-Steering Kinematic Models for Subarctic Environments</title><link href="https://norlab.ulaval.ca/publications/subartic_kinematic_modelling/" rel="alternate" type="text/html" title="Evaluation of Skid-Steering Kinematic Models for Subarctic Environments" /><published>2020-05-13T00:00:00-04:00</published><updated>2020-05-13T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/publications/subartic_kinematic_modelling</id><content type="html" xml:base="https://norlab.ulaval.ca/publications/subartic_kinematic_modelling/">&lt;p&gt;In subarctic and arctic areas, large and heavy skid-steered robots are preferred for their robustness and ability to operate on difficult terrain. State estimation, motion control and path planning for these robots rely on accurate odometry models based on wheel velocities. However, the state-of-the-art odometry models for skid-steer mobile robots (SSMRs) have usually been tested on relatively lightweight platforms. In this paper, we focus on how these models perform when deployed on a large and heavy (590 kg) SSMR. We collected more than 2 km of data on both snow and concrete. We compare the ideal differential-drive, extended differential-drive, radius-of-curvature-based, and full linear kinematic models commonly deployed for SSMRs. Each of the models is fine-tuned by searching their optimal parameters on both snow and concrete. We then discuss the relationship between the parameters, the model tuning, and the final accuracy of the models.&lt;/p&gt;

&lt;h1 id=&quot;quick-facts&quot;&gt;Quick facts:&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;4 Trajectories of more than 2 km were used to train and validate 5 kinematic models for SSMRs on dry concrete and snow-covered terrain&lt;/li&gt;
  &lt;li&gt;A &lt;a href=&quot;https://clearpathrobotics.com/warthog-unmanned-ground-vehicle-robot/&quot;&gt;Clearpath Robotics Warthog&lt;/a&gt; unmanned ground vehicle was used&lt;/li&gt;
  &lt;li&gt;An extensive analysis of model parameter training is given in the results&lt;/li&gt;
  &lt;li&gt;Our paper is available &lt;a href=&quot;https://arxiv.org/abs/2004.05131&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;It was presented at the &lt;a href=&quot;https://www.computerrobotvision.org/&quot;&gt;17th Conference on Computer and Robot Vision (CRV)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;video&quot;&gt;Video&lt;/h1&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/2ebxortAhmE&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;

&lt;p&gt;&lt;span id=&quot;Baril2020&quot;&gt;Baril, D., Grondin, V., Deschênes, S., Laconte, J., M., V., Kubelka, V., … Pomerleau, F. (2020). Evaluation of Skid-Steering Kinematic Models for Subarctic Environments. In &lt;i&gt;Proceeding of the 2020 17th Conference on Computer and Robot Vision (CRV)&lt;/i&gt;.&lt;/span&gt;&lt;/p&gt;</content><author><name>Dominic Baril</name><email>dominic.baril@norlab.ulaval.ca</email></author><category term="mobile  robots" /><category term="skid-steering  vehicles" /><category term="robot  kinematics" /><category term="winter" /><summary type="html">In subarctic and arctic areas, large and heavy skid-steered robots are preferred for their robustness and ability to operate on difficult terrain. State estimation, motion control and path planning for these robots rely on accurate odometry models based on wheel velocities. However, the state-of-the-art odometry models for skid-steer mobile robots (SSMRs) have usually been tested on relatively lightweight platforms. In this paper, we focus on how these models perform when deployed on a large and heavy (590 kg) SSMR. We collected more than 2 km of data on both snow and concrete. We compare the ideal differential-drive, extended differential-drive, radius-of-curvature-based, and full linear kinematic models commonly deployed for SSMRs. Each of the models is fine-tuned by searching their optimal parameters on both snow and concrete. We then discuss the relationship between the parameters, the model tuning, and the final accuracy of the models.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22projects/subartic_kinematic_modelling_feature.jpg%22,%20%22teaser%22=%3E%22projects/subartic_kinematic_modelling_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">Project SNOW</title><link href="https://norlab.ulaval.ca/research/snow/" rel="alternate" type="text/html" title="Project SNOW" /><published>2020-04-25T00:00:00-04:00</published><updated>2020-04-25T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/research/snow</id><content type="html" xml:base="https://norlab.ulaval.ca/research/snow/">&lt;p&gt;Self-driving cars are expected on our roads soon. In the project SNOW (Self-driving Navigation Optimized for Winter), we focus on the unexplored problem of autonomous driving during winter that still raises reliability concerns. We have the expertise to automatically build 3D maps of the environment while moving through it with robots. We aim at using this knowledge to investigate mapping and control solutions for challenging conditions related to Canadian weather.&lt;/p&gt;

&lt;p&gt;The main goal of this project is to extend the current technology used for autonomous driving toward unstructured and dynamic environments generated by winter conditions (e.g., a snow-covered forest). This project is addressing the applications of autonomous driving in remote areas, autonomous refueling, search and rescue missions, Canadian Arctic Sovereignty, freight transport on Northern ice roads, etc. Our research concentrates on maps built by a UGV, which will be able to adapt to environmental changes caused by snow and winds, while allowing a robust localization of the vehicle in real-time. These maps will also serve as the foundation for novel path planning algorithms handling deformable obstacles and environments (e.g., deep snow under a vehicle). The project is carried out in partnership with &lt;a href=&quot;https://www.gdlscanada.com/&quot; title=&quot;Official website&quot;&gt;General Dynamics Land Systems - Canada (GDLS-C)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To achieve the goals of the project, the following specific objectives are defined:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Objective 1—Mapping and Localization:&lt;/strong&gt; to develop algorithms to allow the UGV to localize and
map its environment in winter conditions.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Objective 2—Path Planning and Control:&lt;/strong&gt; to develop algorithms for planning paths and adapt
the behavior of the UGV according to weather conditions.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Objective 3—Field Testing and Integration:&lt;/strong&gt; to carry out an extensive series of experiments using
the UGV in a snow-covered forest.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;from-theory-to-practice&quot;&gt;From theory to practice&lt;/h2&gt;
&lt;p&gt;The following video shows the day we received the UGV - a Warthog robot made by a Canadian company, Clearpath Robotics. We have received the robot in August 2019 and since we began to realize ours plans in practice: 
&lt;!-- blank line --&gt;&lt;/p&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/bmGcV2TA0dY&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;integration-of-the-ugv-hardware-and-software&quot;&gt;Integration of the UGV hardware and software&lt;/h2&gt;
&lt;p&gt;Since the reception of the UGV, we have had a detailed plan of the tasks to follow to meet our goals, one of them being able to test the robot in a snowy forest during the winter of 2019. The first step was to integrate the sensor suite we had planned for the UGV.  This also involved constructing a solid metal frame by ours hands.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/images/projects/snow/forest_3.jpg&quot; style=&quot;width: 80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;When we finished this electrical part, we continued with the software integration. The mapping software required integration with the system of the UGV, mainly communication with its low-level computer which provides time synchronization and wheel odometry. After finishing all these tasks, it was finally the time to start testing. We found a nice and practical place for initial testing in front of our faculty building. In September 2019 when we fixed all the important details, we were able to proceed to the &lt;a href=&quot;https://www.foretmontmorency.ca/en/&quot; title=&quot;Official website&quot;&gt;Montmorency forest&lt;/a&gt;.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/images/projects/snow/forest_1.jpg&quot; style=&quot;width: 80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;The main goal of the first tests in the forest was to prove that we could safely deploy the robot, record all necessary data and possibly run mapping on-board the robot computers. We have, of course, discovered some bugs but they were all quick to fix and after a few sessions, we were able to generate large 3D maps of the forest.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/images/projects/snow/color_map.jpg&quot; style=&quot;width: 80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;Because the mapping functionality seemed working fine, we proceeded to implementing a basic path-following functionality. The robot would be navigated once by hand over a desired path while recording its position. Then, a software controller would repeat the path indefinitely, based on the onboard mapping and localization capabilities. The initial tuning of the controller showed some minor oscillations around the learned trajectory:&lt;/p&gt;

&lt;center&gt;
&lt;figure class=&quot;video_container&quot;&gt;
    &lt;video width=&quot;80%&quot; controls=&quot;&quot;&gt;
        &lt;source src=&quot;/images/projects/snow/oscillating.mp4&quot; type=&quot;video/mp4&quot; /&gt;
        Your browser does not support the video tag.
    &lt;/video&gt;
&lt;/figure&gt;
&lt;/center&gt;

&lt;p&gt;Fortunately, we were able to find the source of the problem, which was a misalignment between the commanded and actually executed turning rate of the robot. After fixing the problem, the controller was able to give us much more satisfying results:&lt;/p&gt;

&lt;center&gt;
&lt;figure class=&quot;video_container&quot;&gt;
    &lt;video muted=&quot;&quot; width=&quot;80%&quot; controls=&quot;&quot;&gt;
        &lt;source src=&quot;/images/projects/snow/better_control.mp4&quot; type=&quot;video/mp4&quot; /&gt;
        Your browser does not support the video tag.
    &lt;/video&gt;
&lt;/figure&gt;
&lt;/center&gt;

&lt;h2 id=&quot;first-review-meeting&quot;&gt;First review meeting&lt;/h2&gt;
&lt;p&gt;At the end of October 2019, the first review meeting took place. It lasted two days and was intended for our partner GDLS-C. We presented the integrated system and its capabilities to allow the partner to replicate the results on their identical UGV. The following video summarizes what was achieved:&lt;/p&gt;

&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/LILvVsYoaAg&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;team&quot;&gt;Team&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Principal Investigator and Technical Lead&lt;/strong&gt;: &lt;a href=&quot;../../people/f_pomerleau/&quot;&gt;François Pomerleau&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Deputy Technical Lead&lt;/strong&gt;: &lt;a href=&quot;../../people/v_kubelka&quot;&gt;Vladimír Kubelka&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Representing GDLS-C&lt;/strong&gt;: &lt;a href=&quot;https://www.linkedin.com/in/richard-lee-gdls-ic/&quot;&gt;Richard Lee&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PhD students&lt;/strong&gt;: &lt;a href=&quot;../../people/d_baril&quot;&gt;Dominic Baril&lt;/a&gt;, &lt;a href=&quot;../../people/&quot;&gt;Simon-Pierre Deschênes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Master student&lt;/strong&gt;: &lt;a href=&quot;../../people/&quot;&gt;Damien LaRocque&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jana Bartakova</name></author><category term="project" /><category term="snow" /><category term="robot" /><category term="warthog" /><summary type="html">Self-driving cars are expected on our roads soon. In the project SNOW (Self-driving Navigation Optimized for Winter), we focus on the unexplored problem of autonomous driving during winter that still raises reliability concerns. We have the expertise to automatically build 3D maps of the environment while moving through it with robots. We aim at using this knowledge to investigate mapping and control solutions for challenging conditions related to Canadian weather.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/projects/snow/forest_2_crop.jpg%22,%20%22teaser%22=%3E%22/projects/snow/snow_teaser.jpg%22%7D" /></entry><entry><title type="html">DARPA - SUBTERRANEAN CHALLENGE</title><link href="https://norlab.ulaval.ca/research/darpa-subt-urban/" rel="alternate" type="text/html" title="DARPA - SUBTERRANEAN CHALLENGE" /><published>2020-04-14T00:00:00-04:00</published><updated>2020-04-14T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/research/darpa-subt-urban</id><content type="html" xml:base="https://norlab.ulaval.ca/research/darpa-subt-urban/">&lt;p&gt;&lt;a href=&quot;https://www.subtchallenge.com&quot;&gt;DARPA - Subterranean Challenge (DARPA-SubT)&lt;/a&gt; is an international robotics competition focusing on autonomy, perception, networking, mobility technologies, and mapping underground areas in unpredictable conditions. This challenge connects the best researchers and teams to push the boundaries of what is possible in the field of mobile robotics. This competition consists of four circuits: tunnel systems, urban underground, cave networks and a combination of all of these together. It is also divided into the System track and the Virtual track and intended for both DARPA-funded and self-funded teams.&lt;/p&gt;

&lt;p&gt;Norlab competed in the System track of the urban circuit as a member of the CTU-CRAS-NORLAB team with the &lt;a href=&quot;https://robotics.fel.cvut.cz/cras&quot;&gt;Center for Robotics and Autonomous Systems (CRAS)&lt;/a&gt; from the Czech Technical University (CTU). Our researches could participate in the competition with a Husky robot thanks to generous funding by General Dynamics Land Systems – Canada. Together with the wheeled Husky robot, three tracked Absolem robots, three hexapod robots and two multi-rotor drones were deployed in the competition.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/images/projects/subt_urban/robots_entry.jpg&quot; style=&quot;width: 40%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;The System track consisted of two courses, the Alpha Course and the Beta Course, each of them would be attempted twice. They were both situated in the underground of an &lt;a href=&quot;https://en.wikipedia.org/wiki/WNP-3_and_WNP-5&quot; title=&quot;Wikipedia&quot;&gt;unfinished nuclear plant&lt;/a&gt; close to Elma, Washington, in the United States. In every course, there were 20 hidden artifacts to be found by the robots in less than sixty minutes. The artifacts consisted of manikins (heated and wearing reflective jackets and hats), red backpacks, working cell phones (video, Wi-Fi, and Bluetooth), CO2 gas and air vents. The position of the artifacts would change between the two possible attempts. The goal was to detect and localize as many artifacts as possible.&lt;/p&gt;

&lt;p&gt;Our team deployed a combination of robots with different types of locomotion to be prepared for various obstacles expected in the man-made underground. The core of the robotic team consisted of three tracked robots that were able to navigate stairs and therefore explore multiple floors. Norlab provided a Husky robot allowing fast exploration on a single floor. Finally, drones and walking hexapods extended the reach of our team by either flying further (drones) or carrying radio modules (hexapods) extending the communication range. Our team chose lidars to be its primary mean of mapping and localization which also went well with the research focus of Norlab. Together with the thorough preparation of the artifact detectors on the Czech side and intensive testing, we were able to accurately localize artifacts the robots encountered. Motivated by the performance of the winning team, we now focus on improving the speed of exploration through better cooperation between the robots and higher autonomy.&lt;/p&gt;

&lt;h1 id=&quot;team&quot;&gt;Team&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Principal Investigator&lt;/strong&gt;: &lt;a href=&quot;http://cmp.felk.cvut.cz/~svoboda/&quot;&gt;Tomas Svoboda&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scientific Lead - 3D mapping&lt;/strong&gt;: &lt;a href=&quot;../../people/f_pomerleau/&quot;&gt;François Pomerleau&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Researchers - 3D mapping&lt;/strong&gt;: &lt;a href=&quot;../../people/v_kubelka&quot;&gt;Vladimír Kubelka&lt;/a&gt;, &lt;a href=&quot;../../people/m_vaidis&quot;&gt;Maxime Vaidis&lt;/a&gt;, &lt;a href=&quot;../../people/d_baril&quot;&gt;Dominic Baril&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://robotics.fel.cvut.cz/cras/darpa-subt/&quot;&gt;Team web page from CTU&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/projects/subt_urban/robots_not_ready.jpg&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;During this exciting competition, we also managed to make a few interesting stunts. One of them being the tracked Absolem robot running over and partially crushing the plastic hexapod robot. Another exciting stunt was overturning the Absolem robot on its back while climbing stairs. Also, we broke several drones, and in the end, one burned. Despite all these hardships, the team managed to score 10 points and took an amazing first place as a self-funded team and a third place among all teams.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/projects/subt_urban/prize.jpg&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;video&quot;&gt;Video&lt;/h1&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/u_7DwnYTf-I&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/4hdeFdt0woc?start=14689&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/V9tzKF0hxnE?start=7475&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/O_c7P1TJKM4?start=15215&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/SgPirHYszzw?start=5997&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/rTP64z52JFE&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/3tqBO0HbLHY&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;

&lt;h1 id=&quot;media-coverage&quot;&gt;Media Coverage&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;IEEE SPECTRUM - &lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/robotics-teams-prepare-darpa-subt-challenge-urban-circuit&quot;&gt;How Robotics Teams Prepared for DARPA’s SubT Challenge: Urban Circuit&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;IEEE SPECTRUM - &lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/video-friday-quadruped-robot-locomotion-skills&quot;&gt;Video Friday: Quadruped Robot Learns Locomotion Skills by Imitating Dog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;THE ROBOTREPORT - &lt;a href=&quot;https://www.therobotreport.com/team-costar-wins-urban-circuit-of-darpa-subterranean-challenge/&quot;&gt;Team CoSTAR wins Urban Circuit of DARPA Subterranean Challenge&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;GEEKWIRE - &lt;a href=&quot;https://www.geekwire.com/2020/robots-masters-take-nuclear-plant-darpas-subterranean-challenge/&quot;&gt;Robots and their masters take over nuclear plant for DARPA’s Subterranean Challenge&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;ROS Discourse - &lt;a href=&quot;https://discourse.ros.org/t/subt-challenge-urban-circuit-overview/13635&quot;&gt;SubT Challenge Urban Circuit Overview&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;The Vidette - &lt;a href=&quot;https://www.thevidette.com/news/robots-creeping-around-satsop-hoping-to-find-millions-in-prize-money/&quot;&gt;Robots creeping around Satsop hoping to find millions in prize money&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;ULaval (french) - &lt;a href=&quot;https://nouvelles.ulaval.ca/recherche/des-robots-dans-les-dedales-dune-centrale-nucleaire-abandonnee-a7a44f1b225efdc51eb5c4d657082e0a?sourceOrganizationKey=ulaval&quot;&gt;Des robots dans les dédales d’une centrale nucléaire abandonnée&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;ULaval (french) - &lt;a href=&quot;https://www.fsg.ulaval.ca/faculte/actualites/norlab-et-ses-partenaires-se-distinguent-au-darpa-subterranean-challenge-3400/&quot;&gt;Norlab et ses partenaires se distinguent au DARPA Subterranean Challenge&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;DARPA NEWS - &lt;a href=&quot;https://www.darpa.mil/news-events/2020-02-27&quot;&gt;Teams CoSTAR and BARCS Take Top Spots in DARPA Subterranean Challenge Urban Circuit&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;DARPA NEWS - &lt;a href=&quot;https://www.darpa.mil/news-events/2020-01-10&quot;&gt;DARPA Names Qualifiers for the Subterranean Challenge Urban Circuit&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;NEWSTROTTEUR (french) - &lt;a href=&quot;https://newstrotteur.fr/2020/02/28/des-robots-prennent-le-controle-dune-centrale-nucleaire-pour-le-defi-souterrain-de-la-darpa-newstrotteur/&quot;&gt;Des robots prennent le contrôle d’une centrale nucléaire pour le défi souterrain de la DARPA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;MAGNETPRESS (czech) - &lt;a href=&quot;https://www.vydavatelstvo-mps.sk/atm/6800-robotici-z-fel-cvut-uspeli-v-soutezi.html&quot;&gt;Robotici z FEL ČVUT uspěli v soutěži&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;CZECH WEBSITE: CTU NEWS (czech) - &lt;a href=&quot;https://aktualne.cvut.cz/stalo-se/20200228-robotici-z-fakulty-elektrotechnicke-vyhrali-svetovou-soutez-darpa-subterranean&quot;&gt;Robotici Z Fakulty Elektrotechnické Vyhráli Světovou Soutěž Darpa Subterranean Challenge Urban Circuit Mezi Nesponzorovanými Týmy A Obsadili Celkově 3. Místo&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;SCIENCEMAG (czech) - &lt;a href=&quot;https://sciencemag.cz/robotici-z-cvut-vyhrali-svetovou-soutez-darpa/&quot;&gt;Robotici z ČVUT vyhráli světovou soutěž DARPA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;DRONEWEB (czech) - &lt;a href=&quot;http://www.droneweb.cz/aktuality/item/345-drony-autonomni-fel-cvut-darpa-soutez&quot;&gt;České robotické drony budou soutěžit v americkém podzemí&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jana Bartakova</name></author><category term="project" /><category term="darpa" /><category term="competition" /><category term="subterranean" /><category term="robots" /><summary type="html">DARPA - Subterranean Challenge (DARPA-SubT) is an international robotics competition focusing on autonomy, perception, networking, mobility technologies, and mapping underground areas in unpredictable conditions. This challenge connects the best researchers and teams to push the boundaries of what is possible in the field of mobile robotics. This competition consists of four circuits: tunnel systems, urban underground, cave networks and a combination of all of these together. It is also divided into the System track and the Virtual track and intended for both DARPA-funded and self-funded teams.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/projects/subt_urban/subt_main.jpg%22,%20%22teaser%22=%3E%22/projects/subt_urban/subt_teaser.jpg%22%7D" /></entry><entry><title type="html">The Montmorency dataset</title><link href="https://norlab.ulaval.ca/research/montmorencydataset/" rel="alternate" type="text/html" title="The Montmorency dataset" /><published>2020-01-25T00:00:00-05:00</published><updated>2020-01-25T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/research/montmorencydataset</id><content type="html" xml:base="https://norlab.ulaval.ca/research/montmorencydataset/">&lt;p&gt;Under construction&lt;/p&gt;

&lt;p&gt;The dataset in now available for download on &lt;a href=&quot;https://academictorrents.com/details/cf39b5c4285f20c3539cbe9f37f6e04cfde10afa&quot;&gt;Academic Torrents&lt;/a&gt;.
This dataset contains the ground truth species, diameter at breast height and position of more than 1000 trees across four forests, as well as 11 trajectories of a lidar-equipped robot going through these forests.
It has been the subject of a publication at the 12th Conference on Field and Service Robotics.&lt;/p&gt;

&lt;p&gt;More details will appear later as this work is still undergoing peer-review.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Tremblay2019&quot;&gt;Tremblay, J.-F., Béland, M., Pomerleau, F., Gagnon, R., &amp;amp; Giguère, P. (2019). Automatic 3D Mapping for Tree Diameter Measurements in Inventory Operations. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Tremblay2019.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a href=&quot;/pdf/Tremblay2019.slides.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-powerpoint&quot;&gt;&lt;/i&gt; Slides&lt;/a&gt;

&lt;a class=&quot;details&quot; href=&quot;/bibliography/Tremblay2019/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Jean-François Tremblay</name></author><category term="project" /><category term="mapping" /><category term="forestry" /><category term="lidar" /><summary type="html">Under construction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22projects/forest_mapping_feature.jpg%22,%20%22teaser%22=%3E%22projects/forest_mapping_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">Our first group photo!</title><link href="https://norlab.ulaval.ca/news/christmas/" rel="alternate" type="text/html" title="Our first group photo!" /><published>2019-12-11T00:00:00-05:00</published><updated>2019-12-11T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/news/christmas</id><content type="html" xml:base="https://norlab.ulaval.ca/news/christmas/">&lt;p&gt;It has been a good year in term of team building and equipment acquisition. 
Next year will most probably reserve us a lot of surprises, but I’m certain that we are ready for new scientific breakthroughs.&lt;/p&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="photo" /><category term="group" /><summary type="html">It has been a good year in term of team building and equipment acquisition. Next year will most probably reserve us a lot of surprises, but I’m certain that we are ready for new scientific breakthroughs.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/news/christmas19/christmas_feature.jpg%22,%20%22teaser%22=%3E%22/news/christmas19/christmas_teaser.jpg%22%7D" /></entry><entry><title type="html">Philippe Babin</title><link href="https://norlab.ulaval.ca/people/p_babin/" rel="alternate" type="text/html" title="Philippe Babin" /><published>2019-09-13T00:00:00-04:00</published><updated>2019-09-13T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/people/p_babin</id><content type="html" xml:base="https://norlab.ulaval.ca/people/p_babin/">&lt;p&gt;Philippe Babin is currently employed at &lt;a href=&quot;https://argo.ai&quot;&gt;Argo AI&lt;/a&gt; a self-driving car startup.
He got a Bachelor’s Degree in Computer Science Engineering at Université Laval in 2017.
Throught his master, he works on improving the robustness of Iterative Closest Point (ICP).
His first project explored the effects of outlier filters (such as M-estimator) on ICP.
He then worked on the development of LIDAR SLAM algorithm for a forest mapping application.&lt;/p&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;M.Sc. in Computer Science - Université Laval, 2017-2019&lt;/li&gt;
  &lt;li&gt;Bachelor’s Degree in Computer Science Engineering - Distinction Profile - Université Laval, 2013-2017&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;h2 class=&quot;bibliography&quot;&gt;Conference Articles&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Dandurand2019&quot;&gt;Dandurand, P., Babin, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Predicting GNSS satellite visibility from dense point clouds. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Dandurand2019.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a class=&quot;details&quot; href=&quot;/bibliography/Dandurand2019/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Babin2019a&quot;&gt;Babin, P., Dandurand, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Large-scale 3D Mapping of Subarctic Forests. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Babin2019a.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a href=&quot;/pdf/Babin2019a.slides.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-powerpoint&quot;&gt;&lt;/i&gt; Slides&lt;/a&gt;

&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2019a/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Babin2019&quot;&gt;Babin, P., Giguère, P., &amp;amp; Pomerleau, F. (2019). Analysis of Robust Functions for Registration Algorithms. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Babin2019.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2019/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;
&lt;h2 class=&quot;bibliography&quot;&gt;Miscellaneous&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Babin2018&quot;&gt;Babin, P., Pomerleau, F., &amp;amp; Giguère, P. (2018). Improving the robustness of registration algorithm in complex environments. Colloque du regroupement FRQNT-REPARTI.&lt;/span&gt;



&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2018/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Philippe Babin</name></author><summary type="html">Philippe Babin is currently employed at Argo AI a self-driving car startup. He got a Bachelor’s Degree in Computer Science Engineering at Université Laval in 2017. Throught his master, he works on improving the robustness of Iterative Closest Point (ICP). His first project explored the effects of outlier filters (such as M-estimator) on ICP. He then worked on the development of LIDAR SLAM algorithm for a forest mapping application.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/p_babin.jpg%22,%20%22teaser%22=%3E%22/people/p_babin_avatar.jpg%22%7D" /></entry><entry><title type="html">Large-scale 3D Mapping of Subarctic Forests</title><link href="https://norlab.ulaval.ca/publications/penality-icp/" rel="alternate" type="text/html" title="Large-scale 3D Mapping of Subarctic Forests" /><published>2019-09-13T00:00:00-04:00</published><updated>2019-09-13T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/publications/penality-icp</id><content type="html" xml:base="https://norlab.ulaval.ca/publications/penality-icp/">&lt;p&gt;The ability to map challenging subarctic environments opens new horizons for robotic deployments in industries such as forestry, surveillance, and open-pit mining. In this paper, we explore possibilities of large-scale lidar mapping in a boreal forest. Computational and sensory requirements with regards to contemporary hardware are considered as well. The lidar mapping is often based on the SLAM technique relying on pose graph optimization, which fuses the Iterative Closest Point (ICP) algorithm, Global Navigation Satellite System (GNSS) positioning, and Inertial Measurement Unit (IMU) measurements.  To handle those sensors directly within the ICP minimization process, we propose an alternative approach of embedding external constraints. Furthermore, a novel formulation of a cost function is presented and cast into the problem of handling uncertainties from GNSS and lidar points. To test our approach, we acquired a large-scale dataset in the Foret Montmorency research forest. We report on the technical problems faced during our winter deployments aiming at building 3D maps using our new cost function. Those maps demonstrate both global and local consistency over 4.1km.&lt;/p&gt;

&lt;h1 id=&quot;quick-facts&quot;&gt;Quick facts:&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;4.1 km of untapped forest trail and snowmobile was mapped using a custom acquisition platform&lt;/li&gt;
  &lt;li&gt;The acquisition platform has a Xsens MTI-30 IMU, a &lt;a href=&quot;https://www.robosense.ai/rslidar/rs-lidar-16&quot;&gt;RoboSense RS-lidar-16&lt;/a&gt; and a REACH RS+ GNSS station&lt;/li&gt;
  &lt;li&gt;All of field test were done at &lt;a href=&quot;https://www.foretmontmorency.ca/en/&quot;&gt;Forêt Montmorency&lt;/a&gt;, a research forest owns by Université Laval.&lt;/li&gt;
  &lt;li&gt;Our paper is available &lt;a href=&quot;https://arxiv.org/abs/1904.07814&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;It was presented at the 12th Conference on Field and Service Robotic, the slides are available &lt;a href=&quot;../../pdf/Babin2019a.slides.pdf&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;video&quot;&gt;Video&lt;/h1&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/t_cBdiPQ1R8&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Babin2019a&quot;&gt;Babin, P., Dandurand, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Large-scale 3D Mapping of Subarctic Forests. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Babin2019a.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a href=&quot;/pdf/Babin2019a.slides.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-powerpoint&quot;&gt;&lt;/i&gt; Slides&lt;/a&gt;

&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2019a/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Philippe Babin</name></author><category term="project" /><category term="icp" /><category term="mapping" /><category term="subarctic" /><category term="snowmobile" /><category term="forestry" /><category term="lidar" /><summary type="html">The ability to map challenging subarctic environments opens new horizons for robotic deployments in industries such as forestry, surveillance, and open-pit mining. In this paper, we explore possibilities of large-scale lidar mapping in a boreal forest. Computational and sensory requirements with regards to contemporary hardware are considered as well. The lidar mapping is often based on the SLAM technique relying on pose graph optimization, which fuses the Iterative Closest Point (ICP) algorithm, Global Navigation Satellite System (GNSS) positioning, and Inertial Measurement Unit (IMU) measurements. To handle those sensors directly within the ICP minimization process, we propose an alternative approach of embedding external constraints. Furthermore, a novel formulation of a cost function is presented and cast into the problem of handling uncertainties from GNSS and lidar points. To test our approach, we acquired a large-scale dataset in the Foret Montmorency research forest. We report on the technical problems faced during our winter deployments aiming at building 3D maps using our new cost function. Those maps demonstrate both global and local consistency over 4.1km.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22projects/penalty_icp_feature.jpg%22,%20%22teaser%22=%3E%22projects/penalty_icp_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">Lambda-Field: A Continuous Counterpart of the Bayesian Occupancy Grid for Risk Assessment</title><link href="https://norlab.ulaval.ca/publications/lambda-field/" rel="alternate" type="text/html" title="Lambda-Field: A Continuous Counterpart of the Bayesian Occupancy Grid for Risk Assessment" /><published>2019-09-02T00:00:00-04:00</published><updated>2019-09-02T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/publications/lambda-field</id><content type="html" xml:base="https://norlab.ulaval.ca/publications/lambda-field/">&lt;p&gt;In a context of autonomous robots, one of the most important tasks is to ensure the safety of the robot and its surrounding.
The risk of navigation is usually said to be the probability of collision.
This notion of risk is not well defined in the literature, especially when dealing with occupancy grids.
The Bayesian occupancy grid is the most used method to deal with complex environments.
However, this is not fitted to compute the risk along a path by its discrete nature.
In this article, we present a new way to store the occupancy of the environment that allows the computation of risk along a given path.
We then define the risk as the force of collision that would occur for a given obstacle.
Using this framework, we are able to generate navigation paths ensuring the safety of the robot.&lt;/p&gt;

&lt;h1 id=&quot;contributions&quot;&gt;Contributions&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;A novel type of map, called Lambda-Field, specially conceived to allow path integrals and thus probabilities of collision;&lt;/li&gt;
  &lt;li&gt;A definition of the risk encountered over a path, specified as the expected force of collision along a path.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;results-in-images&quot;&gt;Results in Images&lt;/h1&gt;

&lt;p&gt;Using the lambda-field, we are able to construct maps where the probability of collision along a path logically arises from the theory.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/publications/lambda-field/maps.png&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The robot (trajectory in blue) maps an urban-like environment and creates a Bayesian Grid as well as a Lambda-Field.
Although the maps are almost the same, the Lambda-Field tends to better store the unstructured obstacles (bushes in this example).&lt;/p&gt;

&lt;h1 id=&quot;in-video&quot;&gt;In Video&lt;/h1&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/ybj8NWWbzAo&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;

&lt;p&gt;&lt;span id=&quot;Laconte2019a&quot;&gt;Laconte, J., Debain, C., Chapuis, R., Pomerleau, F., &amp;amp; Aufrere, R. (2019). Lambda-Field: A Continuous Counterpart of the Bayesian Occupancy Grid for Risk Assessment. In &lt;i&gt;Proceedings of the IEEE International Conference on Intelligent Robots and Systems (IROS)&lt;/i&gt;.&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;links&quot;&gt;Links&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.researchgate.net/publication/331565267_Lambda-Field_A_Continuous_Counterpart_of_the_Bayesian_Occupancy_Grid_for_Risk_Assessment&quot;&gt;Download link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Johann Laconte</name></author><category term="publications" /><category term="traversability" /><category term="lidar" /><category term="mapping" /><summary type="html">In a context of autonomous robots, one of the most important tasks is to ensure the safety of the robot and its surrounding. The risk of navigation is usually said to be the probability of collision. This notion of risk is not well defined in the literature, especially when dealing with occupancy grids. The Bayesian occupancy grid is the most used method to deal with complex environments. However, this is not fitted to compute the risk along a path by its discrete nature. In this article, we present a new way to store the occupancy of the environment that allows the computation of risk along a given path. We then define the risk as the force of collision that would occur for a given obstacle. Using this framework, we are able to generate navigation paths ensuring the safety of the robot.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22publications/lambda-field_teaser.png%22,%20%22feature%22=%3E%22publications/lambda-field_feature.png%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">Norlab is going to Asia!</title><link href="https://norlab.ulaval.ca/news/iros-fsr19/" rel="alternate" type="text/html" title="Norlab is going to Asia!" /><published>2019-06-24T00:00:00-04:00</published><updated>2019-06-24T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/news/iros-fsr19</id><content type="html" xml:base="https://norlab.ulaval.ca/news/iros-fsr19/">&lt;p&gt;We are going to Tokyo (Japan) and Macau (China) with four accepted publications at the &lt;a href=&quot;http://www.srg.mech.keio.ac.jp/fsr2019/&quot;&gt;2019 International Conference on Field and Service Robotics&lt;/a&gt; and one at the &lt;a href=&quot;https://www.iros2019.org/&quot;&gt;2019 IEEE/RSJ International Conference on Intelligent Robots and Systems&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We will present our latest results on lambda-field maps for continuous and risk-aware path planning &lt;a href=&quot;#Laconte2019a&quot;&gt;(Laconte, Debain, Chapuis, Pomerleau, &amp;amp; Aufrere, 2019)&lt;/a&gt;, 3D mapping in subarctic environments &lt;a href=&quot;#Babin2019a&quot;&gt;(Babin, Dandurand, Kubelka, Giguère, &amp;amp; Pomerleau, 2019)&lt;/a&gt;, estimation of GPS satellite visibility given 3D maps &lt;a href=&quot;#Dandurand2019&quot;&gt;(Dandurand, Babin, Kubelka, Giguère, &amp;amp; Pomerleau, 2019)&lt;/a&gt;, automatic forestry inventory based on 3D maps&lt;a href=&quot;#Tremblay2019&quot;&gt;(Tremblay, Béland, Pomerleau, Gagnon, &amp;amp; Giguère, 2019)&lt;/a&gt;, and multi-session lake-shore monitoring based on lidar &lt;a href=&quot;#Pradalier2019&quot;&gt;(Pradalier, Aravecchia, &amp;amp; Pomerleau, 2019)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;More details, and hopefully videos to come!&lt;/p&gt;

&lt;h1 id=&quot;our-articles&quot;&gt;Our articles&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Laconte2019a&quot;&gt;Laconte, J., Debain, C., Chapuis, R., Pomerleau, F., &amp;amp; Aufrere, R. (2019). Lambda-Field: A Continuous Counterpart of the Bayesian Occupancy Grid for Risk Assessment. In &lt;i&gt;Proceedings of the IEEE International Conference on Intelligent Robots and Systems (IROS)&lt;/i&gt;.&lt;/span&gt;



&lt;a class=&quot;details&quot; href=&quot;/bibliography/Laconte2019a/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Dandurand2019&quot;&gt;Dandurand, P., Babin, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Predicting GNSS satellite visibility from dense point clouds. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Dandurand2019.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a class=&quot;details&quot; href=&quot;/bibliography/Dandurand2019/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Babin2019a&quot;&gt;Babin, P., Dandurand, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Large-scale 3D Mapping of Subarctic Forests. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Babin2019a.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a href=&quot;/pdf/Babin2019a.slides.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-powerpoint&quot;&gt;&lt;/i&gt; Slides&lt;/a&gt;

&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2019a/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Tremblay2019&quot;&gt;Tremblay, J.-F., Béland, M., Pomerleau, F., Gagnon, R., &amp;amp; Giguère, P. (2019). Automatic 3D Mapping for Tree Diameter Measurements in Inventory Operations. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Tremblay2019.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a href=&quot;/pdf/Tremblay2019.slides.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-powerpoint&quot;&gt;&lt;/i&gt; Slides&lt;/a&gt;

&lt;a class=&quot;details&quot; href=&quot;/bibliography/Tremblay2019/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Pradalier2019&quot;&gt;Pradalier, C., Aravecchia, S., &amp;amp; Pomerleau, F. (2019). Multi-session lake-shore monitoring in visually challenging conditions. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;



&lt;a class=&quot;details&quot; href=&quot;/bibliography/Pradalier2019/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="conference" /><summary type="html">We are going to Tokyo (Japan) and Macau (China) with four accepted publications at the 2019 International Conference on Field and Service Robotics and one at the 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22/news/iros_fsr19/iros_fsr19_teaser.jpg%22%7D" /></entry></feed>