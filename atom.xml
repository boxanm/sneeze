<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://norlab.ulaval.ca/atom.xml" rel="self" type="application/atom+xml" /><link href="https://norlab.ulaval.ca/" rel="alternate" type="text/html" /><updated>2019-06-06T15:34:28+02:00</updated><id>https://norlab.ulaval.ca/atom.xml</id><title type="html">Northern Robotics Laboratory</title><subtitle>Website showcasing research and news from the Northern Robotics Laboratory, Laval University</subtitle><entry><title type="html">Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping</title><link href="https://norlab.ulaval.ca/publications/lidar-bias/" rel="alternate" type="text/html" title="Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping" /><published>2019-05-27T00:00:00+02:00</published><updated>2019-05-27T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/publications/lidar-bias</id><content type="html" xml:base="https://norlab.ulaval.ca/publications/lidar-bias/">&lt;p&gt;In a context of 3D mapping, it is very important to obtain accurate measurements from sensors.
In particular, LIDAR measurements are typically treated as a zero-mean Gaussian distribution.
We show that this assumption leads to predictable localisation drifts, especially when a bias related to measuring obstacles with high incidence angles is not taken into consideration.
Moreover, we present a way to physically understand and model this bias, which generalizes to multiple sensors.
Using an experimental setup, we measured the bias of the Sick LMS-151, Velodyne HDL-32E, and Robosense RS-LiDAR-16 as a function of depth and incidence angle, and showed that the bias can reach 20 cm for high incidence angles.
We then used our model to remove the bias from the measurements, leading to more accurate maps and a reduced localisation drift.&lt;/p&gt;
&lt;h1 id=&quot;contributions&quot;&gt;Contributions&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Physical explanation of a lidar bias caused by the incidence angle of the laser beam on a surface&lt;/li&gt;
  &lt;li&gt;A way to quantify and correct this bias for common LIDARs used in mobile robotics&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;results-in-images&quot;&gt;Results in Images&lt;/h1&gt;

&lt;p&gt;Using our model, we found the following bias for three commonly used LIDARs:
&lt;img src=&quot;/images/publications/lidar-bias/isocurves.jpg&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We were able to remove the bias from the measurements, leading to more accurate maps.
In blue, the map of a tunnel without taking into account the bias.
In red, the same map taking into account the bias and removing it from the measurements.
&lt;img src=&quot;/images/publications/lidar-bias/tunnels.jpg&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;in-video&quot;&gt;In Video&lt;/h1&gt;

&lt;!--&lt;iframe src=&quot;https://www.youtube.com/watch?v=YE-oL7do2HM&quot; style=&quot;width: 100%&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;--&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/YE-oL7do2HM&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;

&lt;p&gt;&lt;span id=&quot;Laconte2019&quot;&gt;Laconte, J., Deschênes, S.-P., Labussière, M., &amp;amp; Pomerleau, F. (2019). Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;links&quot;&gt;Links&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.researchgate.net/publication/328063232_Lidar_Measurement_Bias_Estimation_via_Return_Waveform_Modelling_in_a_Context_of_3D_Mapping&quot;&gt;Download link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Johann Laconte</name></author><category term="publications" /><category term="ICP" /><category term="bias estimation" /><category term="sensor error modelling" /><category term="lidar" /><category term="mapping" /><summary type="html">In a context of 3D mapping, it is very important to obtain accurate measurements from sensors. In particular, LIDAR measurements are typically treated as a zero-mean Gaussian distribution. We show that this assumption leads to predictable localisation drifts, especially when a bias related to measuring obstacles with high incidence angles is not taken into consideration. Moreover, we present a way to physically understand and model this bias, which generalizes to multiple sensors. Using an experimental setup, we measured the bias of the Sick LMS-151, Velodyne HDL-32E, and Robosense RS-LiDAR-16 as a function of depth and incidence angle, and showed that the bias can reach 20 cm for high incidence angles. We then used our model to remove the bias from the measurements, leading to more accurate maps and a reduced localisation drift. Contributions</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22publications/lidar-bias_feature.jpg%22,%20%22teaser%22=%3E%22publications/lidar-bias_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">Satellite Visibility Prediction</title><link href="https://norlab.ulaval.ca/research/satellite-visibility/" rel="alternate" type="text/html" title="Satellite Visibility Prediction" /><published>2019-05-09T00:00:00+02:00</published><updated>2019-05-09T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/research/satellite-visibility</id><content type="html" xml:base="https://norlab.ulaval.ca/research/satellite-visibility/">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;To help future mobile agents plan their movement in harsh environments,a predictive model has been designed to determine what areas would be favorable for Global Navigation Satellite System (GNSS) positioning. The model is able to predict the number of viable satellites for a GNSS receiver, based on a 3D point cloud map and a satellite constellation. Both occlusion and absorption effects of the environment are considered. A rugged mobile platform was designed to collect data in order to generate the point cloud maps. It was deployed during the Canadian winter known for large amounts of snow and extremely low temperatures. The test environments include a highly dense boreal forest and a university campus with high buildings. The experiment results indicate that the model performs well in both structured and unstructured environments.&lt;/p&gt;

&lt;h1 id=&quot;quick-facts&quot;&gt;Quick facts:&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;This method has been tested in diverse environments such has a highly dense boreal forest and a university campus with high buildings&lt;/li&gt;
  &lt;li&gt;This method is able to differentiate between forest and buildings&lt;/li&gt;
  &lt;li&gt;The hardware used in the paper has been proven to work in sub-arctic environment&lt;/li&gt;
  &lt;li&gt;Our preprint is available &lt;a href=&quot;https://arxiv.org/abs/1904.07837&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;video&quot;&gt;Video&lt;/h1&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/5LdxV1-9rEE&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Dandurand2019&quot;&gt;Dandurand, P., Babin, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Predicting GNSS satellite visibility from dense point clouds. In &lt;i&gt;preprint, ArXiv. Submitted to Field and Service Robotics (FSR)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Dandurand2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Philippe Dandurand</name></author><category term="project" /><category term="GNSS" /><category term="GPS" /><category term="lidar" /><category term="RTK" /><category term="DGNSS" /><category term="winter" /><category term="mapping" /><category term="uncertainty" /><summary type="html">Abstract To help future mobile agents plan their movement in harsh environments,a predictive model has been designed to determine what areas would be favorable for Global Navigation Satellite System (GNSS) positioning. The model is able to predict the number of viable satellites for a GNSS receiver, based on a 3D point cloud map and a satellite constellation. Both occlusion and absorption effects of the environment are considered. A rugged mobile platform was designed to collect data in order to generate the point cloud maps. It was deployed during the Canadian winter known for large amounts of snow and extremely low temperatures. The test environments include a highly dense boreal forest and a university campus with high buildings. The experiment results indicate that the model performs well in both structured and unstructured environments.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22projects/sat_vis_feature.jpg%22,%20%22teaser%22=%3E%22projects/sat_vis_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">First appearance of the lab in IEEE Spectrum</title><link href="https://norlab.ulaval.ca/news/ieee-spectrum/" rel="alternate" type="text/html" title="First appearance of the lab in IEEE Spectrum" /><published>2019-05-07T00:00:00+02:00</published><updated>2019-05-07T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/news/ieee-spectrum</id><content type="html" xml:base="https://norlab.ulaval.ca/news/ieee-spectrum/">&lt;p&gt;Norlab appears in the online version of the magazine IEEE Spectrum with the title &lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/darpa-subt-meet-the-first-nine-teams&quot;&gt;DARPA Subterranean Challenge: Meet the First 9 Teams&lt;/a&gt;.
They confuse our French and English name, but at least the URL is correct.&lt;/p&gt;

&lt;p&gt;Our lab is supporting the mapping capability of the Team CRAS (Center for Robotics and Autonomous Systems) leaded by the Czech Technical University in Prague, Czech Republic.&lt;/p&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="media" /><summary type="html">Norlab appears in the online version of the magazine IEEE Spectrum with the title DARPA Subterranean Challenge: Meet the First 9 Teams. They confuse our French and English name, but at least the URL is correct.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22/logos/ieeeSpectrum.jpg%22%7D" /></entry><entry><title type="html">Information for New Students</title><link href="https://norlab.ulaval.ca/research/new-students/" rel="alternate" type="text/html" title="Information for New Students" /><published>2019-05-07T00:00:00+02:00</published><updated>2019-05-07T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/research/new-students</id><content type="html" xml:base="https://norlab.ulaval.ca/research/new-students/">&lt;p&gt;Welcome to the laboratory!
It will take a couple of weeks to get you up and running in the lab, so why not use that time to explore different sources of information that will save you time later.&lt;/p&gt;

&lt;h1 id=&quot;register-to-news-feeds&quot;&gt;Register to news feeds&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Register to the magazine &lt;a href=&quot;https://www.universityaffairs.ca&quot;&gt;University Affairs&lt;/a&gt; (free) for general information about the academic life.&lt;/li&gt;
  &lt;li&gt;Register to &lt;a href=&quot;https://www.eu-robotics.net/eurobotics/newsroom/mailing-list&quot;&gt;euRobotics mailing list&lt;/a&gt;  for jobs, software release, call for journal special issues, etc.&lt;/li&gt;
  &lt;li&gt;Register to &lt;a href=&quot;http://duerer.usc.edu/mailman/listinfo.cgi/robotics-worldwide&quot;&gt;robotics-worldwide mailing list&lt;/a&gt;. Same information as euRobotics with a larger audience.&lt;/li&gt;
  &lt;li&gt;Don’t take your work &lt;a href=&quot;http://phdcomics.com/&quot;&gt;too seriously&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;explore-our-github-repo&quot;&gt;Explore our GitHub repo&lt;/h1&gt;

&lt;p&gt;You will need an account on GitHub, so you can be added to the members of&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;
&lt;a href=&quot;https://github.com/norlab-ulaval&quot; target=&quot;_blank&quot; class=&quot;btn&quot;&gt;
&lt;img src=&quot;/images/logos/github.svg&quot; style=&quot;padding-right: 1em; width: 4em; -webkit-filter: invert(100%); filter: invert(100%);&quot; /&gt;
norlab-ulaval
&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;Then, explore the following:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval?utf8=%E2%9C%93&amp;amp;q=poster&amp;amp;type=&amp;amp;language=&quot;&gt;Scientific posters&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval?utf8=%E2%9C%93&amp;amp;q=publication&amp;amp;type=&amp;amp;language=&quot;&gt;Scientific publications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval?utf8=%E2%9C%93&amp;amp;q=mastersProposal&amp;amp;type=&amp;amp;language=&quot;&gt;Master’s proposal&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval?utf8=%E2%9C%93&amp;amp;q=mastersThesis&amp;amp;type=&amp;amp;language=&quot;&gt;Master’s thesis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval/visualIdentity&quot;&gt;Different logos of the lab&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Read our &lt;a href=&quot;https://github.com/norlab-ulaval/latexGoodPractices/blob/master/preamble.tex&quot;&gt;Latex good practices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;little-tip-to-save-you-some-time&quot;&gt;Little tip to save you some time&lt;/h1&gt;
&lt;p&gt;Create a new bookmark on you favorite web browser and copy-paste this script as the url:&lt;/p&gt;
&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;javascript&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;href&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'https://acces.bibl.ulaval.ca/login?qurl='&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+%&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;encodeURIComponent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;href&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);})());&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If you click the bookmark when you are on a scientific article publisher website (e.g. Springer), it will log you into Ariane automatically. Ariane grants you access to the article without having to pay if the university has an agreement with the publisher.&lt;/p&gt;

&lt;h1 id=&quot;be-social&quot;&gt;Be social&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Like our Facebook page &lt;a href=&quot;https://www.facebook.com/norlab.ulaval/&quot;&gt;norlab.ulaval&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Follow the LinkedIn page &lt;a href=&quot;https://www.linkedin.com/company/norlab/&quot;&gt;Norlab&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Subscribe to our YouTube channel &lt;a href=&quot;https://www.youtube.com/channel/UCh9G8xpr72lBiyWyBKXBTXA&quot;&gt;norlab&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Ask to be added on our ResearchGate &lt;a href=&quot;https://www.researchgate.net/lab/Northern-Robotics-Laboratory-Norlab-Francois-Pomerleau&quot;&gt;laboratory page&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;In general, reshare news from the lab to ensure maximum impact of our work&lt;/li&gt;
&lt;/ul&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="howto" /><category term="grants" /><category term="salary" /><category term="students" /><summary type="html">Welcome to the laboratory! It will take a couple of weeks to get you up and running in the lab, so why not use that time to explore different sources of information that will save you time later.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3Enil,%20%22feature%22=%3Enil%7D" /></entry><entry><title type="html">Dominic Baril</title><link href="https://norlab.ulaval.ca/people/d_baril/" rel="alternate" type="text/html" title="Dominic Baril" /><published>2019-05-05T00:00:00+02:00</published><updated>2019-05-05T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/people/d_baril</id><content type="html" xml:base="https://norlab.ulaval.ca/people/d_baril/">&lt;p&gt;Dominic Baril is a master’s student at Norlab.
He graduated in mechanical engineering at Sherbrooke University in 2018. To complete his bachelor’s, he worked on a major robotic project in collaboration with &lt;a href=&quot;https://www.exonetik.com/&quot; target=&quot;_blank&quot;&gt;Exonetik&lt;/a&gt;, a company that produces magnetorheological actuators. The project (named &lt;a href=&quot;https://www.facebook.com/expomegageniale/videos/2039870909411790/&quot; target=&quot;_blank&quot;&gt;ASIMOV&lt;/a&gt;) consisted in designing, manufacturing and controlling 2 identic and mechanically independent robotic arms. The arms are able to simultaneously reprodouce a haptic feeling in the other when touching objects. He also realised an internship in the &lt;a href=&quot;https://https://www.createk.co/&quot; target=&quot;_blank&quot;&gt;Createk&lt;/a&gt; laboratory under the supervision of Pr. &lt;a href=&quot;https://alexandregirard.ca/&quot; target=&quot;_blank&quot;&gt;Alexandre Girard&lt;/a&gt;. He was tasked with integrating a 1:10 scaled robotic car (based on the MIT’s &lt;a href=&quot;http://fast.scripts.mit.edu/racecar/&quot; target=&quot;_blank&quot;&gt;RACECAR&lt;/a&gt;). The car was outfitted with the standard autonomous car sensors and Dominic created a control architecture (using ROS) for the robot. 
His work in Norlab will be related to the control of an autonomous robot in a harsh winter environment.&lt;/p&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Bachelor’s degree in mechanical Engineering at Sherbrooke University, 2018&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Dominic Baril</name><email>dominic.baril.1@ulaval.ca</email></author><summary type="html">Dominic Baril is a master’s student at Norlab. He graduated in mechanical engineering at Sherbrooke University in 2018. To complete his bachelor’s, he worked on a major robotic project in collaboration with Exonetik, a company that produces magnetorheological actuators. The project (named ASIMOV) consisted in designing, manufacturing and controlling 2 identic and mechanically independent robotic arms. The arms are able to simultaneously reprodouce a haptic feeling in the other when touching objects. He also realised an internship in the Createk laboratory under the supervision of Pr. Alexandre Girard. He was tasked with integrating a 1:10 scaled robotic car (based on the MIT’s RACECAR). The car was outfitted with the standard autonomous car sensors and Dominic created a control architecture (using ROS) for the robot. His work in Norlab will be related to the control of an autonomous robot in a harsh winter environment.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/d_baril.jpg%22,%20%22teaser%22=%3E%22/people/d_baril_avatar.jpg%22%7D" /></entry><entry><title type="html">Dominic Baril</title><link href="https://norlab.ulaval.ca/people/d_baril_fr/" rel="alternate" type="text/html" title="Dominic Baril" /><published>2019-05-05T00:00:00+02:00</published><updated>2019-05-05T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/people/d_baril_fr</id><content type="html" xml:base="https://norlab.ulaval.ca/people/d_baril_fr/">&lt;p&gt;Dominic Baril est un étudiant à la maîtrise au sein du Norlab.
Il a gardué du baccalauréat en génie mécanique à l’Université de Sherbrooke en 2018. Afin de compléter son baccalauréat, il a participé à un projet majeur en robotique en collaboration avec &lt;a href=&quot;https://www.exonetik.com/&quot; target=&quot;_blank&quot;&gt;Exonetik&lt;/a&gt;, une entreprise qui produit des actionneurs à fluides magnétorhéologiques. Le projet (dénommé &lt;a href=&quot;https://www.facebook.com/expomegageniale/videos/2039870909411790/&quot; target=&quot;_blank&quot;&gt;ASIMOV&lt;/a&gt;) consistait en la conception, la fabrication et le contrôle de 2 bras robotiques identiques et mécaniquement indépendants. Les bras sont capables de simultanément reproduire un sentiment haptique dans l’autre lorsqu’ils touchent à des objets. Il a également réalisé un stage au sein du laboratoire &lt;a href=&quot;https://https://www.createk.co/&quot; target=&quot;_blank&quot;&gt;Createk&lt;/a&gt; sous la supervision du Pr. &lt;a href=&quot;https://alexandregirard.ca/&quot; target=&quot;_blank&quot;&gt;Alexandre Girard&lt;/a&gt;. Il avait la tâche d’intégrer une voiture robotique à échelle 1:10 (basée sur le &lt;a href=&quot;http://fast.scripts.mit.edu/racecar/&quot; target=&quot;_blank&quot;&gt;RACECAR&lt;/a&gt; du MIT). La voiture a été équipée avec les capteurs standards des voitures autonomes et Dominic a réalisé un architecture de contrôle (fonctionnant avec ROS) pour le robot.
Son travail au Norlab sera en lien avec le contrôle d’un robot autonome en environnement hivernal difficile.&lt;/p&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Baccalauréat en génie mécanique à l’Université de Sherbrooke, 2018&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Dominic Baril</name><email>dominic.baril.1@ulaval.ca</email></author><summary type="html">Dominic Baril est un étudiant à la maîtrise au sein du Norlab. Il a gardué du baccalauréat en génie mécanique à l’Université de Sherbrooke en 2018. Afin de compléter son baccalauréat, il a participé à un projet majeur en robotique en collaboration avec Exonetik, une entreprise qui produit des actionneurs à fluides magnétorhéologiques. Le projet (dénommé ASIMOV) consistait en la conception, la fabrication et le contrôle de 2 bras robotiques identiques et mécaniquement indépendants. Les bras sont capables de simultanément reproduire un sentiment haptique dans l’autre lorsqu’ils touchent à des objets. Il a également réalisé un stage au sein du laboratoire Createk sous la supervision du Pr. Alexandre Girard. Il avait la tâche d’intégrer une voiture robotique à échelle 1:10 (basée sur le RACECAR du MIT). La voiture a été équipée avec les capteurs standards des voitures autonomes et Dominic a réalisé un architecture de contrôle (fonctionnant avec ROS) pour le robot. Son travail au Norlab sera en lien avec le contrôle d’un robot autonome en environnement hivernal difficile.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/d_baril.jpg%22,%20%22teaser%22=%3E%22/people/d_baril_avatar.jpg%22%7D" /></entry><entry><title type="html">How to set a static transform with our interactive RVIZ tool</title><link href="https://norlab.ulaval.ca/research/how-to-visually-setup-static-tf/" rel="alternate" type="text/html" title="How to set a static transform with our interactive RVIZ tool" /><published>2019-04-30T00:00:00+02:00</published><updated>2019-04-30T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/research/how-to-visually-setup-static-tf</id><content type="html" xml:base="https://norlab.ulaval.ca/research/how-to-visually-setup-static-tf/">&lt;p&gt;Sometimes, there is a need to quickly set up a static transform in ROS.
To avoid manually searching for translation and rotation parameters, we have written this minimalistic tool that allows us to do it a more convenient, click-and-drag way.&lt;/p&gt;

&lt;h1 id=&quot;the-problem&quot;&gt;The Problem&lt;/h1&gt;

&lt;p&gt;The physical configuration of a robot can change or a new sensor is added.
Since this configuration is reflected by the ROS TF system, the corresponding static transform needs to be updated.
The classical approach would be trial-and-error with the comand line &lt;code class=&quot;highlighter-rouge&quot;&gt;rosrun tf static_transform_publisher [params]&lt;/code&gt;, looking for the right numbers.
It is tedious, unnecessary and there is a better way to do this.&lt;/p&gt;

&lt;h1 id=&quot;solution---interactive-static-transform-tool&quot;&gt;Solution - Interactive Static Transform tool&lt;/h1&gt;

&lt;p&gt;Following the &lt;a href=&quot;http://wiki.ros.org/rviz/Tutorials/Interactive%20Markers%3A%20Getting%20Started&quot;&gt;RVIZ Interactive Marker Tutorial&lt;/a&gt;, a simple tool was written.
It helps in finding a transformation between two TF frames by providing
an RVIZ interactive marker. 
Its usage is straightforward:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Set your parent and child frame names in the &lt;a href=&quot;https://github.com/norlab-ulaval/norlab_imu_tools/blob/master/launch/interactive_static_transform_publisher.launch&quot;&gt;launch file&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Run the launch file and also open the RVIZ.&lt;/li&gt;
  &lt;li&gt;The initial transformation is an identity, but you can modify it by displaying
the interactive marker and moving it around.&lt;/li&gt;
  &lt;li&gt;The marker also offers a context menu, the only command which is there
prints the current transform value in the form of the &lt;code class=&quot;highlighter-rouge&quot;&gt;static_transform_publisher&lt;/code&gt;
rosrun command.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The launch file and the code is placed within the &lt;a href=&quot;https://github.com/norlab-ulaval/norlab_imu_tools&quot;&gt;norlab_imu_tools&lt;/a&gt; package:&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;launch&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;node&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;pkg=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;norlab_imu_tools&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;interactive_static_transform_publisher.py&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;interactive_static_transform_publisher_node&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;output=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;screen&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;child_frame&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;moving_frame&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;parent_frame&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;base_link&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tf_publish_period_in_sec&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.1&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/node&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/launch&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The final transform output can be copied and pasted into a terminal or just used to set a new launch file:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[INFO] [1556661102.899894]: The equivalent static transform command:
[INFO] [1556661102.902316]: rosrun tf static_transform_publisher 1.92549085617 0.0 1.12673556805 0.327530413866 -0.155546739697 -0.399795621634 0.841839015484 base_link moving_frame 100
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Vladimír Kubelka</name><email>vladimir.kubelka.1@ulaval.ca</email></author><category term="howto" /><category term="ros" /><category term="transform" /><category term="rviz" /><summary type="html">Sometimes, there is a need to quickly set up a static transform in ROS. To avoid manually searching for translation and rotation parameters, we have written this minimalistic tool that allows us to do it a more convenient, click-and-drag way.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22/rviz_interactive_tf_tool_teaser.jpg%22,%20%22feature%22=%3E%22/rviz_interactive_tf_tool.jpg%22%7D" /></entry><entry><title type="html">Forest Mapping</title><link href="https://norlab.ulaval.ca/research/forest-mapping/" rel="alternate" type="text/html" title="Forest Mapping" /><published>2019-04-17T00:00:00+02:00</published><updated>2019-04-17T00:00:00+02:00</updated><id>https://norlab.ulaval.ca/research/forest-mapping</id><content type="html" xml:base="https://norlab.ulaval.ca/research/forest-mapping/">&lt;h1 id=&quot;quick-facts&quot;&gt;Quick facts:&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;1.4 hectares of forest mapped with a &lt;a href=&quot;https://www.clearpathrobotics.com/husky-unmanned-ground-vehicle-robot/&quot;&gt;Clearpath Husky&lt;/a&gt; and a &lt;a href=&quot;https://velodynelidar.com/hdl-32e.html&quot;&gt;Velodyne HDL-32E&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;943 trees were manually segmented in point clouds, and their diameter and species was identified on the field.&lt;/li&gt;
  &lt;li&gt;Biggest dataset for 3D forest mapping and tree diameter measurements&lt;/li&gt;
  &lt;li&gt;We tested various diameter estimation methods&lt;/li&gt;
  &lt;li&gt;Part of the &lt;a href=&quot;https://www.researchgate.net/project/Automated-forestry-and-logging-operations&quot;&gt;Automated Forestry and Logging Operations project&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Our preprint is available &lt;a href=&quot;https://arxiv.org/abs/1904.05281&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;video&quot;&gt;Video&lt;/h1&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/dJ8eIOvcGPw&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Tremblay2019&quot;&gt;Tremblay, J.-F., Béland, M., Pomerleau, F., Gagnon, R., &amp;amp; Giguère, P. (2019). Automatic 3D Mapping for Tree Diameter Measurements in Inventory Operations. In &lt;i&gt;preprint, ArXiv. Submitted to Field and Service Robotics (FSR)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Tremblay2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Jean-François Tremblay</name></author><category term="project" /><category term="mapping" /><category term="forestry" /><category term="lidar" /><summary type="html">Quick facts: 1.4 hectares of forest mapped with a Clearpath Husky and a Velodyne HDL-32E 943 trees were manually segmented in point clouds, and their diameter and species was identified on the field. Biggest dataset for 3D forest mapping and tree diameter measurements We tested various diameter estimation methods Part of the Automated Forestry and Logging Operations project Our preprint is available here</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22projects/forest_mapping_feature.jpg%22,%20%22teaser%22=%3E%22projects/forest_mapping_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">Three articles accepted at ICRA 2019!</title><link href="https://norlab.ulaval.ca/news/icra19/" rel="alternate" type="text/html" title="Three articles accepted at ICRA 2019!" /><published>2019-03-04T00:00:00+01:00</published><updated>2019-03-04T00:00:00+01:00</updated><id>https://norlab.ulaval.ca/news/icra19</id><content type="html" xml:base="https://norlab.ulaval.ca/news/icra19/">&lt;p&gt;We are happy to announce that we have three accepted publications at the &lt;a href=&quot;https://www.icra2019.org/&quot;&gt;2019 International Conference on Robotics and Automation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We will present our latest results on lidar modeling &lt;a href=&quot;#Laconte2019&quot;&gt;(Laconte, Deschênes, Labussière, &amp;amp; Pomerleau, 2019)&lt;/a&gt;, learning algorithm for covariance estimation &lt;a href=&quot;#Landry2019&quot;&gt;(Landry, Pomerleau, &amp;amp; Giguère, 2019)&lt;/a&gt;, and a survey on different robust cost functions applied to ICP (Iterative Closest Point) &lt;a href=&quot;#Babin2019&quot;&gt;(Babin, Giguère, &amp;amp; Pomerleau, 2019)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;More details, and hopefully videos to come!&lt;/p&gt;

&lt;h1 id=&quot;our-articles&quot;&gt;Our articles&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Landry2019&quot;&gt;Landry, D., Pomerleau, F., &amp;amp; Giguère, P. (2019). CELLO-3D: Estimating the Covariance of ICP in the Real World. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Landry2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Babin2019&quot;&gt;Babin, P., Giguère, P., &amp;amp; Pomerleau, F. (2019). Analysis of Robust Functions for Registration Algorithms. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Laconte2019&quot;&gt;Laconte, J., Deschênes, S.-P., Labussière, M., &amp;amp; Pomerleau, F. (2019). Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Laconte2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="conference" /><summary type="html">We are happy to announce that we have three accepted publications at the 2019 International Conference on Robotics and Automation.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22/news/icra19/icra19_teaser.jpg%22%7D" /></entry><entry><title type="html">Vladimír Kubelka</title><link href="https://norlab.ulaval.ca/people/v_kubelka/" rel="alternate" type="text/html" title="Vladimír Kubelka" /><published>2019-02-21T00:00:00+01:00</published><updated>2019-02-21T00:00:00+01:00</updated><id>https://norlab.ulaval.ca/people/v_kubelka</id><content type="html" xml:base="https://norlab.ulaval.ca/people/v_kubelka/">&lt;p&gt;Vladimír has received his master’s degree in Cybernetics and Robotics from the Czech Technical University in Prague (2013). The experiments for the master’s thesis were performed at the ASL lab (ETH Zurich) during his visiting student internship. After that, he continued as a Ph.D. student at CTU and focused on the problem of data fusion and state estimation for ground robots in harsh conditions. He had the opportunity to participate in two EU-funded  search and rescue projects &lt;a href=&quot;http://www.nifti.eu/&quot; target=&quot;_blank&quot;&gt;NIFTi&lt;/a&gt; and &lt;a href=&quot;http://www.tradr-project.eu/&quot; target=&quot;_blank&quot;&gt;TRADR&lt;/a&gt;. These projects offered real-world scenarios to test the localization algorithms. The main challenge were sensor outages (because of dark areas, smoke), unstable terrain and semi-structured environments (e.g., earthquake aftermath). He defended his Ph.D. thesis in 2018 (supervised by &lt;a href=&quot;https://sites.google.com/site/reinsmic&quot; target=&quot;_blank&quot;&gt;Michal Reinstein&lt;/a&gt; and &lt;a href=&quot;http://cmp.felk.cvut.cz/~svoboda/&quot; target=&quot;_blank&quot;&gt;Tomáš Svoboda&lt;/a&gt;) and enrolled as a postdoc fellow with the NORLAB. The Canadian winter brings new challenges for the ground mobile robots: deep snow, adversary conditions for optical sensors and changing terrain caused by wind and blizzards.&lt;/p&gt;

&lt;p&gt;His research topics are sensor fusion and state estimation for mobile ground robots. He is interested in the problems related to deployment of robots in harsh environments.&lt;/p&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/file/d/12CeiSDOmbEq74qiiiJG8GhfCNXyB24Cp/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Ph.D.&lt;/a&gt; in Artificial Intelligence and Biocybernetics - &lt;a href=&quot;https://www.cvut.cz/en&quot; target=&quot;_blank&quot;&gt;CTU in Prague&lt;/a&gt;, 2018&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/file/d/1kA04kmKFjoW7k5Jas_8xn0ivKFFsQRWb/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Ing.&lt;/a&gt; in Cybernetics and Robotics (Air and Space Systems) - &lt;a href=&quot;https://www.cvut.cz/en&quot; target=&quot;_blank&quot;&gt;CTU in Prague&lt;/a&gt;, 2013&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/file/d/18vtdAQDF4s1qFMwPujufjYuyXQ_VlfzI/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Bc.&lt;/a&gt; in Electrical Engineering (Cybernetics and Measurement) - &lt;a href=&quot;https://www.cvut.cz/en&quot; target=&quot;_blank&quot;&gt;CTU in Prague&lt;/a&gt;, 2011&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;h2 class=&quot;bibliography&quot;&gt;Journal Articles&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;kubelka2016improving&quot;&gt;Kubelka, V., Reinstein, M., &amp;amp; Svoboda, T. (2016). Improving multimodal data fusion for mobile robots by trajectory smoothing. &lt;i&gt;Robotics and Autonomous Systems&lt;/i&gt;, &lt;i&gt;84&lt;/i&gt;, 88–96.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/kubelka2016improving/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Pomerleau2015e&quot;&gt;Kubelka, V., Oswald, L., Pomerleau, F., Colas, F., Svoboda, T., &amp;amp; Reinstein, M. (2015). Robust data fusion of multimodal sensory information for mobile robots. &lt;i&gt;Journal of Field Robotics&lt;/i&gt;, &lt;i&gt;32&lt;/i&gt;(4), 447–473.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Pomerleau2015e/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;simanek2015evaluation&quot;&gt;Simanek, J., Reinstein, M., &amp;amp; Kubelka, V. (2015). Evaluation of the EKF-based estimation architectures for data fusion in mobile robots. &lt;i&gt;IEEE/ASME Transactions on Mechatronics&lt;/i&gt;, &lt;i&gt;20&lt;/i&gt;(2), 985–990.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/simanek2015evaluation/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;simanek2015improving&quot;&gt;Simanek, J., Kubelka, V., &amp;amp; Reinstein, M. (2015). Improving multi-modal data fusion by anomaly detection. &lt;i&gt;Autonomous Robots&lt;/i&gt;, &lt;i&gt;39&lt;/i&gt;(2), 139–154.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/simanek2015improving/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;
&lt;h2 class=&quot;bibliography&quot;&gt;Conference Articles&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Dandurand2019&quot;&gt;Dandurand, P., Babin, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Predicting GNSS satellite visibility from dense point clouds. In &lt;i&gt;preprint, ArXiv. Submitted to Field and Service Robotics (FSR)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Dandurand2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Babin2019a&quot;&gt;Babin, P., Dandurand, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Large-scale 3D Mapping of Sub-arctic Forests. In &lt;i&gt;preprint, ArXiv. Submitted to Field and Service Robotics (FSR)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2019a/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;jirkuu2016wifi&quot;&gt;Jirku, M., Kubelka, V., &amp;amp; Reinstein, M. (2016). WiFi localization in 3D. In &lt;i&gt;2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)&lt;/i&gt; (pp. 4551–4557). IEEE.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/jirkuu2016wifi/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;kruijff2016deployment&quot;&gt;Kruijff-Korbayová, I., Freda, L., Gianni, M., Ntouskos, V., Hlaváč, V., Kubelka, V., … others. (2016). Deployment of ground and aerial robots in earthquake-struck amatrice in italy (brief report). In &lt;i&gt;2016 IEEE international symposium on safety, security, and rescue robotics (SSRR)&lt;/i&gt; (pp. 278–279). IEEE.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/kruijff2016deployment/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;kubelka2014combining&quot;&gt;Kubelka, V., &amp;amp; Reinstein, M. (2014). Combining Complementary Motion Estimation Approaches to Increase Reliability in Urban Search &amp;amp; Rescue Missions. In &lt;i&gt;International Workshop on Modelling and Simulation for Autonomous Systems&lt;/i&gt; (pp. 347–356). Springer, Cham.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/kubelka2014combining/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;reinstein2013terrain&quot;&gt;Reinstein, M., Kubelka, V., &amp;amp; Zimmermann, K. (2013). Terrain adaptive odometry for mobile skid-steer robots. In &lt;i&gt;2013 IEEE International Conference on Robotics and Automation&lt;/i&gt; (pp. 4706–4711). IEEE.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/reinstein2013terrain/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;kubelka2012complementary&quot;&gt;Kubelka, V., &amp;amp; Reinstein, M. (2012). Complementary filtering approach to orientation estimation using inertial sensors only. In &lt;i&gt;2012 IEEE international conference on robotics and automation&lt;/i&gt; (pp. 599–605). IEEE.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/kubelka2012complementary/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Vladimír Kubelka</name><email>vladimir.kubelka.1@ulaval.ca</email></author><summary type="html">Vladimír has received his master’s degree in Cybernetics and Robotics from the Czech Technical University in Prague (2013). The experiments for the master’s thesis were performed at the ASL lab (ETH Zurich) during his visiting student internship. After that, he continued as a Ph.D. student at CTU and focused on the problem of data fusion and state estimation for ground robots in harsh conditions. He had the opportunity to participate in two EU-funded search and rescue projects NIFTi and TRADR. These projects offered real-world scenarios to test the localization algorithms. The main challenge were sensor outages (because of dark areas, smoke), unstable terrain and semi-structured environments (e.g., earthquake aftermath). He defended his Ph.D. thesis in 2018 (supervised by Michal Reinstein and Tomáš Svoboda) and enrolled as a postdoc fellow with the NORLAB. The Canadian winter brings new challenges for the ground mobile robots: deep snow, adversary conditions for optical sensors and changing terrain caused by wind and blizzards.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/v_kubelka.jpg%22,%20%22teaser%22=%3E%22/people/v_kubelka_avatar.jpg%22%7D" /></entry></feed>