<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://norlab.ulaval.ca/atom.xml" rel="self" type="application/atom+xml" /><link href="https://norlab.ulaval.ca/" rel="alternate" type="text/html" /><updated>2020-04-16T11:34:39-04:00</updated><id>https://norlab.ulaval.ca/atom.xml</id><title type="html">Northern Robotics Laboratory</title><subtitle>Website showcasing research and news from the Northern Robotics Laboratory, Laval University</subtitle><entry><title type="html">DARPA - SUBTERRANEAN CHALLENGE</title><link href="https://norlab.ulaval.ca/research/darpa-subt-urban/" rel="alternate" type="text/html" title="DARPA - SUBTERRANEAN CHALLENGE" /><published>2020-04-14T00:00:00-04:00</published><updated>2020-04-14T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/research/darpa-subt-urban</id><content type="html" xml:base="https://norlab.ulaval.ca/research/darpa-subt-urban/">&lt;p&gt;&lt;a href=&quot;https://www.subtchallenge.com&quot;&gt;DARPA - Subterranean Challenge (DARPA-SubT)&lt;/a&gt; is an international robotics competition focusing on autonomy, perception, networking, mobility technologies, and mapping underground areas in unpredictable conditions. This challenge connects the best researchers and teams to push the boundaries of what is possible in the field of mobile robotics. This competition consists of four circuits: tunnel systems, urban underground, cave networks and a combination of all of these together. It is also divided into the System track and the Virtual track and intended for both DARPA-funded and self-funded teams.&lt;/p&gt;

&lt;p&gt;Norlab competed in the System track of the urban circuit as a member of the CTU-CRAS-NORLAB team with the &lt;a href=&quot;https://robotics.fel.cvut.cz/cras&quot;&gt;Center for Robotics and Autonomous Systems (CRAS)&lt;/a&gt; from the Czech Technical University (CTU). Our researches could participate in the competition with a Husky robot thanks to generous funding by General Dynamics Land Systems – Canada. Together with the wheeled Husky robot, three tracked Absolem robots, three hexapod robots and two multi-rotor drones were deployed in the competition.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/images/projects/subt_urban/robots_entry.jpg&quot; style=&quot;width: 40%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;The System track consisted of two courses, the Alpha Course and the Beta Course, each of them would be attempted twice. They were both situated in the underground of an &lt;a href=&quot;https://en.wikipedia.org/wiki/WNP-3_and_WNP-5&quot; title=&quot;Wikipedia&quot;&gt;unfinished nuclear plant&lt;/a&gt; close to Elma, Washington, in the United States. In every course, there were 20 hidden artifacts to be found by the robots in less than sixty minutes. The artifacts consisted of manikins (heated and wearing reflective jackets and hats), red backpacks, working cell phones (video, Wi-Fi, and Bluetooth), CO2 gas and air vents. The position of the artifacts would change between the two possible attempts. The goal was to detect and localize as many artifacts as possible.&lt;/p&gt;

&lt;p&gt;Our team deployed a combination of robots with different types of locomotion to be prepared for various obstacles expected in the man-made underground. The core of the robotic team consisted of three tracked robots that were able to navigate stairs and therefore explore multiple floors. Norlab provided a Husky robot allowing fast exploration on a single floor. Finally, drones and walking hexapods extended the reach of our team by either flying further (drones) or carrying radio modules (hexapods) extending the communication range. Our team chose lidars to be its primary mean of mapping and localization which also went well with the research focus of Norlab. Together with the thorough preparation of the artifact detectors on the Czech side and intensive testing, we were able to accurately localize artifacts the robots encountered. Motivated by the performance of the winning team, we now focus on improving the speed of exploration through better cooperation between the robots and higher autonomy.&lt;/p&gt;

&lt;h1 id=&quot;team&quot;&gt;Team&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Principal Investigator&lt;/strong&gt;: &lt;a href=&quot;http://cmp.felk.cvut.cz/~svoboda/&quot;&gt;Tomas Svoboda&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scientific Lead - 3D mapping&lt;/strong&gt;: &lt;a href=&quot;../../people/f_pomerleau/&quot;&gt;François Pomerleau&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Researchers - 3D mapping&lt;/strong&gt;: &lt;a href=&quot;../../people/v_kubelka&quot;&gt;Vladimír Kubelka&lt;/a&gt;, &lt;a href=&quot;../../people/m_vaidis&quot;&gt;Maxime Vaidis&lt;/a&gt;, &lt;a href=&quot;../../people/d_baril&quot;&gt;Dominic Baril&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://robotics.fel.cvut.cz/cras/darpa-subt/&quot;&gt;Team web page from CTU&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/projects/subt_urban/robots_not_ready.jpg&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;During this exciting competition, we also managed to make a few interesting stunts. One of them being the tracked Absolem robot running over and partially crushing the plastic hexapod robot. Another exciting stunt was overturning the Absolem robot on its back while climbing stairs. Also, we broke several drones, and in the end, one burned. Despite all these hardships, the team managed to score 10 points and took an amazing first place as a self-funded team and a third place among all teams.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/projects/subt_urban/prize.jpg&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;video&quot;&gt;Video&lt;/h1&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/u_7DwnYTf-I&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/4hdeFdt0woc?start=14689&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/V9tzKF0hxnE?start=7475&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/O_c7P1TJKM4?start=15215&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/SgPirHYszzw?start=5997&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/rTP64z52JFE&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/3tqBO0HbLHY&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;

&lt;h1 id=&quot;media-coverage&quot;&gt;Media Coverage&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;IEEE SPECTRUM - &lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/robotics-teams-prepare-darpa-subt-challenge-urban-circuit&quot;&gt;How Robotics Teams Prepared for DARPA’s SubT Challenge: Urban Circuit&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;IEEE SPECTRUM - &lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/video-friday-quadruped-robot-locomotion-skills&quot;&gt;Video Friday: Quadruped Robot Learns Locomotion Skills by Imitating Dog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;THE ROBOTREPORT - &lt;a href=&quot;https://www.therobotreport.com/team-costar-wins-urban-circuit-of-darpa-subterranean-challenge/&quot;&gt;Team CoSTAR wins Urban Circuit of DARPA Subterranean Challenge&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;GEEKWIRE - &lt;a href=&quot;https://www.geekwire.com/2020/robots-masters-take-nuclear-plant-darpas-subterranean-challenge/&quot;&gt;Robots and their masters take over nuclear plant for DARPA’s Subterranean Challenge&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;ROS Discourse - &lt;a href=&quot;https://discourse.ros.org/t/subt-challenge-urban-circuit-overview/13635&quot;&gt;SubT Challenge Urban Circuit Overview&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;The Vidette - &lt;a href=&quot;https://www.thevidette.com/news/robots-creeping-around-satsop-hoping-to-find-millions-in-prize-money/&quot;&gt;Robots creeping around Satsop hoping to find millions in prize money&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;ULaval (french) - &lt;a href=&quot;https://nouvelles.ulaval.ca/recherche/des-robots-dans-les-dedales-dune-centrale-nucleaire-abandonnee-a7a44f1b225efdc51eb5c4d657082e0a?sourceOrganizationKey=ulaval&quot;&gt;Des robots dans les dédales d’une centrale nucléaire abandonnée&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;ULaval (french) - &lt;a href=&quot;https://www.fsg.ulaval.ca/faculte/actualites/norlab-et-ses-partenaires-se-distinguent-au-darpa-subterranean-challenge-3400/&quot;&gt;Norlab et ses partenaires se distinguent au DARPA Subterranean Challenge&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;DARPA NEWS - &lt;a href=&quot;https://www.darpa.mil/news-events/2020-02-27&quot;&gt;Teams CoSTAR and BARCS Take Top Spots in DARPA Subterranean Challenge Urban Circuit&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;DARPA NEWS - &lt;a href=&quot;https://www.darpa.mil/news-events/2020-01-10&quot;&gt;DARPA Names Qualifiers for the Subterranean Challenge Urban Circuit&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;NEWSTROTTEUR (french) - &lt;a href=&quot;https://newstrotteur.fr/2020/02/28/des-robots-prennent-le-controle-dune-centrale-nucleaire-pour-le-defi-souterrain-de-la-darpa-newstrotteur/&quot;&gt;Des robots prennent le contrôle d’une centrale nucléaire pour le défi souterrain de la DARPA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;MAGNETPRESS (czech) - &lt;a href=&quot;https://www.vydavatelstvo-mps.sk/atm/6800-robotici-z-fel-cvut-uspeli-v-soutezi.html&quot;&gt;Robotici z FEL ČVUT uspěli v soutěži&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;CZECH WEBSITE: CTU NEWS (czech) - &lt;a href=&quot;https://aktualne.cvut.cz/stalo-se/20200228-robotici-z-fakulty-elektrotechnicke-vyhrali-svetovou-soutez-darpa-subterranean&quot;&gt;Robotici Z Fakulty Elektrotechnické Vyhráli Světovou Soutěž Darpa Subterranean Challenge Urban Circuit Mezi Nesponzorovanými Týmy A Obsadili Celkově 3. Místo&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;SCIENCEMAG (czech) - &lt;a href=&quot;https://sciencemag.cz/robotici-z-cvut-vyhrali-svetovou-soutez-darpa/&quot;&gt;Robotici z ČVUT vyhráli světovou soutěž DARPA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;DRONEWEB (czech) - &lt;a href=&quot;http://www.droneweb.cz/aktuality/item/345-drony-autonomni-fel-cvut-darpa-soutez&quot;&gt;České robotické drony budou soutěžit v americkém podzemí&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jana Bartakova</name></author><category term="project" /><category term="darpa" /><category term="competition" /><category term="subterranean" /><category term="robots" /><summary type="html">DARPA - Subterranean Challenge (DARPA-SubT) is an international robotics competition focusing on autonomy, perception, networking, mobility technologies, and mapping underground areas in unpredictable conditions. This challenge connects the best researchers and teams to push the boundaries of what is possible in the field of mobile robotics. This competition consists of four circuits: tunnel systems, urban underground, cave networks and a combination of all of these together. It is also divided into the System track and the Virtual track and intended for both DARPA-funded and self-funded teams.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/projects/subt_urban/subt_main.jpg%22,%20%22teaser%22=%3E%22/projects/subt_urban/subt_teaser.jpg%22%7D" /></entry><entry><title type="html">The Montmorency dataset</title><link href="https://norlab.ulaval.ca/research/montmorencydataset/" rel="alternate" type="text/html" title="The Montmorency dataset" /><published>2020-01-25T00:00:00-05:00</published><updated>2020-01-25T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/research/montmorencydataset</id><content type="html" xml:base="https://norlab.ulaval.ca/research/montmorencydataset/">&lt;p&gt;Under construction&lt;/p&gt;

&lt;p&gt;The dataset in now available for download on &lt;a href=&quot;https://academictorrents.com/details/cf39b5c4285f20c3539cbe9f37f6e04cfde10afa&quot;&gt;Academic Torrents&lt;/a&gt;.
This dataset contains the ground truth species, diameter at breast height and position of more than 1000 trees across four forests, as well as 11 trajectories of a lidar-equipped robot going through these forests.
It has been the subject of a publication at the 12th Conference on Field and Service Robotics.&lt;/p&gt;

&lt;p&gt;More details will appear later as this work is still undergoing peer-review.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Tremblay2019&quot;&gt;Tremblay, J.-F., Béland, M., Pomerleau, F., Gagnon, R., &amp;amp; Giguère, P. (2019). Automatic 3D Mapping for Tree Diameter Measurements in Inventory Operations. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Tremblay2019.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a href=&quot;/pdf/Tremblay2019.slides.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-powerpoint&quot;&gt;&lt;/i&gt; Slides&lt;/a&gt;

&lt;a class=&quot;details&quot; href=&quot;/bibliography/Tremblay2019/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Jean-François Tremblay</name></author><category term="project" /><category term="mapping" /><category term="forestry" /><category term="lidar" /><summary type="html">Under construction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22projects/forest_mapping_feature.jpg%22,%20%22teaser%22=%3E%22projects/forest_mapping_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">Our first group photo!</title><link href="https://norlab.ulaval.ca/news/christmas/" rel="alternate" type="text/html" title="Our first group photo!" /><published>2019-12-11T00:00:00-05:00</published><updated>2019-12-11T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/news/christmas</id><content type="html" xml:base="https://norlab.ulaval.ca/news/christmas/">&lt;p&gt;It has been a good year in term of team building and equipment acquisition. 
Next year will most probably reserve us a lot of surprises, but I’m certain that we are ready for new scientific breakthroughs.&lt;/p&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="photo" /><category term="group" /><summary type="html">It has been a good year in term of team building and equipment acquisition. Next year will most probably reserve us a lot of surprises, but I’m certain that we are ready for new scientific breakthroughs.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/news/christmas19/christmas_feature.jpg%22,%20%22teaser%22=%3E%22/news/christmas19/christmas_teaser.jpg%22%7D" /></entry><entry><title type="html">Philippe Babin</title><link href="https://norlab.ulaval.ca/people/p_babin/" rel="alternate" type="text/html" title="Philippe Babin" /><published>2019-09-13T00:00:00-04:00</published><updated>2019-09-13T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/people/p_babin</id><content type="html" xml:base="https://norlab.ulaval.ca/people/p_babin/">&lt;p&gt;Philippe Babin is currently employed at &lt;a href=&quot;https://argo.ai&quot;&gt;Argo AI&lt;/a&gt; a self-driving car startup.
He got a Bachelor’s Degree in Computer Science Engineering at Université Laval in 2017.
Throught his master, he works on improving the robustness of Iterative Closest Point (ICP).
His first project explored the effects of outlier filters (such as M-estimator) on ICP.
He then worked on the development of LIDAR SLAM algorithm for a forest mapping application.&lt;/p&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;M.Sc. in Computer Science - Université Laval, 2017-2019&lt;/li&gt;
  &lt;li&gt;Bachelor’s Degree in Computer Science Engineering - Distinction Profile - Université Laval, 2013-2017&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;h2 class=&quot;bibliography&quot;&gt;Conference Articles&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Dandurand2019&quot;&gt;Dandurand, P., Babin, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Predicting GNSS satellite visibility from dense point clouds. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Dandurand2019.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a class=&quot;details&quot; href=&quot;/bibliography/Dandurand2019/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Babin2019a&quot;&gt;Babin, P., Dandurand, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Large-scale 3D Mapping of Subarctic Forests. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Babin2019a.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a href=&quot;/pdf/Babin2019a.slides.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-powerpoint&quot;&gt;&lt;/i&gt; Slides&lt;/a&gt;

&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2019a/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Babin2019&quot;&gt;Babin, P., Giguère, P., &amp;amp; Pomerleau, F. (2019). Analysis of Robust Functions for Registration Algorithms. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Babin2019.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2019/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;
&lt;h2 class=&quot;bibliography&quot;&gt;Miscellaneous&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Babin2018&quot;&gt;Babin, P., Pomerleau, F., &amp;amp; Giguère, P. (2018). Improving the robustness of registration algorithm in complex environments. Colloque du regroupement FRQNT-REPARTI.&lt;/span&gt;



&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2018/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Philippe Babin</name></author><summary type="html">Philippe Babin is currently employed at Argo AI a self-driving car startup. He got a Bachelor’s Degree in Computer Science Engineering at Université Laval in 2017. Throught his master, he works on improving the robustness of Iterative Closest Point (ICP). His first project explored the effects of outlier filters (such as M-estimator) on ICP. He then worked on the development of LIDAR SLAM algorithm for a forest mapping application.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/p_babin.jpg%22,%20%22teaser%22=%3E%22/people/p_babin_avatar.jpg%22%7D" /></entry><entry><title type="html">Large-scale 3D Mapping of Subarctic Forests</title><link href="https://norlab.ulaval.ca/publications/penality-icp/" rel="alternate" type="text/html" title="Large-scale 3D Mapping of Subarctic Forests" /><published>2019-09-13T00:00:00-04:00</published><updated>2019-09-13T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/publications/penality-icp</id><content type="html" xml:base="https://norlab.ulaval.ca/publications/penality-icp/">&lt;p&gt;The ability to map challenging subarctic environments opens new horizons for robotic deployments in industries such as forestry, surveillance, and open-pit mining. In this paper, we explore possibilities of large-scale lidar mapping in a boreal forest. Computational and sensory requirements with regards to contemporary hardware are considered as well. The lidar mapping is often based on the SLAM technique relying on pose graph optimization, which fuses the Iterative Closest Point (ICP) algorithm, Global Navigation Satellite System (GNSS) positioning, and Inertial Measurement Unit (IMU) measurements.  To handle those sensors directly within the ICP minimization process, we propose an alternative approach of embedding external constraints. Furthermore, a novel formulation of a cost function is presented and cast into the problem of handling uncertainties from GNSS and lidar points. To test our approach, we acquired a large-scale dataset in the Foret Montmorency research forest. We report on the technical problems faced during our winter deployments aiming at building 3D maps using our new cost function. Those maps demonstrate both global and local consistency over 4.1km.&lt;/p&gt;

&lt;h1 id=&quot;quick-facts&quot;&gt;Quick facts:&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;4.1 km of untapped forest trail and snowmobile was mapped using a custom acquisition platform&lt;/li&gt;
  &lt;li&gt;The acquisition platform has a Xsens MTI-30 IMU, a &lt;a href=&quot;https://www.robosense.ai/rslidar/rs-lidar-16&quot;&gt;RoboSense RS-lidar-16&lt;/a&gt; and a REACH RS+ GNSS station&lt;/li&gt;
  &lt;li&gt;All of field test were done at &lt;a href=&quot;https://www.foretmontmorency.ca/en/&quot;&gt;Forêt Montmorency&lt;/a&gt;, a research forest owns by Université Laval.&lt;/li&gt;
  &lt;li&gt;Our paper is available &lt;a href=&quot;https://arxiv.org/abs/1904.07814&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;It was presented at the 12th Conference on Field and Service Robotic, the slides are available &lt;a href=&quot;../../pdf/Babin2019a.slides.pdf&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;video&quot;&gt;Video&lt;/h1&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/t_cBdiPQ1R8&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Babin2019a&quot;&gt;Babin, P., Dandurand, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Large-scale 3D Mapping of Subarctic Forests. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Babin2019a.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a href=&quot;/pdf/Babin2019a.slides.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-powerpoint&quot;&gt;&lt;/i&gt; Slides&lt;/a&gt;

&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2019a/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Philippe Babin</name></author><category term="project" /><category term="icp" /><category term="mapping" /><category term="subarctic" /><category term="snowmobile" /><category term="forestry" /><category term="lidar" /><summary type="html">The ability to map challenging subarctic environments opens new horizons for robotic deployments in industries such as forestry, surveillance, and open-pit mining. In this paper, we explore possibilities of large-scale lidar mapping in a boreal forest. Computational and sensory requirements with regards to contemporary hardware are considered as well. The lidar mapping is often based on the SLAM technique relying on pose graph optimization, which fuses the Iterative Closest Point (ICP) algorithm, Global Navigation Satellite System (GNSS) positioning, and Inertial Measurement Unit (IMU) measurements. To handle those sensors directly within the ICP minimization process, we propose an alternative approach of embedding external constraints. Furthermore, a novel formulation of a cost function is presented and cast into the problem of handling uncertainties from GNSS and lidar points. To test our approach, we acquired a large-scale dataset in the Foret Montmorency research forest. We report on the technical problems faced during our winter deployments aiming at building 3D maps using our new cost function. Those maps demonstrate both global and local consistency over 4.1km.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22projects/penalty_icp_feature.jpg%22,%20%22teaser%22=%3E%22projects/penalty_icp_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">Lambda-Field: A Continuous Counterpart of the Bayesian Occupancy Grid for Risk Assessment</title><link href="https://norlab.ulaval.ca/publications/lambda-field/" rel="alternate" type="text/html" title="Lambda-Field: A Continuous Counterpart of the Bayesian Occupancy Grid for Risk Assessment" /><published>2019-09-02T00:00:00-04:00</published><updated>2019-09-02T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/publications/lambda-field</id><content type="html" xml:base="https://norlab.ulaval.ca/publications/lambda-field/">&lt;p&gt;In a context of autonomous robots, one of the most important tasks is to ensure the safety of the robot and its surrounding.
The risk of navigation is usually said to be the probability of collision.
This notion of risk is not well defined in the literature, especially when dealing with occupancy grids.
The Bayesian occupancy grid is the most used method to deal with complex environments.
However, this is not fitted to compute the risk along a path by its discrete nature.
In this article, we present a new way to store the occupancy of the environment that allows the computation of risk along a given path.
We then define the risk as the force of collision that would occur for a given obstacle.
Using this framework, we are able to generate navigation paths ensuring the safety of the robot.&lt;/p&gt;

&lt;h1 id=&quot;contributions&quot;&gt;Contributions&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;A novel type of map, called Lambda-Field, specially conceived to allow path integrals and thus probabilities of collision;&lt;/li&gt;
  &lt;li&gt;A definition of the risk encountered over a path, specified as the expected force of collision along a path.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;results-in-images&quot;&gt;Results in Images&lt;/h1&gt;

&lt;p&gt;Using the lambda-field, we are able to construct maps where the probability of collision along a path logically arises from the theory.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/publications/lambda-field/maps.png&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The robot (trajectory in blue) maps an urban-like environment and creates a Bayesian Grid as well as a Lambda-Field.
Although the maps are almost the same, the Lambda-Field tends to better store the unstructured obstacles (bushes in this example).&lt;/p&gt;

&lt;h1 id=&quot;in-video&quot;&gt;In Video&lt;/h1&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/ybj8NWWbzAo&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;

&lt;p&gt;&lt;span id=&quot;Laconte2019a&quot;&gt;Laconte, J., Debain, C., Chapuis, R., Pomerleau, F., &amp;amp; Aufrere, R. (2019). Lambda-Field: A Continuous Counterpart of the Bayesian Occupancy Grid for Risk Assessment. In &lt;i&gt;Proceedings of the IEEE International Conference on Intelligent Robots and Systems (IROS)&lt;/i&gt;.&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;links&quot;&gt;Links&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.researchgate.net/publication/331565267_Lambda-Field_A_Continuous_Counterpart_of_the_Bayesian_Occupancy_Grid_for_Risk_Assessment&quot;&gt;Download link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Johann Laconte</name></author><category term="publications" /><category term="traversability" /><category term="lidar" /><category term="mapping" /><summary type="html">In a context of autonomous robots, one of the most important tasks is to ensure the safety of the robot and its surrounding. The risk of navigation is usually said to be the probability of collision. This notion of risk is not well defined in the literature, especially when dealing with occupancy grids. The Bayesian occupancy grid is the most used method to deal with complex environments. However, this is not fitted to compute the risk along a path by its discrete nature. In this article, we present a new way to store the occupancy of the environment that allows the computation of risk along a given path. We then define the risk as the force of collision that would occur for a given obstacle. Using this framework, we are able to generate navigation paths ensuring the safety of the robot.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22publications/lambda-field_teaser.png%22,%20%22feature%22=%3E%22publications/lambda-field_feature.png%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">Norlab is going to Asia!</title><link href="https://norlab.ulaval.ca/news/iros-fsr19/" rel="alternate" type="text/html" title="Norlab is going to Asia!" /><published>2019-06-24T00:00:00-04:00</published><updated>2019-06-24T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/news/iros-fsr19</id><content type="html" xml:base="https://norlab.ulaval.ca/news/iros-fsr19/">&lt;p&gt;We are going to Tokyo (Japan) and Macau (China) with four accepted publications at the &lt;a href=&quot;http://www.srg.mech.keio.ac.jp/fsr2019/&quot;&gt;2019 International Conference on Field and Service Robotics&lt;/a&gt; and one at the &lt;a href=&quot;https://www.iros2019.org/&quot;&gt;2019 IEEE/RSJ International Conference on Intelligent Robots and Systems&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We will present our latest results on lambda-field maps for continuous and risk-aware path planning &lt;a href=&quot;#Laconte2019a&quot;&gt;(Laconte, Debain, Chapuis, Pomerleau, &amp;amp; Aufrere, 2019)&lt;/a&gt;, 3D mapping in subarctic environments &lt;a href=&quot;#Babin2019a&quot;&gt;(Babin, Dandurand, Kubelka, Giguère, &amp;amp; Pomerleau, 2019)&lt;/a&gt;, estimation of GPS satellite visibility given 3D maps &lt;a href=&quot;#Dandurand2019&quot;&gt;(Dandurand, Babin, Kubelka, Giguère, &amp;amp; Pomerleau, 2019)&lt;/a&gt;, automatic forestry inventory based on 3D maps&lt;a href=&quot;#Tremblay2019&quot;&gt;(Tremblay, Béland, Pomerleau, Gagnon, &amp;amp; Giguère, 2019)&lt;/a&gt;, and multi-session lake-shore monitoring based on lidar &lt;a href=&quot;#Pradalier2019&quot;&gt;(Pradalier, Aravecchia, &amp;amp; Pomerleau, 2019)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;More details, and hopefully videos to come!&lt;/p&gt;

&lt;h1 id=&quot;our-articles&quot;&gt;Our articles&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Laconte2019a&quot;&gt;Laconte, J., Debain, C., Chapuis, R., Pomerleau, F., &amp;amp; Aufrere, R. (2019). Lambda-Field: A Continuous Counterpart of the Bayesian Occupancy Grid for Risk Assessment. In &lt;i&gt;Proceedings of the IEEE International Conference on Intelligent Robots and Systems (IROS)&lt;/i&gt;.&lt;/span&gt;



&lt;a class=&quot;details&quot; href=&quot;/bibliography/Laconte2019a/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Dandurand2019&quot;&gt;Dandurand, P., Babin, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Predicting GNSS satellite visibility from dense point clouds. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Dandurand2019.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a class=&quot;details&quot; href=&quot;/bibliography/Dandurand2019/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Babin2019a&quot;&gt;Babin, P., Dandurand, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Large-scale 3D Mapping of Subarctic Forests. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Babin2019a.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a href=&quot;/pdf/Babin2019a.slides.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-powerpoint&quot;&gt;&lt;/i&gt; Slides&lt;/a&gt;

&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2019a/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Tremblay2019&quot;&gt;Tremblay, J.-F., Béland, M., Pomerleau, F., Gagnon, R., &amp;amp; Giguère, P. (2019). Automatic 3D Mapping for Tree Diameter Measurements in Inventory Operations. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Tremblay2019.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a href=&quot;/pdf/Tremblay2019.slides.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-powerpoint&quot;&gt;&lt;/i&gt; Slides&lt;/a&gt;

&lt;a class=&quot;details&quot; href=&quot;/bibliography/Tremblay2019/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Pradalier2019&quot;&gt;Pradalier, C., Aravecchia, S., &amp;amp; Pomerleau, F. (2019). Multi-session lake-shore monitoring in visually challenging conditions. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;



&lt;a class=&quot;details&quot; href=&quot;/bibliography/Pradalier2019/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="conference" /><summary type="html">We are going to Tokyo (Japan) and Macau (China) with four accepted publications at the 2019 International Conference on Field and Service Robotics and one at the 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22/news/iros_fsr19/iros_fsr19_teaser.jpg%22%7D" /></entry><entry><title type="html">Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping</title><link href="https://norlab.ulaval.ca/publications/lidar-bias/" rel="alternate" type="text/html" title="Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping" /><published>2019-05-27T00:00:00-04:00</published><updated>2019-05-27T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/publications/lidar-bias</id><content type="html" xml:base="https://norlab.ulaval.ca/publications/lidar-bias/">&lt;p&gt;In a context of 3D mapping, it is very important to obtain accurate measurements from sensors.
In particular, LIDAR measurements are typically treated as a zero-mean Gaussian distribution.
We show that this assumption leads to predictable localisation drifts, especially when a bias related to measuring obstacles with high incidence angles is not taken into consideration.
Moreover, we present a way to physically understand and model this bias, which generalizes to multiple sensors.
Using an experimental setup, we measured the bias of the Sick LMS-151, Velodyne HDL-32E, and Robosense RS-LiDAR-16 as a function of depth and incidence angle, and showed that the bias can reach 20 cm for high incidence angles.
We then used our model to remove the bias from the measurements, leading to more accurate maps and a reduced localisation drift.&lt;/p&gt;
&lt;h1 id=&quot;contributions&quot;&gt;Contributions&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Physical explanation of a lidar bias caused by the incidence angle of the laser beam on a surface&lt;/li&gt;
  &lt;li&gt;A way to quantify and correct this bias for common LIDARs used in mobile robotics&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;results-in-images&quot;&gt;Results in Images&lt;/h1&gt;

&lt;p&gt;Using our model, we found the following bias for three commonly used LIDARs:
&lt;img src=&quot;/images/publications/lidar-bias/isocurves.jpg&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We were able to remove the bias from the measurements, leading to more accurate maps.
In blue, the map of a tunnel without taking into account the bias.
In red, the same map taking into account the bias and removing it from the measurements.
&lt;img src=&quot;/images/publications/lidar-bias/tunnels.jpg&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;in-video&quot;&gt;In Video&lt;/h1&gt;

&lt;!--&lt;iframe src=&quot;https://www.youtube.com/watch?v=YE-oL7do2HM&quot; style=&quot;width: 100%&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;--&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/YE-oL7do2HM&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;

&lt;p&gt;&lt;span id=&quot;Laconte2019&quot;&gt;Laconte, J., Deschênes, S.-P., Labussière, M., &amp;amp; Pomerleau, F. (2019). Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;links&quot;&gt;Links&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.researchgate.net/publication/328063232_Lidar_Measurement_Bias_Estimation_via_Return_Waveform_Modelling_in_a_Context_of_3D_Mapping&quot;&gt;Download link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Johann Laconte</name></author><category term="publications" /><category term="ICP" /><category term="bias estimation" /><category term="sensor error modelling" /><category term="lidar" /><category term="mapping" /><summary type="html">In a context of 3D mapping, it is very important to obtain accurate measurements from sensors. In particular, LIDAR measurements are typically treated as a zero-mean Gaussian distribution. We show that this assumption leads to predictable localisation drifts, especially when a bias related to measuring obstacles with high incidence angles is not taken into consideration. Moreover, we present a way to physically understand and model this bias, which generalizes to multiple sensors. Using an experimental setup, we measured the bias of the Sick LMS-151, Velodyne HDL-32E, and Robosense RS-LiDAR-16 as a function of depth and incidence angle, and showed that the bias can reach 20 cm for high incidence angles. We then used our model to remove the bias from the measurements, leading to more accurate maps and a reduced localisation drift. Contributions</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22publications/lidar-bias_feature.jpg%22,%20%22teaser%22=%3E%22publications/lidar-bias_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">Predicting GNSS satellite visibility from dense point clouds</title><link href="https://norlab.ulaval.ca/publications/satellite-visibility/" rel="alternate" type="text/html" title="Predicting GNSS satellite visibility from dense point clouds" /><published>2019-05-09T00:00:00-04:00</published><updated>2019-05-09T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/publications/satellite-visibility</id><content type="html" xml:base="https://norlab.ulaval.ca/publications/satellite-visibility/">&lt;p&gt;To help future mobile agents plan their movement in harsh environments,a predictive model has been designed to determine what areas would be favorable for Global Navigation Satellite System (GNSS) positioning. The model is able to predict the number of viable satellites for a GNSS receiver, based on a 3D point cloud map and a satellite constellation. Both occlusion and absorption effects of the environment are considered. A rugged mobile platform was designed to collect data in order to generate the point cloud maps. It was deployed during the Canadian winter known for large amounts of snow and extremely low temperatures. The test environments include a highly dense boreal forest and a university campus with high buildings. The experiment results indicate that the model performs well in both structured and unstructured environments.&lt;/p&gt;

&lt;h1 id=&quot;quick-facts&quot;&gt;Quick facts:&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;This method has been tested in diverse environments such has a highly dense boreal forest and a university campus with high buildings&lt;/li&gt;
  &lt;li&gt;This method is able to differentiate between forest and buildings&lt;/li&gt;
  &lt;li&gt;The hardware used in the paper has been proven to work in sub-arctic environment&lt;/li&gt;
  &lt;li&gt;Our preprint is available &lt;a href=&quot;https://arxiv.org/abs/1904.07837&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;video&quot;&gt;Video&lt;/h1&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/5LdxV1-9rEE&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Dandurand2019&quot;&gt;Dandurand, P., Babin, P., Kubelka, V., Giguère, P., &amp;amp; Pomerleau, F. (2019). Predicting GNSS satellite visibility from dense point clouds. In &lt;i&gt;Proceedings of the Conference on Field and Service Robotics (FSR). Springer Tracts in Advanced Robotics&lt;/i&gt;.&lt;/span&gt;


&lt;a href=&quot;/pdf/Dandurand2019.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt; PDF&lt;/a&gt;


&lt;a class=&quot;details&quot; href=&quot;/bibliography/Dandurand2019/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&lt;/i&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Philippe Dandurand</name></author><category term="project" /><category term="GNSS" /><category term="GPS" /><category term="lidar" /><category term="RTK" /><category term="DGNSS" /><category term="winter" /><category term="mapping" /><category term="uncertainty" /><summary type="html">To help future mobile agents plan their movement in harsh environments,a predictive model has been designed to determine what areas would be favorable for Global Navigation Satellite System (GNSS) positioning. The model is able to predict the number of viable satellites for a GNSS receiver, based on a 3D point cloud map and a satellite constellation. Both occlusion and absorption effects of the environment are considered. A rugged mobile platform was designed to collect data in order to generate the point cloud maps. It was deployed during the Canadian winter known for large amounts of snow and extremely low temperatures. The test environments include a highly dense boreal forest and a university campus with high buildings. The experiment results indicate that the model performs well in both structured and unstructured environments.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22projects/sat_vis_feature.jpg%22,%20%22teaser%22=%3E%22projects/sat_vis_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">Information for New Students</title><link href="https://norlab.ulaval.ca/research/new-students/" rel="alternate" type="text/html" title="Information for New Students" /><published>2019-05-07T00:00:00-04:00</published><updated>2019-05-07T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/research/new-students</id><content type="html" xml:base="https://norlab.ulaval.ca/research/new-students/">&lt;p&gt;Welcome to the laboratory!
It will take a couple of weeks to get you up and running in the lab, so why not use that time to explore different sources of information that will save you time later.&lt;/p&gt;

&lt;h1 id=&quot;register-to-news-feeds&quot;&gt;Register to news feeds&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Register to the magazine &lt;a href=&quot;https://www.universityaffairs.ca&quot;&gt;University Affairs&lt;/a&gt; (free) for general information about the academic life.&lt;/li&gt;
  &lt;li&gt;Register to &lt;a href=&quot;https://www.eu-robotics.net/eurobotics/newsroom/mailing-list&quot;&gt;euRobotics mailing list&lt;/a&gt;  for jobs, software release, call for journal special issues, etc.&lt;/li&gt;
  &lt;li&gt;Register to &lt;a href=&quot;http://duerer.usc.edu/mailman/listinfo.cgi/robotics-worldwide&quot;&gt;robotics-worldwide mailing list&lt;/a&gt;. Same information as euRobotics with a larger audience.&lt;/li&gt;
  &lt;li&gt;Don’t take your work &lt;a href=&quot;http://phdcomics.com/&quot;&gt;too seriously&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;explore-our-github-repo&quot;&gt;Explore our GitHub repo&lt;/h1&gt;

&lt;p&gt;You will need an account on GitHub, so you can be added to the members of&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;
&lt;a href=&quot;https://github.com/norlab-ulaval&quot; target=&quot;_blank&quot; class=&quot;btn&quot;&gt;
&lt;img src=&quot;/images/logos/github.svg&quot; style=&quot;padding-right: 1em; width: 4em; -webkit-filter: invert(100%); filter: invert(100%);&quot; /&gt;
norlab-ulaval
&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;Then, explore the following:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval?utf8=%E2%9C%93&amp;amp;q=poster&amp;amp;type=&amp;amp;language=&quot;&gt;Scientific posters&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval?utf8=%E2%9C%93&amp;amp;q=publication&amp;amp;type=&amp;amp;language=&quot;&gt;Scientific publications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval?utf8=%E2%9C%93&amp;amp;q=mastersProposal&amp;amp;type=&amp;amp;language=&quot;&gt;Master’s proposal&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval?utf8=%E2%9C%93&amp;amp;q=mastersThesis&amp;amp;type=&amp;amp;language=&quot;&gt;Master’s thesis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval/visualIdentity&quot;&gt;Different logos of the lab&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Read our &lt;a href=&quot;https://github.com/norlab-ulaval/latexGoodPractices/blob/master/preamble.tex&quot;&gt;Latex good practices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;little-tip-to-save-you-some-time&quot;&gt;Little tip to save you some time&lt;/h1&gt;
&lt;p&gt;Create a new bookmark on you favorite web browser and copy-paste this script as the url:&lt;/p&gt;
&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;javascript&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;href&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'https://acces.bibl.ulaval.ca/login?qurl='&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+%&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;encodeURIComponent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;href&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);})());&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If you click the bookmark when you are on a scientific article publisher website (e.g. Springer), it will log you into Ariane automatically. Ariane grants you access to the article without having to pay if the university has an agreement with the publisher.&lt;/p&gt;

&lt;h1 id=&quot;be-social&quot;&gt;Be social&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Like our Facebook page &lt;a href=&quot;https://www.facebook.com/norlab.ulaval/&quot;&gt;norlab.ulaval&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Follow the LinkedIn page &lt;a href=&quot;https://www.linkedin.com/company/norlab/&quot;&gt;Norlab&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Subscribe to our YouTube channel &lt;a href=&quot;https://www.youtube.com/channel/UCh9G8xpr72lBiyWyBKXBTXA&quot;&gt;norlab&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Ask to be added on our ResearchGate &lt;a href=&quot;https://www.researchgate.net/lab/Northern-Robotics-Laboratory-Norlab-Francois-Pomerleau&quot;&gt;laboratory page&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;In general, reshare news from the lab to ensure maximum impact of our work&lt;/li&gt;
&lt;/ul&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="howto" /><category term="grants" /><category term="salary" /><category term="students" /><summary type="html">Welcome to the laboratory! It will take a couple of weeks to get you up and running in the lab, so why not use that time to explore different sources of information that will save you time later.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3Enil,%20%22feature%22=%3Enil%7D" /></entry></feed>