<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.1">Jekyll</generator><link href="https://norlab.ulaval.ca/atom.xml" rel="self" type="application/atom+xml" /><link href="https://norlab.ulaval.ca/" rel="alternate" type="text/html" /><updated>2021-11-30T11:33:47-05:00</updated><id>https://norlab.ulaval.ca/atom.xml</id><title type="html">Northern Robotics Laboratory</title><subtitle>Website showcasing research and news from the Northern Robotics Laboratory, Laval University</subtitle><entry><title type="html">Kilometer-scale autonomous navigation in subarctic forests: challenges and lessons learned</title><link href="https://norlab.ulaval.ca/publications/field-report-ltr/" rel="alternate" type="text/html" title="Kilometer-scale autonomous navigation in subarctic forests: challenges and lessons learned" /><published>2021-11-30T00:00:00-05:00</published><updated>2021-11-30T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/publications/field-report-ltr</id><content type="html" xml:base="https://norlab.ulaval.ca/publications/field-report-ltr/">&lt;p&gt;Challenges inherent to autonomous wintertime navigation in forests include lack of reliable a Global Navigation Satellite System (GNSS) signal, low feature contrast, high illumination variations and changing environment. This type of off-road environment is an extreme case of situations autonomous cars could encounter in northern regions. Thus, it is important to understand the impact of this harsh environment on autonomous navigation systems. To this end, we present a field report analyzing teach-and-repeat navigation in a subarctic region while subject to large variations of meteorological conditions. First, we describe the system, which relies on point cloud registration to localize a mobile robot through a boreal forest, while simultaneously building a map. We experimentally evaluate this system in over 18.6 km of autonomous navigation in the teach-and-repeat mode. We show that dense vegetation perturbs the GNSS signal, rendering it unsuitable for navigation in forest trails. Furthermore, we highlight the increased uncertainty related to localizing using point cloud registration in forest corridors. We demonstrate that it is not snow precipitation, but snow accumulation that affects our system‚Äôs ability to localize within the environment. Finally, we expose some lessons learned and challenges from our field campaign to support better experimental work in winter conditions.&lt;/p&gt;

&lt;h1 id=&quot;quick-facts&quot;&gt;Quick facts:&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;18.6 km of autonomous route repeating using a &lt;a href=&quot;https://www.clearpathrobotics.com/husky-unmanned-ground-vehicle-robot/https://clearpathrobotics.com/warthog-unmanned-ground-vehicle-robot/&quot;&gt;Clearpath Warthog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;The description of our Weather-Invariant Lidar-based navigation (WILN) system, relying on a &lt;a href=&quot;https://www.robosense.ai/en/rslidar/RS-LiDAR-32&quot;&gt;Robosense RS-32 lidar&lt;/a&gt; and a &lt;a href=&quot;https://www.xsens.com/products/mti-10-series&quot;&gt;XSens MTi-10 IMU&lt;/a&gt; for autonomous navigation.&lt;/li&gt;
  &lt;li&gt;GNSS localization measurements using &lt;a href=&quot;https://emlid.com/reachrs/&quot;&gt;Emlid Reach-RS+&lt;/a&gt; receivers.&lt;/li&gt;
  &lt;li&gt;Deployment in the &lt;a href=&quot;https://www.foretmontmorency.ca/en/&quot;&gt;Montmorency subarctic forest&lt;/a&gt;, the largest research forest in the world harsh winter weather.&lt;/li&gt;
  &lt;li&gt;We present a thorough analysis of the impact of the boreal forest biome and winter weather, inherent to northern countries on state-of-the-art autonomous navigation technologies.&lt;/li&gt;
  &lt;li&gt;We highlight the upcoming challenges in enabling multi-season autonomy in northern territories.&lt;/li&gt;
  &lt;li&gt;Our preprint is available &lt;a href=&quot;https://arxiv.org/abs/2111.13981&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;video&quot;&gt;Video&lt;/h1&gt;
&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/W8TdAoeNv4U&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;</content><author><name>Dominic Baril</name><email>dominic.baril@norlab.ulaval.ca</email></author><category term="publications" /><category term="SLAM" /><category term="extreme environments" /><category term="winter" /><category term="navigation" /><category term="GPS-denied operation" /><summary type="html">Challenges inherent to autonomous wintertime navigation in forests include lack of reliable a Global Navigation Satellite System (GNSS) signal, low feature contrast, high illumination variations and changing environment. This type of off-road environment is an extreme case of situations autonomous cars could encounter in northern regions. Thus, it is important to understand the impact of this harsh environment on autonomous navigation systems. To this end, we present a field report analyzing teach-and-repeat navigation in a subarctic region while subject to large variations of meteorological conditions. First, we describe the system, which relies on point cloud registration to localize a mobile robot through a boreal forest, while simultaneously building a map. We experimentally evaluate this system in over 18.6 km of autonomous navigation in the teach-and-repeat mode. We show that dense vegetation perturbs the GNSS signal, rendering it unsuitable for navigation in forest trails. Furthermore, we highlight the increased uncertainty related to localizing using point cloud registration in forest corridors. We demonstrate that it is not snow precipitation, but snow accumulation that affects our system‚Äôs ability to localize within the environment. Finally, we expose some lessons learned and challenges from our field campaign to support better experimental work in winter conditions.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22publications/field-report-ltr2021/ref_maps.jpg%22,%20%22teaser%22=%3E%22publications/field-report-ltr2021/large_path.jpg%22,%20%22thumb%22=%3Enil%7D" /><media:content medium="image" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22publications/field-report-ltr2021/ref_maps.jpg%22,%20%22teaser%22=%3E%22publications/field-report-ltr2021/large_path.jpg%22,%20%22thumb%22=%3Enil%7D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Vincent Grondin</title><link href="https://norlab.ulaval.ca/people/v_grondin/" rel="alternate" type="text/html" title="Vincent Grondin" /><published>2021-07-27T00:00:00-04:00</published><updated>2021-07-27T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/people/v_grondin</id><content type="html" xml:base="https://norlab.ulaval.ca/people/v_grondin/">&lt;p&gt;Vincent Grondin is a Ph.D candidate supervised by Prof. &lt;a href=&quot;../../people/p_giguere_fr&quot;&gt;Philippe Gigu√®re&lt;/a&gt;  at Universit√© Laval, and he is a member of Norlab. He graduated with both a certificate in physics and a bachelor in electrical engineering from Universit√© de Sherbrooke. During his bachelor, he was responsible for ensuring the control and simulation of a Hoverbike as a part of a higly-funded third year project. He also completed two internships at the &lt;a href=&quot;https://www.asc-csa.gc.ca/eng/default.asp&quot; target=&quot;_blank&quot;&gt; Canadian Space Agency &lt;/a&gt; , where he developed a communication prototype with spatial recognition. Additionally, during an internship at the &lt;a href=&quot;https://www.gel.usherbrooke.ca/audio/&quot; target=&quot;_blank&quot;&gt; Speech and Audio Research Group Laboratory &lt;/a&gt;, he conducted research on the classification of speech and audio by using artificial intelligence (AI).&lt;/p&gt;

&lt;p&gt;Currently, his research focuses on environment perception and simulation by employing AI in forests. Here is an example of his most recent project where AI algorithms perform automatic tree detection:&lt;/p&gt;

&lt;iframe src=&quot;https://www.youtube.com/embed/KAh_z77_4eM&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;M.Sc. en informatique (&lt;a href=&quot;https://norlab.ulaval.ca/accueil/&quot; target=&quot;_blank&quot;&gt; Norlab &lt;/a&gt;) - Universit√© Laval (passage acc√©l√©r√© au doctorat), 2020&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;B.Ing. en g√©nie √©lectrique - Universit√© de Sherbrooke, 2018&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Certificat en physique - Universit√© de Sherbrooke, 2014&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;h2 class=&quot;bibliography&quot;&gt;Conference Articles&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Baril2020&quot;&gt;Baril, D., Grondin, V., Deschenes, S., Laconte, J., Vaidis, M., Kubelka, V., Gallant, A., Giguere, P., &amp;amp; Pomerleau, F. (2020). Evaluation of Skid-Steering Kinematic Models for Subarctic Environments. &lt;i&gt;2020 17th Conference on Computer and Robot Vision (CRV)&lt;/i&gt;, 198‚Äì205. https://doi.org/10.1109/CRV50864.2020.00034&lt;/span&gt;

&lt;br /&gt;

&lt;a href=&quot;/pdf/Baril2020.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&amp;nbsp;PDF&lt;/i&gt;&lt;/a&gt;
&amp;emsp;



&lt;a href=&quot;https://doi.ieeecomputersociety.org/10.1109/CRV50864.2020.00034&quot;&gt;&lt;i class=&quot;fas fa-external-link-alt&quot;&gt;&amp;nbsp;Publisher&lt;/i&gt;&lt;/a&gt;
&amp;emsp;

&lt;a class=&quot;details&quot; href=&quot;/bibliography/Baril2020/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&amp;nbsp;Bibtex source&lt;/i&gt; &lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;‚Äì&amp;gt;&lt;/p&gt;</content><author><name>Vincent Grondin</name><email>vincent.grondin.2@ulaval.ca</email></author><summary type="html">Vincent Grondin is a Ph.D candidate supervised by Prof. Philippe Gigu√®re at Universit√© Laval, and he is a member of Norlab. He graduated with both a certificate in physics and a bachelor in electrical engineering from Universit√© de Sherbrooke. During his bachelor, he was responsible for ensuring the control and simulation of a Hoverbike as a part of a higly-funded third year project. He also completed two internships at the Canadian Space Agency , where he developed a communication prototype with spatial recognition. Additionally, during an internship at the Speech and Audio Research Group Laboratory , he conducted research on the classification of speech and audio by using artificial intelligence (AI).</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/v_grondin.jpg%22,%20%22teaser%22=%3E%22/people/v_grondin_avatar.jpg%22%7D" /><media:content medium="image" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/v_grondin.jpg%22,%20%22teaser%22=%3E%22/people/v_grondin_avatar.jpg%22%7D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Vincent Grondin</title><link href="https://norlab.ulaval.ca/people/v_grondin_fr/" rel="alternate" type="text/html" title="Vincent Grondin" /><published>2021-07-27T00:00:00-04:00</published><updated>2021-07-27T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/people/v_grondin_fr</id><content type="html" xml:base="https://norlab.ulaval.ca/people/v_grondin_fr/">&lt;p&gt;Vincent Grondin est un √©tudiant au doctorat √† l‚ÄôUniversit√© Laval sous la supervision du Pr. &lt;a href=&quot;../../people/p_giguere_fr&quot;&gt;Philippe Gigu√®re&lt;/a&gt; et membre du laboratoire Norlab. Dipl√¥m√© d‚Äôun certificat en physique et d‚Äôun baccalaur√©at en g√©nie √©lectrique √† l‚ÄôUniversit√© de Sherbrooke, il a occup√© le poste de responsable en contr√¥le et asservissement d‚Äôun Hoverbike dans un projet majeur en ing√©nierie lors de sa derni√®re ann√©e au baccalaur√©at. Pendant ses √©tudes, il a r√©alis√© deux stages √† l‚Äô&lt;a href=&quot;https://www.asc-csa.gc.ca/fra/default.asp&quot; target=&quot;_blank&quot;&gt; Agence spatiale canadienne &lt;/a&gt; sur la recherche et d√©veloppement d‚Äôun prototype de communication avec reconnaissance spatiale. Durant son stage au laboratoire &lt;a href=&quot;https://www.gel.usherbrooke.ca/audio/&quot; target=&quot;_blank&quot;&gt; Groupe de recherche sur la parole et l‚Äôaudio &lt;/a&gt;, il a conduit une recherche sur la classification de la parole et l‚Äôaudio √† l‚Äôaide d‚Äôintelligence artificielle (IA).&lt;/p&gt;

&lt;p&gt;Pr√©sentement, ses travaux de recherche se concentrent sur la simulation et la perception d‚Äôenvironnements par IA en milieux forestiers. Voici un exemple de d√©tection automatique d‚Äôarbres:&lt;/p&gt;

&lt;iframe src=&quot;https://www.youtube.com/embed/KAh_z77_4eM&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;M.Sc. en informatique (&lt;a href=&quot;https://norlab.ulaval.ca/accueil/&quot; target=&quot;_blank&quot;&gt; Norlab &lt;/a&gt;) - Universit√© Laval (passage acc√©l√©r√© au doctorat), 2020&lt;/li&gt;
  &lt;li&gt;B.Ing. en g√©nie √©lectrique - Universit√© de Sherbrooke, 2018&lt;/li&gt;
  &lt;li&gt;Certificat en physique - Universit√© de Sherbrooke, 2014&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;h2 class=&quot;bibliography&quot;&gt;Conference Articles&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Baril2020&quot;&gt;Baril, D., Grondin, V., Deschenes, S., Laconte, J., Vaidis, M., Kubelka, V., Gallant, A., Giguere, P., &amp;amp; Pomerleau, F. (2020). Evaluation of Skid-Steering Kinematic Models for Subarctic Environments. &lt;i&gt;2020 17th Conference on Computer and Robot Vision (CRV)&lt;/i&gt;, 198‚Äì205. https://doi.org/10.1109/CRV50864.2020.00034&lt;/span&gt;

&lt;br /&gt;

&lt;a href=&quot;/pdf/Baril2020.pdf&quot;&gt;&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&amp;nbsp;PDF&lt;/i&gt;&lt;/a&gt;
&amp;emsp;



&lt;a href=&quot;https://doi.ieeecomputersociety.org/10.1109/CRV50864.2020.00034&quot;&gt;&lt;i class=&quot;fas fa-external-link-alt&quot;&gt;&amp;nbsp;Publisher&lt;/i&gt;&lt;/a&gt;
&amp;emsp;

&lt;a class=&quot;details&quot; href=&quot;/bibliography/Baril2020/&quot;&gt; &lt;i class=&quot;fas fa-file-code&quot;&gt;&amp;nbsp;Bibtex source&lt;/i&gt; &lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;‚Äì&amp;gt;&lt;/p&gt;</content><author><name>Vincent Grondin</name><email>vincent.grondin.2@ulaval.ca</email></author><summary type="html">Vincent Grondin est un √©tudiant au doctorat √† l‚ÄôUniversit√© Laval sous la supervision du Pr. Philippe Gigu√®re et membre du laboratoire Norlab. Dipl√¥m√© d‚Äôun certificat en physique et d‚Äôun baccalaur√©at en g√©nie √©lectrique √† l‚ÄôUniversit√© de Sherbrooke, il a occup√© le poste de responsable en contr√¥le et asservissement d‚Äôun Hoverbike dans un projet majeur en ing√©nierie lors de sa derni√®re ann√©e au baccalaur√©at. Pendant ses √©tudes, il a r√©alis√© deux stages √† l‚Äô Agence spatiale canadienne sur la recherche et d√©veloppement d‚Äôun prototype de communication avec reconnaissance spatiale. Durant son stage au laboratoire Groupe de recherche sur la parole et l‚Äôaudio , il a conduit une recherche sur la classification de la parole et l‚Äôaudio √† l‚Äôaide d‚Äôintelligence artificielle (IA).</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/v_grondin.jpg%22,%20%22teaser%22=%3E%22/people/v_grondin_avatar.jpg%22%7D" /><media:content medium="image" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/v_grondin.jpg%22,%20%22teaser%22=%3E%22/people/v_grondin_avatar.jpg%22%7D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Norlab robots</title><link href="https://norlab.ulaval.ca/research/norlab-robots/" rel="alternate" type="text/html" title="Norlab robots" /><published>2021-07-03T00:00:00-04:00</published><updated>2021-07-03T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/research/norlab-robots</id><content type="html" xml:base="https://norlab.ulaval.ca/research/norlab-robots/">&lt;p&gt;The list of our robots is growing, see for yourself! We like them rugged bacause they often go outdoors, collecting datasets, capturing lidar maps and driving autonomously around the campus and in the Montmorency forest. The black sheep of this family is the robotic arm, but even that is one day going to end up attached to the Warthog driving in some bushes üòÉ&lt;/p&gt;

&lt;h3 id=&quot;warthog&quot;&gt;&lt;center&gt;Warthog&lt;center&gt;&lt;/center&gt;&lt;/center&gt;&lt;/h3&gt;
&lt;h5 id=&quot;large-all-terrain-unmanned-ground-vehicle-from-clearpath&quot;&gt;&lt;center&gt;Large, all-terrain unmanned ground vehicle from Clearpath&lt;center&gt;&lt;/center&gt;&lt;/center&gt;&lt;/h5&gt;

&lt;p&gt;It can handle tough environments with its rugged build, low ground pressure, and traction tires, which allow effortless mobility in soft terrain. In the winter season, we exchange the wheels for tracks that allow it to drive on all sorts of snow. It is the optimal platform for the forest environment the Norlab is all about.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/projects/norlab_robots/warthog_03.jpg&quot; style=&quot;width: 50%; float: left; margin-right: 2em; margin-bottom: 1em&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Weight: 280 kg + payload (approx. 150 kg)&lt;/li&gt;
&lt;li&gt;Size: 1.52 x 1.38 x 0.83 m&lt;/li&gt;
&lt;li&gt;Max speed: 18 km/h&lt;/li&gt;
&lt;li&gt;Battery: 12x lead-acid, 48 V, 2.5 h&lt;/li&gt;
&lt;li&gt;Onboard computers: 2x automotive PC, 1x NVidia Xavier planned&lt;/li&gt;
&lt;li&gt;Sensors: 2x 16-beam lidar, 1x 32-beam lidar, IMU, 2x RTK-GPS, 1x RGB camera&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For our research, the warthog is equipped with tree RS-LIDARs from RoboSense, a Dalsa camera for collecting visual datasets, two GPS receivers for reference positioning and an IMU for precise attitude estimation. There are also two onboard PCs, one handling low-level drivers of the motor controllers and one dedicated for high-level tasks such as mapping and navigation. They run Ubuntu with ROS.&lt;/p&gt;

&lt;p style=&quot;clear:both;&quot;&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;husky&quot;&gt;&lt;center&gt;Husky&lt;center&gt;&lt;/center&gt;&lt;/center&gt;&lt;/h3&gt;
&lt;h5 id=&quot;skid-steered-robotic-development-platform-from-clearpath&quot;&gt;&lt;center&gt;Skid-steered robotic development platform from Clearpath&lt;center&gt;&lt;/center&gt;&lt;/center&gt;&lt;/h5&gt;

&lt;p&gt;The Husky‚Äôs rugged construction and high-torque drivetrain make it suitable for indoor and outdoor, moderately uneven terrains. Husky carries cameras, a LIDAR, and an IMU. It was the Norlab‚Äôs workhorse in the DARPA SubT Urban circuit and before that, the first explorer of the Montmorency forest.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/projects/norlab_robots/husky.jpg&quot; style=&quot;width: 50%; float: right; margin-left: 2em; margin-bottom: 1em&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Weight: 62 kg&lt;/li&gt;
&lt;li&gt;Size: 0.99 x 0.67 x 0.39 m&lt;/li&gt;
&lt;li&gt;Max speed: 3.6 km/h&lt;/li&gt;
&lt;li&gt;Battery: 2x lead-acid, 24 V, 2 h&lt;/li&gt;
&lt;li&gt;Onboard computers: 1x Dell 3070, 1x NVidia Xavier&lt;/li&gt;
&lt;li&gt;Sensors: 1x 16-beam lidar, IMU, 6x RGB camera, 1x RGB-D camera&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;clear:both;&quot;&gt;Its payload has been designed by Norlab's students for the DARPA SubT competition. The ability to explore the environment by an omnidirectional set of high-resolution cameras, by a lidar and by an additional RGB-D sensor makes this platform ideal for developing and testing machine-learning and SLAM algorithms. Although not perfect on obstacles and stairs, it can traverse rough terrain, and thus it is going to serve as a dataset-collecting platform of the lab. &lt;br /&gt; &lt;/p&gt;

&lt;h3 id=&quot;marmotte-hd2&quot;&gt;&lt;center&gt;Marmotte (HD2)&lt;center&gt;&lt;/center&gt;&lt;/center&gt;&lt;/h3&gt;
&lt;h5 id=&quot;tracked-robotic-development-platform-from-superdroid-robots&quot;&gt;&lt;center&gt;Tracked robotic development platform from SuperDroid Robots&lt;center&gt;&lt;/center&gt;&lt;/center&gt;&lt;/h5&gt;

&lt;p&gt;The tracks of this platform are driven by powerful geared motors through heavy-duty chains. Its frame is ribbed and gusseted to make it rigid, and altogether it has a sturdy and solid chassis that will withstand rough treatment. Its size allows it to easily climb obstacles, ascend stairs, and drive over most terrains. In 2021, it is Norlab‚Äôs wild card in the DARPA SubT üî•&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/projects/norlab_robots/Marmotte.jpg&quot; style=&quot;width: 50%; float: left; margin-right: 2em; margin-bottom: 1em&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Weight: 57 kg&lt;/li&gt;
&lt;li&gt;Size: 1.00 x 0.65 x 0.50 m&lt;/li&gt;
&lt;li&gt;Max speed: 4.0 km/h&lt;/li&gt;
&lt;li&gt;Battery: 2x LiFePo4, 25.6 V, 2 h&lt;/li&gt;
&lt;li&gt;Onboard computers: 1x Dell 3070, 1x NVidia Xavier&lt;/li&gt;
&lt;li&gt;Sensors: 1x 16-beam lidar, IMU, 6x RGB camera, 1x RGB-D camera&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;clear:both;&quot;&gt;This robot is Husky's young sister (Marmotte is &lt;i&gt;she&lt;/i&gt;), equipped with the same sensor suite to accelerate software development for these two robots. Marmotte's advantage is the fact that it can climb stairs and get to places Husky cannot.&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;vaul-robot&quot;&gt;&lt;center&gt;Vaul robot&lt;center&gt;&lt;/center&gt;&lt;/center&gt;&lt;/h3&gt;
&lt;h5 id=&quot;heavy-unmanned-ground-vehicle-from-superdroid-customized-by-students-to-be-a-snowplow&quot;&gt;&lt;center&gt;Heavy unmanned ground vehicle from SuperDroid, customized by students to be a snowplow&lt;center&gt;&lt;/center&gt;&lt;/center&gt;&lt;/h5&gt;

&lt;p&gt;The weight of this robot is perfect to plow snow on the sidewalks. The frame is made from aluminum, and four powerful geared motors allow the robot to carry a heavy payload. Students of the robotic club VAUL made a custom frame to carry the sensors and to protect the motors and batteries from the cold during the winter operations. With its plow, the robot can autonomously push around 40 kg of snow.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/projects/norlab_robots/vaul.jpg&quot; style=&quot;width: 50%; float: right; margin-left: 2em; margin-bottom: 1em&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Weight: 160 kg&lt;/li&gt;
&lt;li&gt;Size: 1.00 x 1.5 x 1.5 m&lt;/li&gt;
&lt;li&gt;Max speed: 7.2 km/h&lt;/li&gt;
&lt;li&gt;Battery: 4x Sealed Lead Acid Battery, 2x24V, 2h&lt;/li&gt;
&lt;li&gt;Onboard computers: 1x Dell 3070, 1xNVidia Xavier AGX&lt;/li&gt;
&lt;li&gt;Sensors: 1x 16-beam lidar, IMU, 3x RGB camera, 2xReach M+ RTK-GPS&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;clear:both;&quot;&gt;With its diversified sensor suite, this snowplow can operate autonomously in diverse types of weather. The robot participated in its first Autonomous Snowplow Competition in Minneapolis in January 2020.&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;universal-robots-ur10e&quot;&gt;&lt;center&gt;Universal Robots' UR10e&lt;center&gt;&lt;/center&gt;&lt;/center&gt;&lt;/h3&gt;
&lt;h5 id=&quot;the-ur10e-is-an-extraordinarily-versatile-collaborative-industrial-robot-from-universal-robots&quot;&gt;&lt;center&gt;The UR10e is an extraordinarily versatile collaborative industrial robot from Universal Robots.&lt;center&gt;&lt;/center&gt;&lt;/center&gt;&lt;/h5&gt;

&lt;p&gt;Our robot is equipped with a Robotiq 2-finger adaptive gripper. With a fixed or mounted-on-the-wrist camera, computer-vision-enabled applications make the UR10e perfect for pick-and-place and bin-picking applications.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/projects/norlab_robots/Universal_robot_small.jpg&quot; style=&quot;width: 50%; float: left; margin-right: 2em; margin-bottom: 1em&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Reach: 1300 mm&lt;/li&gt;
&lt;li&gt;Payload: 12.5 kg&lt;/li&gt;
&lt;li&gt;Footprint: diameter 190 mm&lt;/li&gt;
&lt;li&gt;Repeatability: ¬±0.05 mm, with payload&lt;/li&gt;
&lt;li&gt;Equipped with sensitive force &amp;amp; torque sensor&lt;/li&gt;
&lt;li&gt;Our end-effector: Robotiq 2-finger adaptive gripper&lt;/li&gt;
&lt;li&gt;Weight: 33.5 kg&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;clear:both;&quot;&gt;The arm is equipped with 2D and 3D vision systems backed by powerful AI to fully unlock the potential of the robot to use state-of-the-art algorithms for pattern detection and object recognition, and design smart policies for manipulation tasks and autonomous grasping.&lt;br /&gt;&lt;/p&gt;</content><author><name>Jana Bartakova</name></author><category term="research" /><category term="project" /><category term="hd2" /><category term="husky" /><category term="robot" /><category term="warthog" /><summary type="html">The list of our robots is growing, see for yourself! We like them rugged bacause they often go outdoors, collecting datasets, capturing lidar maps and driving autonomously around the campus and in the Montmorency forest. The black sheep of this family is the robotic arm, but even that is one day going to end up attached to the Warthog driving in some bushes üòÉ</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/projects/norlab_robots/feature_collage.jpg%22,%20%22teaser%22=%3E%22/projects/norlab_robots/teaser.jpg%22%7D" /><media:content medium="image" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/projects/norlab_robots/feature_collage.jpg%22,%20%22teaser%22=%3E%22/projects/norlab_robots/teaser.jpg%22%7D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Lie theory cheatsheet</title><link href="https://norlab.ulaval.ca/research/LieCheatsheet/" rel="alternate" type="text/html" title="Lie theory cheatsheet" /><published>2021-06-25T00:00:00-04:00</published><updated>2021-06-25T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/research/LieCheatsheet</id><content type="html" xml:base="https://norlab.ulaval.ca/research/LieCheatsheet/">&lt;h1 id=&quot;lie-theory-in-robotics&quot;&gt;Lie theory in robotics&lt;/h1&gt;

&lt;p&gt;In the last years, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Lie_group&quot;&gt;Lie theory&lt;/a&gt; started to gain momentum and proved to be a powerful tool in the domain of state estimation.
The theory was transposed in robotics terms in &lt;a href=&quot;http://asrl.utias.utoronto.ca/~tdb/&quot;&gt;‚ÄúState Estimation for Robotics‚Äù&lt;/a&gt; by Tim Barfoot. Also, a micro Lie theory was proposed by &lt;a href=&quot;https://arxiv.org/abs/1812.01537&quot;&gt;Sola et al.&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Using the notations of Tim Barfoot‚Äôs book, we designed a cheatsheet synthesizing the main notions to remember when working with Lie groups.&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval/cheatsheet_LieAlgebra/raw/master/main.pdf&quot;&gt;Download the pdf version of the cheatsheet&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/norlab-ulaval/cheatsheet_LieAlgebra&quot;&gt;Github repository&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/norlab-ulaval/cheatsheet_LieAlgebra/raw/master/preview-1.png&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;</content><author><name>Johann Laconte</name><email>laconte.johann@gmail.com</email></author><category term="research" /><category term="howto" /><category term="Cheatsheet" /><category term="Lie" /><summary type="html">Lie theory in robotics</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22publications/icp-lie_teaser.jpg%22,%20%22feature%22=%3Enil%7D" /><media:content medium="image" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22publications/icp-lie_teaser.jpg%22,%20%22feature%22=%3Enil%7D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Norlab in media!</title><link href="https://norlab.ulaval.ca/research/media/" rel="alternate" type="text/html" title="Norlab in media!" /><published>2021-06-02T00:00:00-04:00</published><updated>2021-06-02T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/research/media</id><content type="html" xml:base="https://norlab.ulaval.ca/research/media/">&lt;p&gt;We are happy that Norlab is being noticed in media. See what they have written about us.&lt;/p&gt;

&lt;p&gt;IEEE Spectrum:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/darpa-subt-meet-the-first-nine-teams&quot;&gt;DARPA Subterranean Challenge: Meet the First 9 Teams&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-software/darpa-subt-cave-circuit-competition&quot;&gt;17 Teams to Take Part in DARPA‚Äôs SubT Cave Circuit Competition&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/late-nights-cool-hacks-and-more-stories-from-the-darpa-subt-urban-circuit&quot;&gt;Late Nights, Cool Hacks, and More Stories From the DARPA SubT Urban Circuit&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/robotics-teams-prepare-darpa-subt-challenge-urban-circuit&quot;&gt;How Robotics Teams Prepared for DARPA‚Äôs SubT Challenge: Urban Circuit&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;IEEE Spectrum ‚Äì Video Friday:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/video-friday-robotic-eyeball-camera&quot;&gt;Teaser ‚Äì SNOW milestone 3 achieved&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/video-friday-aquatic-snakebotics&quot;&gt;DARPA SubT ‚Äì Urban challenge under 10 min&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-software/video-friday-starship-robots-1-million-deliveries&quot;&gt;Driving our robot on the campus after the snow storm&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/video-friday-mit-mini-cheetah-robots-naver-labs&quot;&gt;Uncut ‚Äì A Christmas story&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/video-friday-agility-robotics-robot-production&quot;&gt;Can you throw your robot into a lake?&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/video-friday-mesmer-humanoid-robot&quot;&gt;Fallen tree crossing&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-software/video-friday-3d-printed-liquid-crystal-elastomer&quot;&gt;SNOW control intro video&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/video-friday-quadruped-robot-locomotion-skills&quot;&gt;CTU-CRAS-NORLAB: DARPA Subterranean Challenge - Urban Circuit&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://spectrum.ieee.org/automaton/robotics/robotics-hardware/video-friday-robots-wish-happy-holidays&quot;&gt;Robotic Christmas Spirit ‚Äì Norlab 2019&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DARPA Subterranean Challenge:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.darpa.mil/news-events/2021-05-03&quot;&gt;DARPA Subterranean Challenge Announces Systems Competition Teams for Final Event&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.darpa.mil/news-events/2020-11-17&quot;&gt;Teams Coordinated Robotics, BARCS, and Dynamo On Top in DARPA Subterranean Challenge Cave Circuit Virtual Competition&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.darpa.mil/news-events/2020-09-28a&quot;&gt;Subterranean Challenge Identifies Qualified Teams for Cave Circuit Virtual Competition&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.darpa.mil/news-events/2020-02-27&quot;&gt;Teams CoSTAR and BARCS Take Top Spots in DARPA Subterranean Challenge Urban Circuit&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.darpa.mil/news-events/2020-01-10&quot;&gt;DARPA Names Qualifiers for the Subterranean Challenge Urban Circuit&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Univesit√© Laval:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.fsg.ulaval.ca/faculte/actualites/norlab-et-ses-partenaires-se-distinguent-au-darpa-subterranean-challenge-3400/&quot;&gt;Norlab et ses partenaires se distinguent au DARPA Subterranean Challenge&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Executive Gov:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.executivegov.com/2021/05/darpa-picks-eight-teams-for-subterranean-challenge-robot-competition-finals/&quot;&gt;DARPA Picks Eight Teams for Subterranean Challenge Robot Competition Finals&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Center for Robotics and Autonomous Systems, Czech Technical University:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;http://robotics.fel.cvut.cz/cras/darpa-subt/&quot;&gt;DARPA Sub-T&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Robots &amp;amp; Automation News:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://roboticsandautomationnews.com/2021/05/03/darpa-selects-eight-teams-for-3-5-million-prize-competition/42994/&quot;&gt;Darpa selects eight teams for $3.5 million prize competition&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Geek Wire:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.geekwire.com/2020/robots-masters-take-nuclear-plant-darpas-subterranean-challenge/&quot;&gt;Robots and their masters take over nuclear plant for DARPA‚Äôs Subterranean Challenge&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Vidette:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.thevidette.com/news/robots-creeping-around-satsop-hoping-to-find-millions-in-prize-money/&quot;&gt;Robots creeping around Satsop hoping to find millions in prize money&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.thevidette.com/news/accelerating-innovation-is-one-goal-of-darpa-with-contest/&quot;&gt;Accelerating innovation is one goal of DARPA with contest&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Propulsion Qu√©bec ‚Äì En Route! :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://propulsionquebec.com/en-route/le-developpement-durable-au-coeur-de-notre-enseignement/&quot;&gt;Laboratoire de robotique bor√©ale (Norlab)&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jana Bartakova</name></author><category term="research" /><category term="project" /><category term="media" /><summary type="html">We are happy that Norlab is being noticed in media. See what they have written about us.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3Enil,%20%22teaser%22=%3E%22norlab_in_media.jpg%22%7D" /><media:content medium="image" url="https://norlab.ulaval.ca/%7B%22feature%22=%3Enil,%20%22teaser%22=%3E%22norlab_in_media.jpg%22%7D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How to publish your preprints on Arxiv</title><link href="https://norlab.ulaval.ca/research/publish-prepints-arxiv/" rel="alternate" type="text/html" title="How to publish your preprints on Arxiv" /><published>2021-03-11T00:00:00-05:00</published><updated>2021-03-11T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/research/publish-prepints-arxiv</id><content type="html" xml:base="https://norlab.ulaval.ca/research/publish-prepints-arxiv/">&lt;p&gt;Before submitting a preprint to arXiv, make sure the publisher permits preprints.
In general, they require that:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The authors disclose the existence of the preprint at submission.&lt;/li&gt;
  &lt;li&gt;Once an article is published, the preprint should link to the published version (typically via DOI or URL).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For IEEE, see &lt;a href=&quot;https://journals.ieeeauthorcenter.ieee.org/become-an-ieee-journal-author/publishing-ethics/guidelines-and-policies/post-publication-policies/&quot;&gt;IEEE publication Policies&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For other publishers, see &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_academic_publishers_by_preprint_policy&quot;&gt;List of academic publishers by preprint policy&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;submitting-to-arxiv&quot;&gt;Submitting to arXiv&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;Register at &lt;a href=&quot;arxiv.org&quot;&gt;arXiv&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Install &lt;a href=&quot;https://pypi.org/project/arxiv-collector/&quot;&gt;arxiv-collector&lt;/a&gt;:
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; pip &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;arxiv-collector	
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;In case of problems with the installation, you can download the standalone python file at this &lt;a href=&quot;https://github.com/djsutherland/arxiv-collector&quot;&gt;repository&lt;/a&gt;.
 You will also need a working installation of latexmk, see the &lt;a href=&quot;https://pypi.org/project/arxiv-collector/#requirements&quot;&gt;documentation&lt;/a&gt; if it is not already installed in your system.
 You can also add the script directly to an &lt;a href=&quot;www.overleaf.com&quot;&gt;Overleaf&lt;/a&gt; project and run it there for the same effect, please refer to the &lt;a href=&quot;https://pypi.org/project/arxiv-collector/#using-directly-on-overleaf&quot;&gt;GitHub repository&lt;/a&gt; for instructions.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Execute arxiv-collector in the root directory of the Latex project:
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; arxiv-collector root.tex
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;If using overleaf, arxiv-collector can be used online, see the &lt;a href=&quot;https://pypi.org/project/arxiv-collector/#using-directly-on-overleaf&quot;&gt;documentation&lt;/a&gt;.
 In both cases, an archive &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arxiv.tar.gz&lt;/code&gt; will be created.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In your &lt;a href=&quot;https://arxiv.org/user/&quot;&gt;user page&lt;/a&gt;, click on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;START NEW SUBMISSION&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Review the user information and choose a license for your article. Be aware that some publishers may accept preprints on the condition that a specific license is used. In general, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CC BY: Creative Commons Attribution&lt;/code&gt; licence is fine.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Choose a primary classification for the submission. Most of the time, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Computer Science&lt;/code&gt; - &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Robotics&lt;/code&gt; is a good choice.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Click &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Next&lt;/code&gt; and upload &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arxiv.tab.gz&lt;/code&gt; created beforehand. Click &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Continue:Process Files&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If the processing went well, you should see a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Preview your paper&lt;/code&gt; button. Click on it and check that the paper did compile properly (pay attention to the figures and equations).
  If the processing yields error, which is quite frequent, see below for some troubleshooting.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;On the next page, fill the metadata of the paper. Do not forget to fill the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Comments&lt;/code&gt; field with additional information asked from the publisher. You can also specify that the paper has been submitted to the conference/journal.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Leave blank most of the last fields (i.e. Report Number, Journal Reference, DOI, ACM class, MSC class). You will be able to update these after the paper is published in the conference/journal.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Preview your submission and submit. It should take about a day for the paper to appear on arxiv.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Once the paper is on arxiv, an email will be sent to you with a password. Send it to your co-authors so that they can claim ownership of the paper as well.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Do not forget that once the paper is accepted in the conference/journal, you need to update the&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Comment&lt;/code&gt; &lt;strong&gt;field on arXiv with the publisher‚Äôs copyright.&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;troubleshooting-arxiv-compilation&quot;&gt;Troubleshooting: arXiv Compilation&lt;/h1&gt;
&lt;p&gt;Most of the time, the compilation errors come from clashes in packages versions.
An easy solution is to include the packages that may cause errors in the submission so that they are used in the compilation instead of the arXiv server‚Äôs packages.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Locate the package that cause errors in your system by adding the line &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\listfiles&lt;/code&gt; in your main latex file, and compile.&lt;/li&gt;
  &lt;li&gt;Open the log file &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;root.log&lt;/code&gt; and search for the packages. You should find lines containing the paths to the packages. For instance:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; (/usr/share/texlive/texmf-dist/tex/latex/amsfonts/amsfonts.sty
 Package: amsfonts 2013/01/14 v3.01 Basic AMSFonts support
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Copy the packages in the working directory and execute &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arxiv-collector root.tex&lt;/code&gt;. The packages are now included in the archive.&lt;/li&gt;
  &lt;li&gt;Re-upload the archive to arXiv and process the files.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;list-of-known-errors-and-solutions&quot;&gt;List of known errors and solutions&lt;/h2&gt;
&lt;h3 id=&quot;package-biblatex-ieee-error-failed-to-update-citation-style&quot;&gt;Package biblatex-ieee Error: Failed to update citation style&lt;/h3&gt;
&lt;p&gt;Locate and include &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ieee.bbx&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ieee.cbx&lt;/code&gt; in the working directory.&lt;/p&gt;</content><author><name>Johann Laconte</name><email>laconte.johann@gmail.com</email></author><category term="research" /><category term="howto" /><category term="arxiv" /><category term="preprint" /><summary type="html">Before submitting a preprint to arXiv, make sure the publisher permits preprints. In general, they require that:</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22/logos/arxiv_logo-400x200.png%22,%20%22feature%22=%3E%22/logos/arxiv_logo-1200x329.png%22%7D" /><media:content medium="image" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22/logos/arxiv_logo-400x200.png%22,%20%22feature%22=%3E%22/logos/arxiv_logo-1200x329.png%22%7D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Four internships in robotics for the summer 2021 all taken!</title><link href="https://norlab.ulaval.ca/news/internships/" rel="alternate" type="text/html" title="Four internships in robotics for the summer 2021 all taken!" /><published>2021-02-04T00:00:00-05:00</published><updated>2021-02-04T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/news/internships</id><content type="html" xml:base="https://norlab.ulaval.ca/news/internships/">&lt;p&gt;Norlab is opening four internships covering multiple fields of study for this summer.
&lt;del&gt;Apply as soon as you can, we are closing the openings soon.&lt;/del&gt;
Here is the list of opportunities:&lt;/p&gt;

&lt;p&gt;All the positions have been filled, but keep an eye on the Norlab website, there will be more in future!&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;intern-1---not-available-anymore&quot;&gt;Intern 1 - Not available anymore&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;computer science, software engineering, computer engineering&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This internship is part of the SNOW (Self-driving Navigation Optimized for Winter) project, which aims at adapting autonomous navigation technologies to environments affected by winter. As part of his mandate, the student will develop an open library to predict the movements of a mobile robot. Several prototype algorithms have been analyzed in a Python Notebook, and must now be coded cleanly to allow real-time computation on a moving robot. The goal of the library is to allow researchers in the laboratory to do experiments faster. Ultimately, these experiments will allow mobile robots to adapt to changes in traction caused by snow cover during autonomous navigation.&lt;/p&gt;

&lt;p&gt;The trainee will be supervised by a PhD student specializing in control, allowing the student to focus on software development while acquiring practical robotics skills. The student will also be expected to support the team‚Äôs efforts in robot integration and field deployments. The intern will have access to state-of-the-art equipment and a 500 kg robot. The library will be publicly hosted on the lab‚Äôs GitHub and will be integrated with ROS (Robot Operating System).&lt;/p&gt;

&lt;p&gt;For contextual information, see &lt;a href=&quot;../../research/snow/&quot;&gt;the project page on SNOW&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;intern-2---not-available-anymore&quot;&gt;Intern 2 - Not available anymore&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;computer science, software engineering, computer engineering&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The laboratory is continuously developing several 3D mapping solutions for autonomous vehicles. Once the robot is on the move, it is relatively easy to locate it on a map. However, the laboratory has no software tools to relocate a robot if a map is reused.&lt;/p&gt;

&lt;p&gt;The objective of the internship is to develop a software to relocate a robot in a given 3D map. The first step will be to relocalize the robot manually in a 3D graphical user interface (rviz). In a second step, the placement of the robot will have to be refined automatically using a recalibration tool used in the laboratory. Finally, an algorithm to find the optimal placement of the robot in the map automatically (Go-ICP) can be implemented. The student will be supervised by experts in 3D cartography and the registration algorithm. The code will be publicly hosted on the GitHub of the laboratory and will be integrated to ROS (Robot Operating System).&lt;/p&gt;

&lt;p&gt;For contextual information, see &lt;a href=&quot;../../research/libpointmatcher/&quot;&gt;the project page on libpointmatcher&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;intern-3---not-available-anymore&quot;&gt;Intern 3 - Not available anymore&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Electrical Engineering, Computer Engineering&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The laboratory is preparing for a major U.S. deployment in September 2021. The goal of this deployment is to explore underground environments using a fleet of autonomous robots. To do so, the laboratory recently acquired new robots and commissioned the design of a custom power supply board for the sensors.&lt;/p&gt;

&lt;p&gt;The objective of the internship is to complete the electronic integration of the robots and to participate in the robustness tests of the systems. The tracked robots should be able to climb stairs and withstand a certain level of shock. The student will be supervised by robotics experts with backgrounds in computer science, electricity and mechanics.&lt;/p&gt;

&lt;p&gt;For contextual information, see &lt;a href=&quot;../../research/darpa-subt-urban/&quot;&gt;the project page on SUBT&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;intern-4---not-available-anymore&quot;&gt;Intern 4 - Not available anymore&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;computer science, software engineering, computer engineering&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The laboratory is preparing for a major U.S. deployment in September 2021. The goal of this deployment is to explore underground environments using a fleet of autonomous robots. The laboratory is developing 3D mapping and localization solutions based on lidars, but the maps used are often too sparse to allow obstacle avoidance.&lt;/p&gt;

&lt;p&gt;The objective of this internship is to combine the data from a lidar with the robot‚Äôs localization algorithms to produce a dense map within a close radius of the robot. In a first step, a dense map will be produced and displayed in a graphical user interface (rviz). Then, compression solutions will be tested to reduce the bandwidth of these maps during wireless transmission. Finally, obstacle avoidance algorithms will be studied. The student will be supervised by experts in 3D mapping and resetting algorithms. The code will be publicly hosted on the laboratory‚Äôs GitHub and will be integrated to ROS (Robot Operating System).&lt;/p&gt;

&lt;p&gt;For contextual information, see &lt;a href=&quot;../../research/darpa-subt-urban/&quot;&gt;the project page on SUBT&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;work-environment&quot;&gt;Work environment&lt;/h1&gt;

&lt;p&gt;All internships will be held in the Norlab (Northern Robotics Laboratory). This research laboratory specializes in mobile and autonomous systems operating in northern or difficult conditions in general. We aim to study problems related to navigation algorithms in order to push the limits of what is currently possible to do with a mobile robot in real-life conditions. Currently, our efforts are directed towards localization algorithms based on laser sensors (lidar) and 3D reconstruction of environments.&lt;/p&gt;

&lt;p&gt;The laboratory has two workshops in the Adrien-Pouliot building allowing interaction with research equipment according to current health standards. Unless otherwise specified, software development can be done remotely using existing data sets. Once the basis has been demonstrated, tests can be done on site with real research robots.&lt;/p&gt;

&lt;h1 id=&quot;compensation&quot;&gt;Compensation&lt;/h1&gt;

&lt;p&gt;There are two possible compensation options. The first option is for students aiming to continue at the Master‚Äôs level. If you have a rating greater than 3.8/4.3, we suggest that you apply for the NSERC Fellowship (https://www.nserc-crsng.gc.ca/students-etudiants/ug-pc/usra-brpc_fra.asp). Obtaining this scholarship will allow you to improve your record as a young researcher and normally comes with supplements from FRQNT. The laboratory also gives a $3,000 scholarship supplement for the internship. The application deadline is February 18, 2021.&lt;/p&gt;

&lt;p&gt;If you are not selected for the award, salaries are set according to the collective agreement for research assistants and are approximately $15/hour. The work week is 35 hours/week. The duration of the internship may vary from 12 to 15 weeks.&lt;/p&gt;

&lt;h1 id=&quot;application&quot;&gt;Application&lt;/h1&gt;

&lt;p&gt;Send your choice of internship, your CV and your transcript to the laboratory director, Fran√ßois Pomerleau &lt;a href=&quot;mailto:francois.pomerleau@ift.ulaval.ca&quot;&gt;francois.pomerleau@ift.ulaval.ca&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;Positions will be allocated at the beginning of March 2021.&lt;/p&gt;</content><author><name>Fran√ßois Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="news" /><category term="internships" /><summary type="html">Norlab is opening four internships covering multiple fields of study for this summer. Apply as soon as you can, we are closing the openings soon. Here is the list of opportunities:</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/news/intern21/intern21.jpg%22,%20%22teaser%22=%3E%22/news/intern21/intern21_teaser.jpg%22%7D" /><media:content medium="image" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/news/intern21/intern21.jpg%22,%20%22teaser%22=%3E%22/news/intern21/intern21_teaser.jpg%22%7D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Quatre stages en robotique pour l‚Äô√©t√© 2021 tous pris!</title><link href="https://norlab.ulaval.ca/news/internships_fr/" rel="alternate" type="text/html" title="Quatre stages en robotique pour l‚Äô√©t√© 2021 tous pris!" /><published>2021-02-04T00:00:00-05:00</published><updated>2021-02-04T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/news/internships_fr</id><content type="html" xml:base="https://norlab.ulaval.ca/news/internships_fr/">&lt;p&gt;Norlab ouvre quatre stages couvrant plusieurs domaines d‚Äô√©tude cet √©t√©.
&lt;del&gt;Appliquez aussit√¥t que vous pouvez car les offres se terminent sous peu.&lt;/del&gt;
Voici la liste des offres :&lt;/p&gt;

&lt;p&gt;Tous les offres sont pourvus, mais gardez un ≈ìil sur le site Norlab, il y en aura plus √† l‚Äôavenir!&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;stagiaire-1---plus-disponible&quot;&gt;Stagiaire 1 - Plus disponible&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;informatique, g√©nie logiciel, g√©nie informatique, g√©nie robotique&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Ce stage s‚Äôinscrit dans le projet SNOW (Self-driving Navigation Optimized for Winter), qui vise √† adapter les technologies de navigation autonome aux environnements affect√©s par l‚Äôhiver. Dans le cadre de son mandat, l‚Äô√©tudiant sera amen√© √† d√©velopper une biblioth√®que ouverte permettant de pr√©dire les mouvements d‚Äôun robot mobile. Plusieurs prototypes d‚Äôalgorithmes ont √©t√© analys√©s dans un Notebook Python, et doivent maintenant √™tre cod√© proprement afin de permettre du calcul temps r√©el sur un robot en movement. L‚Äôobjectif de la biblioth√®que est de permettre aux chercheurs du laboratoire de faire des exp√©riences plus rapidement. √Ä terme, ces exp√©riences permettrons aux robots mobiles de s‚Äôadapter aux changements de traction engendr√©s par le recouvrement de neige lors de la navigation autonome.&lt;/p&gt;

&lt;p&gt;Le stagiaire sera encadr√© par un √©tudiant au doctorat qui se sp√©cialise en control, ce qui permettra √† l‚Äô√©tudiant de se concentrer sur le d√©veloppement logiciel, tout en acqu√©rant des comp√©tences pratiques en robotique. L‚Äô√©tudiant sera √©galement amen√© √† soutenir l‚Äôeffort de l‚Äô√©quipe pour l‚Äôint√©gration du robot ainsi que pour les d√©ploiements de terrain. Le stagiaire aura acc√®s √† de l‚Äô√©quipement √† la fine pointe et √† un robot de 500 kg. La biblioth√®que sera h√©berg√©e publiquement sur le GitHub du laboratoire et sera int√©gr√©e √† ROS (Robot Operating System).&lt;/p&gt;

&lt;p&gt;Pour de l‚Äôinformation contextuel, voir &lt;a href=&quot;../../research/snow/&quot;&gt;la page sur le projet SNOW&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;stagiaire-2---plus-disponible&quot;&gt;Stagiaire 2 - Plus disponible&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;informatique, g√©nie logiciel, g√©nie informatique, g√©nie robotique&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;La laboratoire d√©veloppe de fa√ßon continu plusieurs solutions de cartographie 3D pour les v√©hicules autonomes. Une fois le robot en d√©placement, il est relativement facile de le localiser dans une carte. Cependant, le laboratoire n‚Äôa pas d‚Äôoutils logiciel pour relocalizer un robot si une carte est r√©utilis√©.&lt;/p&gt;

&lt;p&gt;L‚Äôobjectif du stage est de d√©velopper un logiciel permettant de relocalizer un robot dans une carte 3D donn√©e. La premi√®re √©tape sera de relocalizer le robot manuellement dans un interface graphique 3D (rviz). Dans un deuxi√®me temps, la pose du robot devra √™tre raffin√©e automatiquement √† l‚Äôaide d‚Äôun outils de recalage utilis√© dans le laboratoire. Finalement, un algorithme cherchant la pose optimal du robot dans la carte automatiquement (Go-ICP) pourra √™tre impl√©ment√©. L‚Äô√©tudiant sera encadr√© par des experts en cartographie 3D et en algorithme de recalage. Le code sera sera h√©berg√©e publiquement sur le GitHub du laboratoire et sera int√©gr√©e √† ROS (Robot Operating System).&lt;/p&gt;

&lt;p&gt;Pour de l‚Äôinformation contextuel, voir &lt;a href=&quot;../../research/libpointmatcher/&quot;&gt;la page sur libpointmatcher&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;stagiaire-3---plus-disponible&quot;&gt;Stagiaire 3 - Plus disponible&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;g√©nie √©lectrique, g√©nie informatique, g√©nie robotique&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Le laboratoire se pr√©pare pour un d√©ploiement d‚Äôenvergure aux √âtats-Unies qui aura lieu en septembre 2021. Le but de ce d√©ploiements est d‚Äôexplorer des environnements souterrains √† l‚Äôaide d‚Äôune flotte de robots autonomes. Pour se faire, le laboratoire r√©cemment a fait l‚Äôacquisition de nouveaux robots et a commander la conception d‚Äôune carte d‚Äôalimentation sur mesure pour les capteurs.&lt;/p&gt;

&lt;p&gt;L‚Äôobjectif du stage est de terminer l‚Äôint√©gration √©lectronique des robots et de participer aux tests de robustesse des syst√®mes. Les robots √† chenilles devraient √™tre en mesure de monter les escaliers et de r√©sister √† un certain niveau de chocs. L‚Äô√©tudiant sera encadr√© par des experts en robotique ayant une formation en informatique, √©lectrique et m√©canique.&lt;/p&gt;

&lt;p&gt;Pour de l‚Äôinformation contextuel, voir &lt;a href=&quot;../../research/darpa-subt-urban/&quot;&gt;la page sur le projet SUBT&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;stagiaire-4---plus-disponible&quot;&gt;Stagiaire 4 - Plus disponible&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;informatique, g√©nie logiciel, g√©nie informatique, g√©nie robotique&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Le laboratoire se pr√©pare pour un d√©ploiement d‚Äôenvergure aux √âtats-Unies qui aura lieu en septembre 2021. Le but de ce d√©ploiements est d‚Äôexplorer des environnements souterrains √† l‚Äôaide d‚Äôune flotte de robots autonomes. Le laboratoire d√©veloppe des solutions de cartographie et de localisation 3D bas√© sur des lidars, mais les cartes utilis√© sont souvent trop clairsem√©es pour permettre l‚Äô√©vitement d‚Äôobstacles.&lt;/p&gt;

&lt;p&gt;L‚Äôobjectif de ce stage est de combiner les donn√©es d‚Äôun lidar avec les algorithmes de localisation du robot afin de produire une carte dense dans un rayon rapproch√© du robot. Dans un premier temps, un carte dense sera produite et affich√©e dans un interface graphique (rviz). Par la suite, des solutions de compression seront test√©s afin de r√©duire la bande passante de ces cartes lors de la transmission sans fils. Finalement, des algorithmes d‚Äô√©vitement d‚Äôobstacles pourront √™tre √©tudi√©s. L‚Äô√©tudiant sera encadr√© par des experts en cartographie 3D et en algorithme de recalage. Le code sera sera h√©berg√©e publiquement sur le GitHub du laboratoire et sera int√©gr√©e √† ROS (Robot Operating System).&lt;/p&gt;

&lt;p&gt;Pour de l‚Äôinformation contextuel, voir &lt;a href=&quot;../../research/darpa-subt-urban/&quot;&gt;la page sur le projet SUBT&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;#Environnement de travail&lt;/p&gt;

&lt;p&gt;Tous les stages se tiendront dans le Norlab (Laboratoire de robotique bor√©ale). Ce laboratoire de recherche est sp√©cialis√© en syst√®mes mobiles et autonomes fonctionnant en conditions nordiques ou difficiles en g√©n√©ral. Nous visons l‚Äô√©tude de probl√®mes reli√©s au algorithmes de navigation dans l‚Äôoptique de repousser les limites de ce qui est pr√©sentement possible de faire avec un robot mobile en conditions d‚Äôutilisations r√©elles. Pr√©sentement, nos efforts sont dirig√©s vers les algorithmes de localisation bas√©s sur les capteurs laser (lidar) et sur la reconstruction 3D d‚Äôenvironnements.&lt;/p&gt;

&lt;p&gt;Le laboratoire poss√®de deux ateliers dans le b√¢timent Adrien-Pouliot permettant une interaction avec l‚Äô√©quipement de recherche suivant les normes sanitaires en vigueur. √Ä moins d‚Äôavis contraire, le d√©veloppement logiciel pourra se faire √† distance en utilisant des jeux de donn√©es existants. Une fois la base d√©montr√©, des tests pourront √™tre fait sur place avec de vrais robots de recherche.&lt;/p&gt;

&lt;p&gt;#R√©mun√©ration&lt;/p&gt;

&lt;p&gt;Il y a deux option de r√©mun√©ration possible. Le premi√®re options vise les √©tudiants visant continuer √† la ma√Ætrise. Si vous avez une cote de plus grande que 3.8/4.3, nous vous sugg√©rons d‚Äôappliquer √† la bourse de recherche CRSNG (https://www.nserc-crsng.gc.ca/students-etudiants/ug-pc/usra-brpc_fra.asp). L‚Äôobtention de cette bourse d‚Äôexcellence vous permettra d‚Äôam√©liorer votre dossier de jeune chercheur et vient normalement avec des suppl√©ments du FRQNT. Le laboratoire donne √©galement un suppl√©ment de 3 000 $ en bourse pour le stage. La date limite pour faire la demande est le 18 f√©vrier 2021.&lt;/p&gt;

&lt;p&gt;Si votre candidature n‚Äôest pas retenue pour la bourse, les salaires sont fix√©s selon la convention collective pour les auxiliaires de recherche et sont d‚Äôenviron 15 $/h. La semaine de travail est de 35 h/sem. La dur√©e du stage peut varier de 12 √† 15 semaines.&lt;/p&gt;

&lt;p&gt;#Application&lt;/p&gt;

&lt;p&gt;Envoyez votre choix de stage, votre CV et votre relev√© de notes au directeur du laboratoire, Fran√ßois Pomerleau &lt;a href=&quot;mailto:francois.pomerleau@ift.ulaval.ca&quot;&gt;francois.pomerleau@ift.ulaval.ca&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;Les postes seront allou√©s en d√©but mars 2021.&lt;/p&gt;</content><author><name>Fran√ßois Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="news" /><category term="internships" /><summary type="html">Norlab ouvre quatre stages couvrant plusieurs domaines d‚Äô√©tude cet √©t√©. Appliquez aussit√¥t que vous pouvez car les offres se terminent sous peu. Voici la liste des offres :</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/news/intern21/intern21.jpg%22,%20%22teaser%22=%3E%22/news/intern21/intern21_teaser.jpg%22%7D" /><media:content medium="image" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/news/intern21/intern21.jpg%22,%20%22teaser%22=%3E%22/news/intern21/intern21_teaser.jpg%22%7D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Project SNOW update: Better mapping for Lidar Teach &amp;amp; Repeat capability</title><link href="https://norlab.ulaval.ca/news/LTR/" rel="alternate" type="text/html" title="Project SNOW update: Better mapping for Lidar Teach &amp;amp; Repeat capability" /><published>2021-01-21T00:00:00-05:00</published><updated>2021-01-21T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/news/LTR</id><content type="html" xml:base="https://norlab.ulaval.ca/news/LTR/">&lt;p&gt;In the context of the second milestone of the Snow project, we want to expand and improve our mapping system.&lt;/p&gt;

&lt;p&gt;In our research, we focus on mappers optimized for large-scale environments. The next step is to be able to save and later reuse the 3D map while re-locating in it to match the new initial position of the robot. All these improved capabilities will allow us to pursuit longer distances travelled using the lidar-teach-and-repeat mode. We aim for several kilometers automatically navigated in deep snow through paths of the Montmorency research forest.&lt;/p&gt;

&lt;p&gt;Video of the lidar teach-and-repeat tests in the campus:&lt;/p&gt;

&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/1mKg2BFUNpM&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;</content><author><name>Jana Bartakova</name></author><category term="news" /><category term="project" /><summary type="html">In the context of the second milestone of the Snow project, we want to expand and improve our mapping system.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/news/LTR/ltr_b.png%22,%20%22teaser%22=%3E%22/news/LTR/ltr_a.jpg%22%7D" /><media:content medium="image" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/news/LTR/ltr_b.png%22,%20%22teaser%22=%3E%22/news/LTR/ltr_a.jpg%22%7D" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>