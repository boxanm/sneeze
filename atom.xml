<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://norlab.ulaval.ca/atom.xml" rel="self" type="application/atom+xml" /><link href="https://norlab.ulaval.ca/" rel="alternate" type="text/html" /><updated>2019-03-19T15:36:31-04:00</updated><id>https://norlab.ulaval.ca/atom.xml</id><title type="html">Northern Robotics Laboratory</title><subtitle>Website showcasing research and news from the Northern Robotics Laboratory, Laval University</subtitle><entry><title type="html">Three articles accepted at ICRA 2019!</title><link href="https://norlab.ulaval.ca/news/icra19/" rel="alternate" type="text/html" title="Three articles accepted at ICRA 2019!" /><published>2019-03-04T00:00:00-05:00</published><updated>2019-03-04T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/news/icra19</id><content type="html" xml:base="https://norlab.ulaval.ca/news/icra19/">&lt;p&gt;We are happy to announce that we have three accepted publications at the &lt;a href=&quot;https://www.icra2019.org/&quot;&gt;2019 International Conference on Robotics and Automation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We will present our latest results on lidar modeling &lt;a href=&quot;#Laconte2019&quot;&gt;(Laconte, Deschênes, Labussière, &amp;amp; Pomerleau, 2019)&lt;/a&gt;, learning algorithm for covariance estimation &lt;a href=&quot;#Landry2019&quot;&gt;(Landry, Pomerleau, &amp;amp; Giguère, 2019)&lt;/a&gt;, and a survey on different robust cost functions applied to ICP (Iterative Closest Point) &lt;a href=&quot;#Babin2019&quot;&gt;(Babin, Giguère, &amp;amp; Pomerleau, 2019)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;More details, and hopefully videos to come!&lt;/p&gt;

&lt;h1 id=&quot;our-articles&quot;&gt;Our articles&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Laconte2019&quot;&gt;Laconte, J., Deschênes, S.-P., Labussière, M., &amp;amp; Pomerleau, F. (2019). Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Laconte2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Landry2019&quot;&gt;Landry, D., Pomerleau, F., &amp;amp; Giguère, P. (2019). CELLO-3D: Estimating the Covariance of ICP in the Real World. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Landry2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Babin2019&quot;&gt;Babin, P., Giguère, P., &amp;amp; Pomerleau, F. (2019). Analysis of Robust Functions for Registration Algorithms. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="conference" /><summary type="html">We are happy to announce that we have three accepted publications at the 2019 International Conference on Robotics and Automation.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22/news/icra19/icra19_teaser.jpg%22%7D" /></entry><entry><title type="html">Vladimír Kubelka</title><link href="https://norlab.ulaval.ca/people/v_kubelka/" rel="alternate" type="text/html" title="Vladimír Kubelka" /><published>2019-02-21T00:00:00-05:00</published><updated>2019-02-21T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/people/v_kubelka</id><content type="html" xml:base="https://norlab.ulaval.ca/people/v_kubelka/">&lt;p&gt;Vladimír has received his master’s degree in Cybernetics and Robotics from the Czech Technical University in Prague (2013). The experiments for the master’s thesis were performed at the ASL lab (ETH Zurich) during his visiting student internship. After that, he continued as a Ph.D. student at CTU and focused on the problem of data fusion and state estimation for ground robots in harsh conditions. He had the opportunity to participate in two EU-funded  search and rescue projects &lt;a href=&quot;http://www.nifti.eu/&quot; target=&quot;_blank&quot;&gt;NIFTi&lt;/a&gt; and &lt;a href=&quot;http://www.tradr-project.eu/&quot; target=&quot;_blank&quot;&gt;TRADR&lt;/a&gt;. These projects offered real-world scenarios to test the localization algorithms. The main challenge were sensor outages (because of dark areas, smoke), unstable terrain and semi-structured environments (e.g., earthquake aftermath). He defended his Ph.D. thesis in 2018 (supervised by &lt;a href=&quot;https://sites.google.com/site/reinsmic&quot; target=&quot;_blank&quot;&gt;Michal Reinstein&lt;/a&gt; and &lt;a href=&quot;http://cmp.felk.cvut.cz/~svoboda/&quot; target=&quot;_blank&quot;&gt;Tomáš Svoboda&lt;/a&gt;) and enrolled as a postdoc fellow with the NORLAB. The Canadian winter brings new challenges for the ground mobile robots: deep snow, adversary conditions for optical sensors and changing terrain caused by wind and blizzards.&lt;/p&gt;

&lt;p&gt;His research topics are sensor fusion and state estimation for mobile ground robots. He is interested in the problems related to deployment of robots in harsh environments.&lt;/p&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/file/d/12CeiSDOmbEq74qiiiJG8GhfCNXyB24Cp/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Ph.D.&lt;/a&gt; in Artificial Intelligence and Biocybernetics - &lt;a href=&quot;https://www.cvut.cz/en&quot; target=&quot;_blank&quot;&gt;CTU in Prague&lt;/a&gt;, 2018&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/file/d/1kA04kmKFjoW7k5Jas_8xn0ivKFFsQRWb/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Ing.&lt;/a&gt; in Cybernetics and Robotics (Air and Space Systems) - &lt;a href=&quot;https://www.cvut.cz/en&quot; target=&quot;_blank&quot;&gt;CTU in Prague&lt;/a&gt;, 2013&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/file/d/18vtdAQDF4s1qFMwPujufjYuyXQ_VlfzI/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Bc.&lt;/a&gt; in Electrical Engineering (Cybernetics and Measurement) - &lt;a href=&quot;https://www.cvut.cz/en&quot; target=&quot;_blank&quot;&gt;CTU in Prague&lt;/a&gt;, 2011&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;h2 class=&quot;bibliography&quot;&gt;Journal Articles&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;kubelka2016improving&quot;&gt;Kubelka, V., Reinstein, M., &amp;amp; Svoboda, T. (2016). Improving multimodal data fusion for mobile robots by trajectory smoothing. &lt;i&gt;Robotics and Autonomous Systems&lt;/i&gt;, &lt;i&gt;84&lt;/i&gt;, 88–96.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/kubelka2016improving/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Pomerleau2015e&quot;&gt;Kubelka, V., Oswald, L., Pomerleau, F., Colas, F., Svoboda, T., &amp;amp; Reinstein, M. (2015). Robust data fusion of multimodal sensory information for mobile robots. &lt;i&gt;Journal of Field Robotics&lt;/i&gt;, &lt;i&gt;32&lt;/i&gt;(4), 447–473.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Pomerleau2015e/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;simanek2015evaluation&quot;&gt;Simanek, J., Reinstein, M., &amp;amp; Kubelka, V. (2015). Evaluation of the EKF-based estimation architectures for data fusion in mobile robots. &lt;i&gt;IEEE/ASME Transactions on Mechatronics&lt;/i&gt;, &lt;i&gt;20&lt;/i&gt;(2), 985–990.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/simanek2015evaluation/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;simanek2015improving&quot;&gt;Simanek, J., Kubelka, V., &amp;amp; Reinstein, M. (2015). Improving multi-modal data fusion by anomaly detection. &lt;i&gt;Autonomous Robots&lt;/i&gt;, &lt;i&gt;39&lt;/i&gt;(2), 139–154.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/simanek2015improving/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;
&lt;h2 class=&quot;bibliography&quot;&gt;Conference Articles&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;kruijff2016deployment&quot;&gt;Kruijff-Korbayová, I., Freda, L., Gianni, M., Ntouskos, V., Hlaváč, V., Kubelka, V., … others. (2016). Deployment of ground and aerial robots in earthquake-struck amatrice in italy (brief report). In &lt;i&gt;2016 IEEE international symposium on safety, security, and rescue robotics (SSRR)&lt;/i&gt; (pp. 278–279). IEEE.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/kruijff2016deployment/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;jirkuu2016wifi&quot;&gt;Jirku, M., Kubelka, V., &amp;amp; Reinstein, M. (2016). WiFi localization in 3D. In &lt;i&gt;2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)&lt;/i&gt; (pp. 4551–4557). IEEE.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/jirkuu2016wifi/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;kubelka2014combining&quot;&gt;Kubelka, V., &amp;amp; Reinstein, M. (2014). Combining Complementary Motion Estimation Approaches to Increase Reliability in Urban Search &amp;amp; Rescue Missions. In &lt;i&gt;International Workshop on Modelling and Simulation for Autonomous Systems&lt;/i&gt; (pp. 347–356). Springer, Cham.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/kubelka2014combining/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;reinstein2013terrain&quot;&gt;Reinstein, M., Kubelka, V., &amp;amp; Zimmermann, K. (2013). Terrain adaptive odometry for mobile skid-steer robots. In &lt;i&gt;2013 IEEE International Conference on Robotics and Automation&lt;/i&gt; (pp. 4706–4711). IEEE.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/reinstein2013terrain/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;kubelka2012complementary&quot;&gt;Kubelka, V., &amp;amp; Reinstein, M. (2012). Complementary filtering approach to orientation estimation using inertial sensors only. In &lt;i&gt;2012 IEEE international conference on robotics and automation&lt;/i&gt; (pp. 599–605). IEEE.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/kubelka2012complementary/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Vladimír Kubelka</name><email>vladimir.kubelka.1@ulaval.ca</email></author><summary type="html">Vladimír has received his master’s degree in Cybernetics and Robotics from the Czech Technical University in Prague (2013). The experiments for the master’s thesis were performed at the ASL lab (ETH Zurich) during his visiting student internship. After that, he continued as a Ph.D. student at CTU and focused on the problem of data fusion and state estimation for ground robots in harsh conditions. He had the opportunity to participate in two EU-funded search and rescue projects NIFTi and TRADR. These projects offered real-world scenarios to test the localization algorithms. The main challenge were sensor outages (because of dark areas, smoke), unstable terrain and semi-structured environments (e.g., earthquake aftermath). He defended his Ph.D. thesis in 2018 (supervised by Michal Reinstein and Tomáš Svoboda) and enrolled as a postdoc fellow with the NORLAB. The Canadian winter brings new challenges for the ground mobile robots: deep snow, adversary conditions for optical sensors and changing terrain caused by wind and blizzards.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/v_kubelka.jpg%22,%20%22teaser%22=%3E%22/people/v_kubelka_avatar.jpg%22%7D" /></entry><entry><title type="html">Survey on UAV, lidar and underground mapping</title><link href="https://norlab.ulaval.ca/publications/survey-lidar-UAV/" rel="alternate" type="text/html" title="Survey on UAV, lidar and underground mapping" /><published>2019-02-14T00:00:00-05:00</published><updated>2019-02-14T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/publications/survey-lidar-UAV</id><content type="html" xml:base="https://norlab.ulaval.ca/publications/survey-lidar-UAV/">&lt;p&gt;This survey presents an overall view of lidar (Light Detection And Ranging) used on UAV (Unmanned Aerial Vehicle) and their project.&lt;/p&gt;

&lt;p&gt;Nowadays, the number of projects which are using UAV with lidar are booming. 
Because of their ability to access areas that human can’t go and their ease of use, UAV are better able to give different interesting viewpoints than UGV (Unmanned Ground Vehicle). 
However, the use of lidar on UAV is still challenging and a lot of issues should be overcome. 
The pose of UAV, its speed and altitude, features of equipment and algorithms used significantly influence the accuracy of mapping. 
In this survey, we present a list of articles using lidar on UAV and give some details about the equipment and algorithms used in their publications. 
Considering the high number of articles, we divided this survey on seven categories:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#underground-mapping&quot;&gt;underground mapping&lt;/a&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#measure-with-airship&quot;&gt;measure with airship&lt;/a&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#pose-estimation-and-trajectory&quot;&gt;pose estimation and trajectory find with lidar&lt;/a&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#measure-some-features-of-the-environment&quot;&gt;measure some features of the environment&lt;/a&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#measure-some-objects&quot;&gt;measure of objects&lt;/a&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#lidar-test-on-uav&quot;&gt;lidar tests on UAV&lt;/a&gt;, and finally&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#algorithms-for-odometry-and-comparison-between-lidar-on-uav-and-ugv&quot;&gt;algorithms for odometry and comparison between lidar on UAV and UGV&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This is an ongoing survey. It will be regularly completed.
We hope that this information will be useful to the robotics community.
If we miss your paper or you find an error, don’t hesitate to contact us.&lt;/p&gt;

&lt;p&gt;Legend: “O” means present and “-“ means absent of the paper.&lt;/p&gt;

&lt;h3 id=&quot;underground-mapping&quot;&gt;Underground mapping&lt;/h3&gt;
&lt;div style=&quot;overflow-x: visible;&quot;&gt;
&lt;table class=&quot;large&quot;&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Article&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Subject&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;UAV&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;lidar&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Camera&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GPS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;IMU&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GNSS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;INS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Test&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Note&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Michael2012&quot;&gt;(Michael et al., 2012)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;3D mapping of earthquake-damaged building with collaborative ground and aerial robots&lt;/td&gt;
			&lt;td&gt;Pelican quadrotor&lt;/td&gt;
			&lt;td&gt;Hokuyo TM-30LX&lt;/td&gt;
			&lt;td&gt;Microsoft Kinect&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Indoor&lt;/td&gt;
			&lt;td&gt;UAV can travel on the UGV, ICP for mapping, SLAM for navigation&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Liu2015&quot;&gt;(Liu, Mohta, Shen, &amp;amp; Kumar, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Multiple UAV for 3D mapping&lt;/td&gt;
			&lt;td&gt;Pelican quadrotor&lt;/td&gt;
			&lt;td&gt;Hokuyo UTM-30LX&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Simulation and Indoor test&lt;/td&gt;
			&lt;td&gt;SLAM for navigation and path planning&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#AjayKumar2017&quot;&gt;(Ajay Kumar, Patil, Patil, Park, &amp;amp; Chai, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Reconstruction of indoor building with UAV and lidar to classify pipes&lt;/td&gt;
			&lt;td&gt;Phantom 3 advanced quadcopter&lt;/td&gt;
			&lt;td&gt;Hokuyo UTM-30LX, Hokuyo URG-04LX-UG01&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Indoor&lt;/td&gt;
			&lt;td&gt;ICP to merge data, use of Kalman filter to have position, classification of pipes by calculating the curvature of them&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Edwards2017&quot;&gt;(Edwards, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Scan of mine tunnel&lt;/td&gt;
			&lt;td&gt;Asctec Hummingbird&lt;/td&gt;
			&lt;td&gt;Z+F Imager S010 3D (terrestrial)&lt;/td&gt;
			&lt;td&gt;Xtion Pro live &lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Indoor&lt;/td&gt;
			&lt;td&gt;Comparison between Microsoft Kinect Fusion Algorithm to terrestrial lidar&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Vempati2017&quot;&gt;(Vempati, Gilitschenski, Nieto, Beardsley, &amp;amp; Siegwart, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Indoor 3D mapping in real-time with UAV&lt;/td&gt;
			&lt;td&gt;DJI M100&lt;/td&gt;
			&lt;td&gt;Leica Multistation MS50 (groundtruth for comparison)&lt;/td&gt;
			&lt;td&gt;Intel RealSense R200&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;DUO-MLX visual-inertial sensor&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;simulation and Indoor test&lt;/td&gt;
			&lt;td&gt;GPU parallelized SLAM to manage GPU memory ressources, 5mm resolution at 60Hz, extend Kalman filter, ICP for mapping&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Ozaslan2017&quot;&gt;(Ozaslan et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Inspection of tunnel and penstock with UAV&lt;/td&gt;
			&lt;td&gt;DJI F550&lt;/td&gt;
			&lt;td&gt;Velodyne Puck Lite&lt;/td&gt;
			&lt;td&gt;MChameleon 3 camera&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;PickHawk&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Indoor&lt;/td&gt;
			&lt;td&gt;Local mapping for state estimation&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Mascarich2018&quot;&gt;(Mascarich et al., 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Inspection of nuclear sites and tunnel with UAV&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Time of flight depth sensor&lt;/td&gt;
			&lt;td&gt;Chameleon 3 camera&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Indoor&lt;/td&gt;
			&lt;td&gt;Detection of radiation and it localization&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Papachristos2019&quot;&gt;(Papachristos, Khattak, Mascarich, &amp;amp; Alexis, 2019)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Autonomous Exploration and Mapping in Underground Mines&lt;/td&gt;
			&lt;td&gt;Quadrotor&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Indoor&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&quot;measure-with-airship&quot;&gt;Measure with airship&lt;/h3&gt;
&lt;div style=&quot;overflow-x: visible;&quot;&gt;
&lt;table class=&quot;large&quot;&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Article&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Subject&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;UAV&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;lidar&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Camera&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GPS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;IMU&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GNSS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;INS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Test&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Note&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Pan2015&quot;&gt;(Pan et al., 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;System to follow power lines in order to detect some issues&lt;/td&gt;
			&lt;td&gt;Small helium airship&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Koska2017&quot;&gt;(Koska et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Comparison between lidar on airship and camera on UAV&lt;/td&gt;
			&lt;td&gt;Airship ACC15X, 12m of length, 2.8m of diameter (57m^3), 15kg of payload&lt;/td&gt;
			&lt;td&gt;Sick LD-LRS1000 (2D rotating)&lt;/td&gt;
			&lt;td&gt;Canon EOS 100D, FLIR SC645&lt;/td&gt;
			&lt;td&gt;IMAR iTracer-F200&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Airship created by AirshipClub.com, issue of accuracy, issues with the structure but more accurate with airship on large area than UAV&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&quot;pose-estimation-and-trajectory&quot;&gt;Pose estimation and Trajectory&lt;/h3&gt;
&lt;div style=&quot;overflow-x: visible;&quot;&gt;
&lt;table class=&quot;large&quot;&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Article&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Subject&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;UAV&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;lidar&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Camera&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GPS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;IMU&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GNSS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;INS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Test&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Note&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Downs2004&quot;&gt;(Downs, Madhavan, &amp;amp; Hong, 2004)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Better estimation of UAV pose with Laser than GPS&lt;/td&gt;
			&lt;td&gt;Flying Eye&lt;/td&gt;
			&lt;td&gt;LADAR system (UAV) and LMS-Z420i ground&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;ICP to process 2 series of data, accuracy comparison between data obtained by UAV and terrestrial robot&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Hwang2012&quot;&gt;(Hwang &amp;amp; Tahk, 2012)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Measurement of UAV pose with lidar&lt;/td&gt;
			&lt;td&gt;Simulation of airplane&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Simulation in order to compare 2 algorithms for localization&lt;/td&gt;
			&lt;td&gt;lidar study the landscape, comparison between Kalman filter and Cross Correlation (which is better)&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Han2012&quot;&gt;(Han et al., 2012)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Measurement of the pose of a target relative to a UAV&lt;/td&gt;
			&lt;td&gt;Small airplane&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Pictures extracted of a database to test an algorithm for detection of outline, GPS and IMU to estimate position of UAV, ICP to process data, discussion about the number of ICP iteration and his effect on results&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Gee2017&quot;&gt;(Gee, James, Van Der Mark, Delmas, &amp;amp; Gimel’Farb, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Merge of some point clouds taken with lidar in order to use SLAM algorithm &lt;/td&gt;
			&lt;td&gt;DJI Phantom Quadcopter&lt;/td&gt;
			&lt;td&gt;Velodyne puck VLP-16&lt;/td&gt;
			&lt;td&gt;GoPro Hero 3+&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Reconstruction of data, static lidar on the ground (camera on UAV), curve fitting on points then ICP to process them and SLAM&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Shetty2017&quot;&gt;(Shetty &amp;amp; Gao, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;GPS and lidar merge of data to correct error of GPS in urban environment&lt;/td&gt;
			&lt;td&gt;Quadrotor&lt;/td&gt;
			&lt;td&gt;Velodyne VLP-16 puck Lite&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;LEA-6T GPS&lt;/td&gt;
			&lt;td&gt;Xsens-Mti-30 IMU&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Modelisation of point cloud covariance error, detection of UAV pose by Unscented Kalman filter, matching between lidar data and 3D city model, ICP to match the point clouds&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Zhen&quot;&gt;(Zhen &amp;amp; Scherer, n.d.)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Test a method with lidar and SLAM algorithm cross-platform for UAV (2D-3D)&lt;/td&gt;
			&lt;td&gt;DJI M100 DJI M600&lt;/td&gt;
			&lt;td&gt;Rotating Hokuyo Rotating Velodyne VLP-16&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Simulation and outdoor&lt;/td&gt;
			&lt;td&gt;Use of Kalman filter (ESKF) and Gaussian Particle Filter (GPF), slow speed to avoid error on position&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Youn2018&quot;&gt;(Youn, Kim, Kim, Yoo, &amp;amp; Lee, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Detection of environment in 3D to plan and watch over traffic in the sky and fly&lt;/td&gt;
			&lt;td&gt;Cessma 208B&lt;/td&gt;
			&lt;td&gt;ALS50-III&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Cut the world in cubic shape with fixed size (different level of cutting following 20 degrees of latitude), 20 level in all&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Gomes2018&quot;&gt;(Gomes, Guerreiro, Cunha, Silvestre, &amp;amp; Oliveira, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Measure of the trajectory derivation with data of lidar on UAV&lt;/td&gt;
			&lt;td&gt;Mikrokopter Quadro XL&lt;/td&gt;
			&lt;td&gt;Hokuyo UTM30LX&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Microstrain IMU&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Indoor&lt;/td&gt;
			&lt;td&gt;Methodology to detect some outline in point cloud, pose estimations&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&quot;measure-some-features-of-the-environment&quot;&gt;Measure some features of the environment&lt;/h3&gt;

&lt;div style=&quot;overflow-x: visible;&quot;&gt;
&lt;table class=&quot;large&quot;&gt;
	&lt;thead&gt;
		&lt;tr class=&quot;header&quot;&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Article&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Subject&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;UAV&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;lidar&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Camera&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GPS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;IMU&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GNSS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;INS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Test&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Note&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Liu2011&quot;&gt;(Liu, Li, Lei, Liu, &amp;amp; Wu, 2011)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Analyze of the ground with UAV and lidar to detect and anticipate some landslide&lt;/td&gt;
			&lt;td&gt;Helicopter&lt;/td&gt;
			&lt;td&gt;lidar on helicopter&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;DGPS&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Process some point clouds and pictures&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Durst2011&quot;&gt;(Durst, Baylot, &amp;amp; McKinley, 2011)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Use of drone and lidar to study some proprieties of roads (type of vehicule, curvature, height...)&lt;/td&gt;
			&lt;td&gt;Buckeye drone&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;The lidar measure the height of landscape, the roads are detected by processing on pictures&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Wallace2012&quot;&gt;(Wallace, Lucieer, Watson, &amp;amp; Turner, 2012)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Search to detect some trees in forest (e.g., height, position, diameter)&lt;/td&gt;
			&lt;td&gt;Oktokopter Droidworsc/Micropter AD-8 (terraLuma)&lt;/td&gt;
			&lt;td&gt;Ibeo LUX laser scanner&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Kalman filter to have position&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Wallace2012a&quot;&gt;(Wallace, Lucieer, &amp;amp; Watson, 2012)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Measurement the effect of ground environment and parameters to take some data about trees &lt;/td&gt;
			&lt;td&gt;Drone TerraLuma&lt;/td&gt;
			&lt;td&gt;Ibeo LUX laser scanner&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Candigliota2012&quot;&gt;(Candigliota, Immordino, Moretti, &amp;amp; Indirli, 2012)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Analyze the structure of city after an earthquarter to avoid some other damages&lt;/td&gt;
			&lt;td&gt;Quadrotor&lt;/td&gt;
			&lt;td&gt;Leica Geosystems HDS 3000&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;DGPS&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;ICP to process the data&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Zhou2013&quot;&gt;(Zhou et al., 2013)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Use different altitudes and speed to take some data about landscape&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Wallace2013&quot;&gt;(Wallace, 2013)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Test some new features to analyze the structure of forest in probabilistic way&lt;/td&gt;
			&lt;td&gt;Drone TerraLuma&lt;/td&gt;
			&lt;td&gt;Ibeo LUX laser scanner&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Roca2014&quot;&gt;(Roca, Armesto, Lagüela, &amp;amp; Díaz-Vilariño, 2014)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Test of UAV with lidar to measure a ground&lt;/td&gt;
			&lt;td&gt;Hisystems GmbH&lt;/td&gt;
			&lt;td&gt;Hokuyo UTM-30LX&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Kalman filter to estimate the pose, tests , test carry out on a house&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Esposito2014&quot;&gt;(Esposito et al., 2014)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Measurement the features of trees (e.g., height, form) to validate the working of a lidar on a UAV &lt;/td&gt;
			&lt;td&gt;Ultralight helicopter&lt;/td&gt;
			&lt;td&gt;YellowScan lidar&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Wallace2014&quot;&gt;(Wallace, Lucieer, &amp;amp; Watson, 2014)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Measurement the influence of algorithms to detection and density of points on the accuracy to detect trees and their features&lt;/td&gt;
			&lt;td&gt;Drone TerraLuma&lt;/td&gt;
			&lt;td&gt;Ibeo LUX laser scanner&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Ni2015&quot;&gt;(Ni, Liu, Zhang, Sun, &amp;amp; Yang, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Do the inventory of forest with UAV and lidar&lt;/td&gt;
			&lt;td&gt;Yun-5 aircraft&lt;/td&gt;
			&lt;td&gt;Leica ALS 60&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Mandlburger2015&quot;&gt;(Mandlburger et al., 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Analyze the features of waterway with UAV and lidar (dynamic, delimitation...)&lt;/td&gt;
			&lt;td&gt;Ricopter UAV&lt;/td&gt;
			&lt;td&gt;Riegl VUX-Sys, VUX-1, VQ-880-G&lt;/td&gt;
			&lt;td&gt;Sony Alpha 6000 RGB&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Reiss2016&quot;&gt;(Reiss et al., 2016)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Scan and record some ruins with lidar on UAV &lt;/td&gt;
			&lt;td&gt;Asctec Falcon 8, Sensefly e-Bee&lt;/td&gt;
			&lt;td&gt;Faro Focus 3D S-120 (UAV), Optec 3D-HD ILRIS (terrestrial)&lt;/td&gt;
			&lt;td&gt;Sony Alpha 6000 RGB&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Merge of terrestrial data and flying photogrametry&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Guo2017&quot;&gt;(Guo et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Scan forest with UAV and lidar&lt;/td&gt;
			&lt;td&gt;8 rotor UAV&lt;/td&gt;
			&lt;td&gt;Velodyne puck VLP-16&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Novatel IMU&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Calibration of equipments, obtaining different features on forest&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Wei2017&quot;&gt;(Wei, Yang, Jiang, Cao, &amp;amp; Wu, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Filter the effect of vegetation to measure the landscape&lt;/td&gt;
			&lt;td&gt;8 rotor UAV&lt;/td&gt;
			&lt;td&gt;Riegl VUX-1&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Trimble Applanix AP20-IMU&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Chiang2017&quot;&gt;(Chiang, Tsai, Li, &amp;amp; El-Sheimy, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Reconstruction of building with UAV and lidar&lt;/td&gt;
			&lt;td&gt;Small helicopter&lt;/td&gt;
			&lt;td&gt;Velodyne lidar VLP-16&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;C-Migits III&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;New strategy of ICP in order to process the deformation of point cloud, use of Kalman filter for data, comparison with terrestrial lidar&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Chen2017&quot;&gt;(Chen, McDermid, Castilla, &amp;amp; Linke, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Measurement of the northern vegetation with UAV and lidar&lt;/td&gt;
			&lt;td&gt;Quadcopter&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Measurement of vegetation height, RTK GNSS use for localization, use of database lidar data, backcross of data to generate a map of measurments&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Sankey2017&quot;&gt;(Sankey, Donager, McVay, &amp;amp; Sankey, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Scan of forest with UAV and lidar&lt;/td&gt;
			&lt;td&gt;Octocopter aircraft&lt;/td&gt;
			&lt;td&gt;Velodyne HDL-32E (UAV), Riegl VZ-1000(terrestrial)&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Comparison with terrestrial lidar, determination of tree species founded according to the reflectance of laser, limited by the density of trees&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Christiansen2017&quot;&gt;(Christiansen, Laursen, Jørgensen, Skovsen, &amp;amp; Gislum, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Scan and measure the height of croops with UAV and lidar&lt;/td&gt;
			&lt;td&gt;DJI Matrice-100 quadcopter&lt;/td&gt;
			&lt;td&gt;Velodyne VLP-16&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;VN-200 IMU&lt;/td&gt;
			&lt;td&gt;Trimble BD920 GNSS&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Process the data to isolate croops and measure their height, high dependancy to GPS values&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Gawel2017&quot;&gt;(Gawel et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Do the scan of a disaster area with UAV and lidar, then send the data to some UGV for SLAM algorithm&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Use of extend Kalman filter for position, ICP to merge data from lidar on UGV and UAV&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Elaksher2017&quot;&gt;(Elaksher, Bhandari, Carreon Limones, &amp;amp; Lauf, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Scan of croops or ground with UAV and lidar&lt;/td&gt;
			&lt;td&gt;DJI S900 hexacopter&lt;/td&gt;
			&lt;td&gt;Velodyne VLP-16&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Classification of data (ground of vegetation)&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#PututAshShidiq2017&quot;&gt;(Putut Ash Shidiq et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Topography of forest with UAV and lidar to differentiate ground and trees&lt;/td&gt;
			&lt;td&gt;DJI Matrice-600&lt;/td&gt;
			&lt;td&gt;YellowScan lidar&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Morsdorf2017&quot;&gt;(Morsdorf et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Topography of forest with UAV and lidar compare to terrrestrial lidar&lt;/td&gt;
			&lt;td&gt;Scout B1-100 helicopter&lt;/td&gt;
			&lt;td&gt;Riegl VUX-1UAV (drone), Riegl VZ1000 (terrestrial)&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;XTS xNAV550 GPS&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Speed of 4 m/s, error of 1 m on the height of trees&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Thiel2017&quot;&gt;(Thiel &amp;amp; Schmullius, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Comparison between point cloud obtained by camera on UAV and lidar on UGV, to find features of forest &lt;/td&gt;
			&lt;td&gt;Geocopter X8000&lt;/td&gt;
			&lt;td&gt;Riegl VZ 1000 TLS (terrestrial)&lt;/td&gt;
			&lt;td&gt;Sony NEX-7 RGB&lt;/td&gt;
			&lt;td&gt;DGPS&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Frame of maxima, height of canopy and level of detection, speed of 8 m/s for UAV, comparison with terrestrial lidar, process of data to have features of forests&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Huang2018&quot;&gt;(Huang, Yeh, Tseng, &amp;amp; Hsu, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Measure the propiety of see wave, change of coast and tide with UAV and lidar&lt;/td&gt;
			&lt;td&gt;DJI S1000&lt;/td&gt;
			&lt;td&gt;Hokuyo UTM-30LX&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Xsens-Mti-30 IMU&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;RTK GNSS for localization, calibration and measurements of data, comparison of lidar data with pressure sensor Doppler Velocimetry (Son Tek ADV-Oceans)&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Cramer2018&quot;&gt;(Cramer, Haala, Laupheimer, Mandlburger, &amp;amp; Havel, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Measure the ground and landscape with high accuracy by lidar on UAV (3-5mm)&lt;/td&gt;
			&lt;td&gt;Ricopter multi-copter pateforme&lt;/td&gt;
			&lt;td&gt;Riegl VUX-1LR&lt;/td&gt;
			&lt;td&gt;Sony Alpha 6000 RGB&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Speed of 8 m/s for UAV, altitude of 50m, comparison with terrestrial data by tacheometry&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Govedarica2018&quot;&gt;(Govedarica, Jakovljevic, &amp;amp; Álvarez Taboada, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Study of flood risk with UAV and lidar&lt;/td&gt;
			&lt;td&gt;WingtraOno drone&lt;/td&gt;
			&lt;td&gt;LMS-Q680i-Full (airplane)&lt;/td&gt;
			&lt;td&gt;42 MP Sony RX1RII&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;DEM technics (digital elevation models), lidar as reference for camera&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Hinterhofer2018&quot;&gt;(Hinterhofer et al., 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Use a UAV and lidar on nuclear disaster area&lt;/td&gt;
			&lt;td&gt;Ricopter-M&lt;/td&gt;
			&lt;td&gt;Riegl VUX-1UAV &lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Mapping the field and measure the gamma rate of radiation&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Yan2018&quot;&gt;(Yan et al., 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Measure of forest production by UAV and lidar&lt;/td&gt;
			&lt;td&gt;GV 1300 multirotor &lt;/td&gt;
			&lt;td&gt;Velodyne VLP-16E&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;IMU-IGM-S1&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Segmentation of trees by algorithms&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Liu2018&quot;&gt;(Liu, Shen, Cao, Wang, &amp;amp; Cao, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Measure the stucture of forest with UAV and lidar&lt;/td&gt;
			&lt;td&gt;GV 1900 multi-rotor UAV&lt;/td&gt;
			&lt;td&gt;Velodyne puck VLP-16&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;IMU-IGM-S1&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Polewski2019&quot;&gt;(Polewski, Yao, Cao, &amp;amp; Gao, 2019)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Methodology to have position of tree by using point cloud obtained by UAV and UGV&lt;/td&gt;
			&lt;td&gt;Quadrotor&lt;/td&gt;
			&lt;td&gt;Velodyne puck VLP-16 (UAV), velodyne puck VLP-16 (UGV)&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;GPS Novatel (UAV)&lt;/td&gt;
			&lt;td&gt;IMU Novatel SPAN-MEMS (UAV)&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;POS (UGV)&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Terrestrial lidar in bag carry by person during tests&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&quot;measure-some-objects&quot;&gt;Measure some objects&lt;/h3&gt;
&lt;div style=&quot;overflow-x: visible;&quot;&gt;
&lt;table class=&quot;large&quot;&gt;
	&lt;thead&gt;
		&lt;tr class=&quot;header&quot;&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Article&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Subject&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;UAV&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;lidar&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Camera&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GPS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;IMU&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GNSS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;INS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Test&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Note&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Lin2014&quot;&gt;(Lin &amp;amp; West, 2014)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Measurement and scan of objects with oblique geomety&lt;/td&gt;
			&lt;td&gt;Microdrone md4-200&lt;/td&gt;
			&lt;td&gt;Sensei MLS system (UAV), Ibeo Lux Laser (véhicule terrestre)&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Merge of data came from UAV and UGV&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Gu2015&quot;&gt;(Gu &amp;amp; Zhang, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Locate some objects with a fast platform and lidar&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Increase the speed of algorithms with K-d tree and AK-d tree, altitude too high imply less performance&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Moore2017&quot;&gt;(Moore et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Inspection of power lines with UAV&lt;/td&gt;
			&lt;td&gt;Octorotor&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Addition of lidar to avoid collision and make path planning, use of several drones to follow the lines, transformation of lidar data in polygominal shape, avoiding drone collisions in real time&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Teng2017&quot;&gt;(Teng et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Inspection of power lines with UAV&lt;/td&gt;
			&lt;td&gt;Hexarotor&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Isolate of lidar the air vibrations, detection of sagging power lines&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Nikolov2017&quot;&gt;(Nikolov &amp;amp; Madsen, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Inspection of wind turbine pale with UAV and lidar&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;RPlidar&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;BNO055g-DOF IMU&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Simplification in 2D of the pale shape&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Chen2018&quot;&gt;(Chen, Yang, Song, Peng, &amp;amp; Huang, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Measure of distance anomaly between power lines and ground&lt;/td&gt;
			&lt;td&gt;Drone mini helicopter&lt;/td&gt;
			&lt;td&gt;Riegl VZ400&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;POS&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Algorithm to differentiate ground and cable, measurement of cable curvature&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&quot;lidar-test-on-uav&quot;&gt;lidar test on UAV&lt;/h3&gt;

&lt;div style=&quot;overflow-x: visible;&quot;&gt;
&lt;table class=&quot;large&quot;&gt;
	&lt;thead&gt;
		&lt;tr class=&quot;header&quot;&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Article&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Subject&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;UAV&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;lidar&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Camera&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GPS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;IMU&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GNSS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;INS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Test&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Note&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Li2015&quot;&gt;(Li, Yan, Jing, &amp;amp; Zhao, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Analyze vibrations of differents UAV in order to use a lidar on it&lt;/td&gt;
			&lt;td&gt;Gasoline helicopter&lt;/td&gt;
			&lt;td&gt;HDL-32 lidar&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Selection of an adapted rotor, measurement and attenuation of vibrations with IMU&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Tulldahl2015&quot;&gt;(Tulldahl, Bissmarck, Larsson, Grönwall, &amp;amp; Tolt, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Evaluate the accuracy of lidar on UAV&lt;/td&gt;
			&lt;td&gt;Tarot-810 hexacopter&lt;/td&gt;
			&lt;td&gt;Velodyne HDL-32E&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Process the data (dynamic calibration)&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Yang2015&quot;&gt;(Yang &amp;amp; Chen, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Use of lidar on mini-UAV&lt;/td&gt;
			&lt;td&gt;Rotor wing mini UAV&lt;/td&gt;
			&lt;td&gt;Riegl LMS-Q160&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Process of data to have the shape of objects founded by lidar(ICP), merge of shape, points and picture obtained by the pose of UAV and lidar&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Kasturi2016&quot;&gt;(Kasturi, Milanovic, Atwood, &amp;amp; Yang, 2016)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Developpment of mini scanner for drone with MEMS (optical and mirror components)&lt;/td&gt;
			&lt;td&gt;DJI Phantom II&lt;/td&gt;
			&lt;td&gt;Playzer&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Indoor&lt;/td&gt;
			&lt;td&gt;Test of the prototype, different modes of scanning by laser, different modes to take measurements, objects tracking by laser, android bluetooth control of Playzer&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Mastrangelo2018&quot;&gt;(Mastrangelo, von Niederhausern, Nelson, &amp;amp; Fuller, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Obtain and access to 3D images in real time on UAV&lt;/td&gt;
			&lt;td&gt;LASE drone&lt;/td&gt;
			&lt;td&gt;ASC TigerCub camera, Arete AirTrac laser, Sentech color camera, Hood Tech gimbal&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Acquisition of data with pose correction&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Torresan2018&quot;&gt;(Torresan et al., 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Integration of lidar on UAV then measure the performances&lt;/td&gt;
			&lt;td&gt;Hexarotor&lt;/td&gt;
			&lt;td&gt;LUX 4L&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;VN-300 GNSS&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Use of extend Kalman filter for position, calibration of measurements, study on accuracy and efficiency of GNSS&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Nasrollahi2018&quot;&gt;(Nasrollahi, Bolourian, Zhu, &amp;amp; Hammad, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Design lidar-equipped UAV for structural inspection&lt;/td&gt;
			&lt;td&gt;DJI Matrice 100&lt;/td&gt;
			&lt;td&gt;Hokuyo UTM-30LX&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Indoor&lt;/td&gt;
			&lt;td&gt;Stationnary mode to test 3D mapping&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&quot;algorithms-for-odometry-and-comparison-between-lidar-on-uav-and-ugv&quot;&gt;Algorithms for odometry and comparison between lidar on UAV and UGV&lt;/h3&gt;

&lt;div style=&quot;overflow-x: visible;&quot;&gt;
&lt;table class=&quot;large&quot;&gt;
	&lt;thead&gt;
		&lt;tr class=&quot;header&quot;&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Article&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Subject&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;UAV&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;lidar&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Camera&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GPS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;IMU&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GNSS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;INS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Test&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Note&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Tulldahl2014&quot;&gt;(Tulldahl &amp;amp; Larsson, 2014)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Comparison of lidar data on UAV to terrestrial lidar&lt;/td&gt;
			&lt;td&gt;Tarot-810 hexacopter&lt;/td&gt;
			&lt;td&gt;Velodyne HDL-32E&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;MEMS-IMU&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Comparison with terrestrial lidar on vehicule and a static one&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Yousif2015&quot;&gt;(Yousif, Bab-Hadiashar, &amp;amp; Hoseinnezhad, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Description of algorithms and strategy use for odometry&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Survey&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Lawson2015&quot;&gt;(Lawson, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Merge of some point cloud obtained by multiple UAV&lt;/td&gt;
			&lt;td&gt;Quadrocopter&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Kinect RGB&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Indoor with 2 drones&lt;/td&gt;
			&lt;td&gt;Generation of a point cloud given to a algorithm which merge data using ICP, need of several overlap to have better results&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Petras2016&quot;&gt;(Petras, Petrasova, Jeziorska, &amp;amp; Mitasova, 2016)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Use of data obtained by UAV with lidar with a software call Grass GIS&lt;/td&gt;
			&lt;td&gt;Airplane&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Microsoft Kinect&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Focus on process data, density of points test to decrease the number of redundant points&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Gasparovic2017&quot;&gt;(Gašparović, Seletković, Berta, &amp;amp; Balenović, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Evaluation of data taken by UAV and lidar during non-optimal conditions (wind, cloud, density of points,...)&lt;/td&gt;
			&lt;td&gt;DJI Phantom 4 Pro and airplane Pilatus P6 aircraft&lt;/td&gt;
			&lt;td&gt;Optech ALTM Gemini 167 (airplane)&lt;/td&gt;
			&lt;td&gt;FC6310 camera (drone)&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Correlation between pictures and lidar data&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Persad2017&quot;&gt;(Persad &amp;amp; Armenakis, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Comparison of approach to merge data collected by different systems (UAV lidar and terrestrial lidar)&lt;/td&gt;
			&lt;td&gt;Geo-X8000&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;Results depend a lot of point clouds configuration and parameters&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Kwon2017&quot;&gt;(Kwon, Park, Moon, Jung, &amp;amp; Park, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Fast merge of atypical 3D data in different situations on construction site (lidar on UAV and terrestrial lidar)&lt;/td&gt;
			&lt;td&gt;DJI Phantom 3 avanced&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;RTK for pose estimations&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Fuad2018&quot;&gt;(Fuad et al., 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Influence of altitude on measure accuracy &lt;/td&gt;
			&lt;td&gt;AL3 S1000&lt;/td&gt;
			&lt;td&gt;AL3-32&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;More the altitude increase (20m, 40m, 60m) more the precision decrease (RMS 0.323m, 0.450m, 0.616m)&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Park2019&quot;&gt;(Park, Kim, Cho, &amp;amp; Kang, 2019)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Merge of data obtained by different platform and different sensors (on UAV and UGV)&lt;/td&gt;
			&lt;td&gt;Quadrotor and UGV&lt;/td&gt;
			&lt;td&gt;O (UGV)&lt;/td&gt;
			&lt;td&gt;Camera (UAV)&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Outdoor&lt;/td&gt;
			&lt;td&gt;ICP to process data, SLAM for UGV, elimination of redundant points then ICP, the drone should take picture between 30 and 90 degrees to optimize results&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Polewski2019&quot;&gt;Polewski, P., Yao, W., Cao, L., &amp;amp; Gao, S. (2019). Marker-free coregistration of UAV and backpack LiDAR point clouds in forested areas. &lt;i&gt;ISPRS Journal of Photogrammetry and Remote Sensing&lt;/i&gt;, &lt;i&gt;147&lt;/i&gt;(July 2018), 307–318. https://doi.org/10.1016/j.isprsjprs.2018.11.020&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Polewski2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Papachristos2019&quot;&gt;Papachristos, C., Khattak, S., Mascarich, F., &amp;amp; Alexis, K. (2019). &lt;i&gt;Autonomous Navigation and Mapping in Underground Mines Using Aerial Robots&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Papachristos2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Park2019&quot;&gt;Park, J., Kim, P., Cho, Y. K., &amp;amp; Kang, J. (2019). Framework for automated registration of UAV and UGV point clouds using local features in images. &lt;i&gt;Automation in Construction&lt;/i&gt;, &lt;i&gt;98&lt;/i&gt;(November 2018), 175–182. https://doi.org/10.1016/j.autcon.2018.11.024&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Park2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Cramer2018&quot;&gt;Cramer, M., Haala, N., Laupheimer, D., Mandlburger, G., &amp;amp; Havel, P. (2018). Ultra-High Precision Uav-Based Lidar and Dense Image Matching, &lt;i&gt;XLII&lt;/i&gt;(October), 10–12.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Cramer2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Gomes2018&quot;&gt;Gomes, A., Guerreiro, B. J., Cunha, R., Silvestre, C., &amp;amp; Oliveira, P. (2018). Sensor-based 3-D pose estimation and control of rotary-wing UAVs using a 2-D LiDAR. &lt;i&gt;Advances in Intelligent Systems and Computing&lt;/i&gt;, &lt;i&gt;693&lt;/i&gt;, 718–729. https://doi.org/10.1007/978-3-319-70833-1_58&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Gomes2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Hinterhofer2018&quot;&gt;Hinterhofer, T., Ullrich, A., Hofstätter, M., Pfennigbauer, M., Schraml, S., &amp;amp; Rothbacher, D. (2018). UAV-based LiDAR and gamma probe with real-time data processing and downlink for survey of nuclear disaster locations. &lt;i&gt;Chemical, Biological, Radiological, Nuclear, and Explosives (CBRNE) Sensing XIX&lt;/i&gt;, (May 2018), 11. https://doi.org/10.1117/12.2304353&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Hinterhofer2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Mastrangelo2018&quot;&gt;Mastrangelo, J., von Niederhausern, K., Nelson, R. D., &amp;amp; Fuller, D. (2018). Real-time LIDAR from ScanEagle UAV. &lt;i&gt;Ground/Air Multisensor Interoperability, Integration, and Networking for Persistent ISR IX&lt;/i&gt;, (May 2018), 33. https://doi.org/10.1117/12.2304393&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Mastrangelo2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Fuad2018&quot;&gt;Fuad, N. A., Ismail, Z., Majid, Z., Darwin, N., Ariff, M. F. M., Idris, K. M., &amp;amp; Yusoff, A. R. (2018). Accuracy evaluation of digital terrain model based on different flying altitudes and conditional of terrain using UAV LiDAR technology. &lt;i&gt;IOP Conference Series: Earth and Environmental Science&lt;/i&gt;, &lt;i&gt;169&lt;/i&gt;(1). https://doi.org/10.1088/1755-1315/169/1/012100&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Fuad2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Youn2018&quot;&gt;Youn, J., Kim, D., Kim, T., Yoo, J. H., &amp;amp; Lee, B. J. (2018). Development of Uav Air Roads By Using 3D Grid System. &lt;i&gt;ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences&lt;/i&gt;, &lt;i&gt;XLII-4&lt;/i&gt;(October), 731–735. https://doi.org/10.5194/isprs-archives-XLII-4-731-2018&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Youn2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Liu2018&quot;&gt;Liu, K., Shen, X., Cao, L., Wang, G., &amp;amp; Cao, F. (2018). Estimating forest structural attributes using UAV-LiDAR data in Ginkgo plantations. &lt;i&gt;ISPRS Journal of Photogrammetry and Remote Sensing&lt;/i&gt;, &lt;i&gt;146&lt;/i&gt;(November), 465–482. https://doi.org/10.1016/j.isprsjprs.2018.11.001&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Liu2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Huang2018&quot;&gt;Huang, Z. C., Yeh, C. Y., Tseng, K. H., &amp;amp; Hsu, W. Y. (2018). A UAV-RTK lidar system for wave and tide measurements in coastal zones. &lt;i&gt;Journal of Atmospheric and Oceanic Technology&lt;/i&gt;, &lt;i&gt;35&lt;/i&gt;(8), 1557–1570. https://doi.org/10.1175/JTECH-D-17-0199.1&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Huang2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Yan2018&quot;&gt;Yan, W., Guan, H., Cao, L., Yu, Y., Gao, S., Lu, J. Y., … Lu, J. Y. (2018). An Automated Hierarchical Approach for Three-Dimensional Segmentation of Single Trees Using UAV LiDAR Data. &lt;i&gt;Remote Sensing&lt;/i&gt;, &lt;i&gt;10&lt;/i&gt;(12), 1999. https://doi.org/10.3390/rs10121999&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Yan2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Chen2018&quot;&gt;Chen, C., Yang, B., Song, S., Peng, X., &amp;amp; Huang, R. (2018). Automatic clearance anomaly detection for transmission line corridors utilizing UAV-Borne LIDAR data. &lt;i&gt;Remote Sensing&lt;/i&gt;, &lt;i&gt;10&lt;/i&gt;(4). https://doi.org/10.3390/rs10040613&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Chen2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Govedarica2018&quot;&gt;Govedarica, M., Jakovljevic, G., &amp;amp; Álvarez Taboada, F. (2018). Flood risk assessment based on LiDAR and UAV points clouds and DEM. &lt;i&gt;Remote Sensing for Agriculture, Ecosystems, and Hydrology XX&lt;/i&gt;, (October 2018), 102. https://doi.org/10.1117/12.2513278&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Govedarica2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Torresan2018&quot;&gt;Torresan, C., Berton, A., Carotenuto, F., Chiavetta, U., Miglietta, F., Zaldei, A., &amp;amp; Gioli, B. (2018). Development and performance assessment of a low-cost UAV laser scanner system (LasUAV). &lt;i&gt;Remote Sensing&lt;/i&gt;, &lt;i&gt;10&lt;/i&gt;(7), 1–17. https://doi.org/10.3390/rs10071094&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Torresan2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Mascarich2018&quot;&gt;Mascarich, F., Wilson, T., Khattak, S., Dang, T., Papachristos, C., &amp;amp; Alexis, K. (2018). WM2018 Conference, March 18 – 22, 2018, Phoenix, Arizona, USA Autonomous 3D and Radiation Mapping in Tunnel Environments Using Aerial Robots – 18156 Frank Mascarich, Taylor Wilson, Shehryar Khattak, Tung Dang, Christos Papachristos, Kostas Alexis Universi, 1–12.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Mascarich2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Nasrollahi2018&quot;&gt;Nasrollahi, M., Bolourian, N., Zhu, Z., &amp;amp; Hammad, A. (2018). Designing LiDAR-equipped UAV Platform for Structural Inspection. &lt;i&gt;Proceedings of the 35th International Symposium on Automation and Robotics in Construction (ISARC)&lt;/i&gt;, (July). https://doi.org/10.22260/isarc2018/0152&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Nasrollahi2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Teng2017&quot;&gt;Teng, G. E., Zhou, M., Li, C. R., Wu, H. H., Li, W., Meng, F. R., … Ma, L. (2017). Mini-UAV LIDAR for power line inspection. &lt;i&gt;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives&lt;/i&gt;, &lt;i&gt;42&lt;/i&gt;(2W7), 297–300. https://doi.org/10.5194/isprs-archives-XLII-2-W7-297-2017&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Teng2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Morsdorf2017&quot;&gt;Morsdorf, F., Eck, C., Zgraggen, C., Imbach, B., Schneider, F. D., &amp;amp; Kükenbrink, D. (2017). UAV-based LiDAR acquisition for the derivation of high-resolution forest and ground information. &lt;i&gt;The Leading Edge&lt;/i&gt;, &lt;i&gt;36&lt;/i&gt;(7), 566–570. https://doi.org/10.1190/tle36070566.1&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Morsdorf2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Gawel2017&quot;&gt;Gawel, A., Dube, R., Surmann, H., Nieto, J., Siegwart, R., &amp;amp; Cadena, C. (2017). 3D registration of aerial and ground robots for disaster response: An evaluation of features, descriptors, and transformation estimation. &lt;i&gt;SSRR 2017 - 15th IEEE International Symposium on Safety, Security and Rescue Robotics, Conference&lt;/i&gt;, 27–34. https://doi.org/10.1109/SSRR.2017.8088136&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Gawel2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Gasparovic2017&quot;&gt;Gašparović, M., Seletković, A., Berta, A., &amp;amp; Balenović, I. (2017). The Evaluation of Photogrammetry-Based DSM from Low-Cost UAV by LiDAR-Based DSM. &lt;i&gt;South-East European Forestry&lt;/i&gt;, &lt;i&gt;8&lt;/i&gt;(2). https://doi.org/10.15177/seefor.17-16&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Gasparovic2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Christiansen2017&quot;&gt;Christiansen, M. P., Laursen, M. S., Jørgensen, R. N., Skovsen, S., &amp;amp; Gislum, R. (2017). Designing and testing a UAV mapping system for agricultural field surveying. &lt;i&gt;Sensors (Switzerland)&lt;/i&gt;, &lt;i&gt;17&lt;/i&gt;(12), 1–19. https://doi.org/10.3390/s17122703&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Christiansen2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;AjayKumar2017&quot;&gt;Ajay Kumar, G., Patil, A. K., Patil, R., Park, S. S., &amp;amp; Chai, Y. H. (2017). A LiDAR and IMU integrated indoor navigation system for UAVs and its application in real-time pipeline classification. &lt;i&gt;Sensors (Switzerland)&lt;/i&gt;, &lt;i&gt;17&lt;/i&gt;(6). https://doi.org/10.3390/s17061268&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/AjayKumar2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Sankey2017&quot;&gt;Sankey, T., Donager, J., McVay, J., &amp;amp; Sankey, J. B. (2017). UAV lidar and hyperspectral fusion for forest monitoring in the southwestern USA. &lt;i&gt;Remote Sensing of Environment&lt;/i&gt;, &lt;i&gt;195&lt;/i&gt;, 30–43. https://doi.org/10.1016/j.rse.2017.04.007&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Sankey2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Chen2017&quot;&gt;Chen, S., McDermid, G. J., Castilla, G., &amp;amp; Linke, J. (2017). Measuring vegetation height in linear disturbances in the boreal forest with UAV photogrammetry. &lt;i&gt;Remote Sensing&lt;/i&gt;, &lt;i&gt;9&lt;/i&gt;(12). https://doi.org/10.3390/rs9121257&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Chen2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Nikolov2017&quot;&gt;Nikolov, I., &amp;amp; Madsen, C. (2017). LiDAR-based 2D Localization and Mapping System using Elliptical Distance Correction Models for UAV Wind Turbine Blade Inspection. &lt;i&gt;Proceedings of the 12th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications&lt;/i&gt;, (Visigrapp), 418–425. https://doi.org/10.5220/0006124304180425&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Nikolov2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Kwon2017&quot;&gt;Kwon, S., Park, J. W., Moon, D., Jung, S., &amp;amp; Park, H. (2017). Smart Merging Method for Hybrid Point Cloud Data using UAV and LIDAR in Earthwork Construction. &lt;i&gt;Procedia Engineering&lt;/i&gt;, &lt;i&gt;196&lt;/i&gt;(June), 21–28. https://doi.org/10.1016/j.proeng.2017.07.168&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Kwon2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Elaksher2017&quot;&gt;Elaksher, A., Bhandari, S., Carreon Limones, C. A., &amp;amp; Lauf, R. (2017). Potential of UAV lidar systems for geospatial mapping. &lt;i&gt;Lidar Remote Sensing for Environmental Monitoring 2017&lt;/i&gt;, (August 2017), 20. https://doi.org/10.1117/12.2275482&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Elaksher2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;PututAshShidiq2017&quot;&gt;Putut Ash Shidiq, I., Wibowo, A., Kusratmoko, E., Indratmoko, S., Ardhianto, R., &amp;amp; Prasetyo Nugroho, B. (2017). Urban forest topographical mapping using UAV LIDAR. &lt;i&gt;IOP Conference Series: Earth and Environmental Science&lt;/i&gt;, &lt;i&gt;98&lt;/i&gt;(1). https://doi.org/10.1088/1755-1315/98/1/012034&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/PututAshShidiq2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Guo2017&quot;&gt;Guo, Q., Su, Y., Hu, T., Zhao, X., Wu, F., Li, Y., … Wang, X. (2017). An integrated UAV-borne lidar system for 3D habitat mapping in three forest ecosystems across China. &lt;i&gt;International Journal of Remote Sensing&lt;/i&gt;, &lt;i&gt;38&lt;/i&gt;(8-10), 2954–2972. https://doi.org/10.1080/01431161.2017.1285083&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Guo2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Wei2017&quot;&gt;Wei, L., Yang, B., Jiang, J., Cao, G., &amp;amp; Wu, M. (2017). Vegetation filtering algorithm for UAV-borne lidar point clouds: a case study in the middle-lower Yangtze River riparian zone. &lt;i&gt;International Journal of Remote Sensing&lt;/i&gt;, &lt;i&gt;38&lt;/i&gt;(8-10), 2991–3002. https://doi.org/10.1080/01431161.2016.1252476&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Wei2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Thiel2017&quot;&gt;Thiel, C., &amp;amp; Schmullius, C. (2017). Comparison of UAV photograph-based and airborne lidar-based point clouds over forest from a forestry application perspective. &lt;i&gt;International Journal of Remote Sensing&lt;/i&gt;, &lt;i&gt;38&lt;/i&gt;(8-10), 2411–2426. https://doi.org/10.1080/01431161.2016.1225181&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Thiel2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Gee2017&quot;&gt;Gee, T., James, J., Van Der Mark, W., Delmas, P., &amp;amp; Gimel’Farb, G. (2017). Lidar guided stereo simultaneous localization and mapping (SLAM) for UAV outdoor 3-D scene reconstruction. &lt;i&gt;International Conference Image and Vision Computing New Zealand&lt;/i&gt;, 1–6. https://doi.org/10.1109/IVCNZ.2016.7804433&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Gee2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Persad2017&quot;&gt;Persad, R. A., &amp;amp; Armenakis, C. (2017). Comparison of 2d and 3D approaches for the alignment of UAV and lidar point clouds. &lt;i&gt;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives&lt;/i&gt;, &lt;i&gt;42&lt;/i&gt;(2W6), 275–279. https://doi.org/10.5194/isprs-archives-XLII-2-W6-275-2017&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Persad2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Chiang2017&quot;&gt;Chiang, K. W., Tsai, G. J., Li, Y. H., &amp;amp; El-Sheimy, N. (2017). Development of LiDAR-Based UAV System for Environment Reconstruction. &lt;i&gt;IEEE Geoscience and Remote Sensing Letters&lt;/i&gt;, &lt;i&gt;14&lt;/i&gt;(10), 1790–1794. https://doi.org/10.1109/LGRS.2017.2736013&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Chiang2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Moore2017&quot;&gt;Moore, A. J., Schubert, M., Rymer, N., Balachandran, S., Consiglio, M., Munoz, C., … Schneider Georgia Power, P. (2017). UAV Inspection of Electrical Transmission Infrastructure with Path Conformance Autonomy and Lidar-based Geofences NASA Report on UTM Reference Mission Flights at Southern Company Flights November 2016 NASA STI Program . . . in Profile.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Moore2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Edwards2017&quot;&gt;Edwards, A. S. (2017). Autonomous 3D Mapping and Surveillance of Mines with MAVs, (March).&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Edwards2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Shetty2017&quot;&gt;Shetty, A., &amp;amp; Gao, G. X. (2017). Covariance Estimation for GPS-LiDAR Sensor Fusion for UAVs, 1–5.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Shetty2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Koska2017&quot;&gt;Koska, B., Jirka, V., Urban, R., Křemen, T., Hesslerová, P., Jon, J., … Fogl, M. (2017). Suitability, characteristics, and comparison of an airship UAV with lidar for middle size area mapping. &lt;i&gt;International Journal of Remote Sensing&lt;/i&gt;, &lt;i&gt;38&lt;/i&gt;(8-10), 2973–2990. https://doi.org/10.1080/01431161.2017.1285086&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Koska2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Vempati2017&quot;&gt;Vempati, A. S., Gilitschenski, I., Nieto, J., Beardsley, P., &amp;amp; Siegwart, R. (2017). Onboard real-time dense reconstruction of large-scale environments for UAV. &lt;i&gt;IEEE International Conference on Intelligent Robots and Systems&lt;/i&gt;, &lt;i&gt;2017-September&lt;/i&gt;, 3479–3486. https://doi.org/10.1109/IROS.2017.8206189&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Vempati2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Ozaslan2017&quot;&gt;Ozaslan, T., Taylor, C. J., Kumar, V., Keller, J., Wozencraft, J. M., Loianno, G., &amp;amp; Hood, T. (2017). Autonomous Navigation and Mapping for Inspection of Penstocks and Tunnels With MAVs. &lt;i&gt;IEEE Robotics and Automation Letters&lt;/i&gt;, &lt;i&gt;2&lt;/i&gt;(3), 1740–1747. https://doi.org/10.1109/lra.2017.2699790&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Ozaslan2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Petras2016&quot;&gt;Petras, V., Petrasova, A., Jeziorska, J., &amp;amp; Mitasova, H. (2016). Processing UAV and LiDAR point clouds in grass GIS. &lt;i&gt;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives&lt;/i&gt;, &lt;i&gt;41&lt;/i&gt;(July), 945–952. https://doi.org/10.5194/isprsarchives-XLI-B7-945-2016&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Petras2016/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Kasturi2016&quot;&gt;Kasturi, A., Milanovic, V., Atwood, B. H., &amp;amp; Yang, J. (2016). UAV-borne lidar with MEMS mirror-based scanning capability, (May 2016), 98320M. https://doi.org/10.1117/12.2224285&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Kasturi2016/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Reiss2016&quot;&gt;Reiss, M. L. L., Da Rocha, R. S., Ferraz, R. S., Cruz, V. C., Morador, L. Q., Yamawaki, M. K., … Mezzomo, W. (2016). Data integration acquired from micro-UAV and terrestrial laser scanner for the 3D mapping of jesuit ruins of são miguel das missões. &lt;i&gt;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives&lt;/i&gt;, &lt;i&gt;41&lt;/i&gt;(July), 315–321. https://doi.org/10.5194/isprsarchives-XLI-B5-315-2016&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Reiss2016/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Lawson2015&quot;&gt;Lawson, A. (2015). Cooperative 3-D Map Generation Using Multiple UAVs. &lt;i&gt;University Scholar Projects&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Lawson2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Liu2015&quot;&gt;Liu, S., Mohta, K., Shen, S., &amp;amp; Kumar, V. (2015). Towards Collaborative Mapping and Exploration Using Multiple Micro Aerial Robots BT - Experimental Robotics: The 14th International Symposium on Experimental Robotics. &lt;i&gt;Experimental Robotics III&lt;/i&gt;. https://doi.org/10.1007/bfb0027579&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Liu2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Pan2015&quot;&gt;Pan, W. W., Dou, Y. J., Wang, G. L., Wu, M. X., Ren, R. G., &amp;amp; Xu, X. (2015). Development and test of blimp-based compact LIDAR powewr-line inspection system. &lt;i&gt;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives&lt;/i&gt;, &lt;i&gt;40&lt;/i&gt;(3W2), 155–159. https://doi.org/10.5194/isprsarchives-XL-3-W2-155-2015&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Pan2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Li2015&quot;&gt;Li, Z., Yan, Y., Jing, Y., &amp;amp; Zhao, S. G. (2015). The design and testing of a LiDAR platform for a UAV for heritage mapping. &lt;i&gt;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives&lt;/i&gt;, &lt;i&gt;40&lt;/i&gt;(1W4), 17–24. https://doi.org/10.5194/isprsarchives-XL-1-W4-17-2015&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Li2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Yousif2015&quot;&gt;Yousif, K., Bab-Hadiashar, A., &amp;amp; Hoseinnezhad, R. (2015). An Overview to Visual Odometry and Visual SLAM: Applications to Mobile Robotics. &lt;i&gt;Intelligent Industrial Systems&lt;/i&gt;, &lt;i&gt;1&lt;/i&gt;(4), 289–311. https://doi.org/10.1007/s40903-015-0032-7&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Yousif2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Gu2015&quot;&gt;Gu, T., &amp;amp; Zhang, N. (2015). Application of iterative closest point algorithm in automatic flight of speedy UAV. &lt;i&gt;2014 IEEE Chinese Guidance, Navigation and Control Conference, CGNCC 2014&lt;/i&gt;, 1456–1459. https://doi.org/10.1109/CGNCC.2014.7007407&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Gu2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Mandlburger2015&quot;&gt;Mandlburger, G., Pfennigbauer, M., Riegl, U., Haring, A., Wieser, M., Glira, P., &amp;amp; Winiwarter, L. (2015). Complementing airborne laser bathymetry with UAV-based lidar for capturing alluvial landscapes, (October 2015), 96370A. https://doi.org/10.1117/12.2194779&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Mandlburger2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Tulldahl2015&quot;&gt;Tulldahl, H. M., Bissmarck, F., Larsson, H., Grönwall, C., &amp;amp; Tolt, G. (2015). Accuracy evaluation of 3D lidar data from small UAV, &lt;i&gt;964903&lt;/i&gt;(October 2015), 964903. https://doi.org/10.1117/12.2194508&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Tulldahl2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Yang2015&quot;&gt;Yang, B., &amp;amp; Chen, C. (2015). Automatic registration of UAV-borne sequent images and LiDAR data. &lt;i&gt;ISPRS Journal of Photogrammetry and Remote Sensing&lt;/i&gt;, &lt;i&gt;101&lt;/i&gt;, 262–274. https://doi.org/10.1016/j.isprsjprs.2014.12.025&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Yang2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Ni2015&quot;&gt;Ni, W., Liu, J., Zhang, Z., Sun, G., &amp;amp; Yang, A. (2015). Evaluation of UAV-based forest inventory system compared with LiDAR data. &lt;i&gt;International Geoscience and Remote Sensing Symposium (IGARSS)&lt;/i&gt;, &lt;i&gt;2015-Novem&lt;/i&gt;, 3874–3877. https://doi.org/10.1109/IGARSS.2015.7326670&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Ni2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Esposito2014&quot;&gt;Esposito, S., Mura, M., Fallavollita, P., Balsi, M., Chirici, G., Oradini, A., &amp;amp; Marchetti, M. (2014). Performance evaluation of lightweight LiDAR for UAV applications. &lt;i&gt;International Geoscience and Remote Sensing Symposium (IGARSS)&lt;/i&gt;, 792–795. https://doi.org/10.1109/IGARSS.2014.6946543&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Esposito2014/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Roca2014&quot;&gt;Roca, D., Armesto, J., Lagüela, S., &amp;amp; Díaz-Vilariño, L. (2014). LIDAR-equipped UAV for building information modelling. &lt;i&gt;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives&lt;/i&gt;, &lt;i&gt;40&lt;/i&gt;(5), 523–527. https://doi.org/10.5194/isprsarchives-XL-5-523-2014&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Roca2014/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Tulldahl2014&quot;&gt;Tulldahl, H. M., &amp;amp; Larsson, H. (2014). Lidar on small UAV for 3D mapping, &lt;i&gt;925009&lt;/i&gt;(October 2014), 925009. https://doi.org/10.1117/12.2068448&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Tulldahl2014/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Wallace2014&quot;&gt;Wallace, L., Lucieer, A., &amp;amp; Watson, C. S. (2014). Evaluating tree detection and segmentation routines on very high resolution UAV LiDAR ata. &lt;i&gt;IEEE Transactions on Geoscience and Remote Sensing&lt;/i&gt;, &lt;i&gt;52&lt;/i&gt;(12), 7619–7628. https://doi.org/10.1109/TGRS.2014.2315649&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Wallace2014/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Lin2014&quot;&gt;Lin, Y., &amp;amp; West, G. (2014). Attempt of UAV oblique images and MLS point clouds for 4D modelling of roadside pole-like objects, &lt;i&gt;9262&lt;/i&gt;(November 2014), 92620Q. https://doi.org/10.1117/12.2068287&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Lin2014/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Zhou2013&quot;&gt;Zhou, G., Yang, B., Zhang, W., Tao, X., Zhao, W., Yue, T., … Yang, C. (2013). Simulation study of new generation of airborne scannerless LiDAR system. &lt;i&gt;International Geoscience and Remote Sensing Symposium (IGARSS)&lt;/i&gt;, (February 2015), 524–527. https://doi.org/10.1109/IGARSS.2013.6721208&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Zhou2013/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Wallace2013&quot;&gt;Wallace, L. (2013). Assessing the stability of canopy maps produced from UAV-LiDAR data. &lt;i&gt;International Geoscience and Remote Sensing Symposium (IGARSS)&lt;/i&gt;, (Figure 1), 3879–3882. https://doi.org/10.1109/IGARSS.2013.6723679&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Wallace2013/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Wallace2012a&quot;&gt;Wallace, L. O., Lucieer, A., &amp;amp; Watson, C. S. (2012). Assessing the Feasibility of Uav-Based Lidar for High Resolution Forest Change Detection. &lt;i&gt;ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences&lt;/i&gt;, &lt;i&gt;XXXIX-B7&lt;/i&gt;(September), 499–504. https://doi.org/10.5194/isprsarchives-XXXIX-B7-499-2012&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Wallace2012a/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Wallace2012&quot;&gt;Wallace, L., Lucieer, A., Watson, C., &amp;amp; Turner, D. (2012). Development of a UAV-LiDAR system with application to forest inventory. &lt;i&gt;Remote Sensing&lt;/i&gt;, &lt;i&gt;4&lt;/i&gt;(6), 1519–1543. https://doi.org/10.3390/rs4061519&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Wallace2012/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Michael2012&quot;&gt;Michael, N., Shen, S., Motha, K., Mulgaonkar, Y., Kumar, V., Nagatani, K., … Tadokoro, S. (2012). Collaborative mapping of an earthquake‐damaged building via ground and aerial robots. &lt;i&gt;\Ldots of Field Robotics&lt;/i&gt;, &lt;i&gt;29&lt;/i&gt;(5), 832–841. https://doi.org/10.1002/rob&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Michael2012/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Hwang2012&quot;&gt;Hwang, Y., &amp;amp; Tahk, M.-jea. (2012). Terrain Referenced UAV Navigation with Lidar – a Comparison of Sequential Processing and Batch Processing Algorithms. &lt;i&gt;28th INTERNATIONAL CONGRESS OF THE AERONAUTICAL SCIENCES&lt;/i&gt;, 1–7.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Hwang2012/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Candigliota2012&quot;&gt;Candigliota, E., Immordino, F., Moretti, L., &amp;amp; Indirli, M. (2012). Remote sensing, laser scanner survey and GIS integrated method for assessment and preservation of historic centers: the example of Arsita. &lt;i&gt;In Proceedings of the 15th World Conference on Earthquake Engineering - WCEE&lt;/i&gt;, 1–9.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Candigliota2012/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Han2012&quot;&gt;Han, K., Aeschliman, C., Park, J., Kak, A. C., Kwon, H., &amp;amp; Pack, D. J. (2012). UAV vision: Feature based accurate ground target localization through propagated initializations and interframe homographies. &lt;i&gt;Proceedings - IEEE International Conference on Robotics and Automation&lt;/i&gt;, 944–950. https://doi.org/10.1109/ICRA.2012.6225073&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Han2012/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Durst2011&quot;&gt;Durst, P. J., Baylot, A., &amp;amp; McKinley, B. (2011). Techniques for inferring terrain parameters related to ground vehicle mobility using UAV born IFSAR and LIDAR data. &lt;i&gt;Proceedings of SPIE - The International Society for Optical Engineering&lt;/i&gt;, &lt;i&gt;8020&lt;/i&gt;(May 2011). https://doi.org/10.1117/12.883510&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Durst2011/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Liu2011&quot;&gt;Liu, C., Li, W., Lei, W., Liu, L., &amp;amp; Wu, H. (2011). Architecture planning and geo-disasters assessment mapping of landslide by using airborne lidar data and UAV images, (October 2011), 82861Q. https://doi.org/10.1117/12.912525&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Liu2011/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Downs2004&quot;&gt;Downs, A., Madhavan, R., &amp;amp; Hong, T. (2004). Registration of range data from unmanned aerial and ground vehicles. &lt;i&gt;Proceedings - Applied Imagery Pattern Recognition Workshop&lt;/i&gt;, &lt;i&gt;2003-Janua&lt;/i&gt;, 45–50. https://doi.org/10.1109/AIPR.2003.1284247&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Downs2004/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Zhen&quot;&gt;Zhen, W., &amp;amp; Scherer, S. A Unified 3D Mapping Framework using a 3D or 2D LiDAR. &lt;i&gt;Robotics&lt;/i&gt;, 1–10.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Zhen/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Maxime Vaidis</name><email>vaidis.maxime@gmail.com</email></author><category term="publications" /><category term="ICP" /><category term="registration" /><category term="mapping" /><category term="robot" /><category term="localization" /><summary type="html">This survey presents an overall view of lidar (Light Detection And Ranging) used on UAV (Unmanned Aerial Vehicle) and their project.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22publications/survey-lidar-UAV_feature.jpg%22,%20%22teaser%22=%3E%22publications/survey-lidar-UAV_teaser.jpg%22,%20%22thumb%22=%3Enil,%20%22credit%22=%3E%22H2H%20Associates,%20DroneZon%22%7D" /></entry><entry><title type="html">Enquête sur l’utilisation des lidars avec les UAV et la cartographie souterraine</title><link href="https://norlab.ulaval.ca/publications/survey-lidar-UAV_fr/" rel="alternate" type="text/html" title="Enquête sur l'utilisation des lidars avec les UAV et la cartographie souterraine" /><published>2019-02-14T00:00:00-05:00</published><updated>2019-02-14T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/publications/survey-lidar-UAV_fr</id><content type="html" xml:base="https://norlab.ulaval.ca/publications/survey-lidar-UAV_fr/">&lt;p&gt;Cette enquête présente une vue générale des projets utilisant des lidars (Technologie de mesure de distance et détection par laser) sur des UAV (Véhicule Aérien Autonome).&lt;/p&gt;

&lt;p&gt;De nos jours le nombre de projets utilisant des UAV avec des lidars est en forte augmentation. 
Du fait de leurs capacités à accéder à des endroits inaccessibles pour l’homme et de leur facilité de déploiement et d’utilisation, les UAV sont plus à même de donner des points de vue différents intéressant que les UGV (Véhicule Terrestre Autonome). 
Cependant, l’utilisation de lidar sur les UAV reste encore un défi en soi et beaucoup de problèmes restent encore à surmonter. 
L’estimation de la position de l’UAV, sa vitesse et son altitude, les caractéristiques de ses équipements et les algorithmes utilisés influencent significativement la précision des mesures de cartographie. 
Dans cette enquête, nous présentons une liste des articles utilisant les lidars sur les UAV et donnons quelques détails à propos des équipements et algorithmes utilisés pour leur projet. 
L’objectif est de fournir des éléments de comparaison sur les équipements utilisés dans les différents projets afin de faciliter le choix d’un lidar pour la cartographie avec des UAV. 
Étant donné le nombre important d’articles sur le sujet, nous divisons cette enquête en sept catégories:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#cartographie-souterraine&quot;&gt;cartographie souterraine&lt;/a&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#mesure-avec-dirigeable&quot;&gt;mesure avec dirigeable&lt;/a&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#estimation-de-la-pose-et-trajectoire&quot;&gt;estimation de la position et trajectoire avec lidar&lt;/a&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#mesure-quelques-caractéristiques-du-paysage&quot;&gt;mesure de quelques caractéristiques du paysage&lt;/a&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#mesure-objets&quot;&gt;mesure d’objets&lt;/a&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#lidar-sur-UAV&quot;&gt;test de lidar sur UAV&lt;/a&gt;, et finallement&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#algorithmes-pour-odometry-et-comparaison-entre-lidar-sur-uav-et-ugv&quot;&gt;algorithmes pour l’odométrie et comparaison entre lidar sur UAV et lidar sur robot terrestre&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Cette enquête est en cours de rédaction. Elle sera régulièrement mise à jour.
Nous espérons que ces informations serons utiles à la communauté scientifique.
Si vous remarquer l’absence de l’un de vos articles ou une erreur, n’hésitez pas à nous contacter.&lt;/p&gt;

&lt;p&gt;Légende: “O” signifie présent et “-“ signifie absent de l’article.&lt;/p&gt;

&lt;h3 id=&quot;cartographie-souterraine&quot;&gt;Cartographie souterraine&lt;/h3&gt;
&lt;div style=&quot;overflow-x: visible;&quot;&gt;
&lt;table class=&quot;large&quot;&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Article&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Sujet&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;UAV&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;lidar&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Caméra&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GPS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;IMU&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GNSS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;INS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Test&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Notes&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Michael2012&quot;&gt;(Michael et al., 2012)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Cartographie 3D d'un bâtiments endommagé par un tremblement de terre en utilisant une collaboration entre un robot terrestre et aérien&lt;/td&gt;
			&lt;td&gt;Pelican quadrotor&lt;/td&gt;
			&lt;td&gt;Hokuyo TM-30LX&lt;/td&gt;
			&lt;td&gt;Microsoft Kinect&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Intérieur&lt;/td&gt;
			&lt;td&gt;UAV peut se déployer à partir de l'UGV, ICP pour cartographie, SLAM pour navigation&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Liu2015&quot;&gt;(Liu, Mohta, Shen, &amp;amp; Kumar, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Multiple UAV pour cartographie 3D&lt;/td&gt;
			&lt;td&gt;Pelican quadrotor&lt;/td&gt;
			&lt;td&gt;Hokuyo UTM-30LX&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Simulation et test intérieur&lt;/td&gt;
			&lt;td&gt;SLAM pour navigation et plannification de trajectoire&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#AjayKumar2017&quot;&gt;(Ajay Kumar, Patil, Patil, Park, &amp;amp; Chai, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Reconstruction d'intérieur de bâtiment et classification de tuyaux&lt;/td&gt;
			&lt;td&gt;Phantom 3 quadcopter avancé&lt;/td&gt;
			&lt;td&gt;Hokuyo UTM-30LX, Hokuyo URG-04LX-UG01&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Intérieur&lt;/td&gt;
			&lt;td&gt;ICP pour fusionner les données, utilisation d'un filtre de Kalman pour avoir la position, classification des tuyaux en calculant leur courbature&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Edwards2017&quot;&gt;(Edwards, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Scan d'un tunnel de mine&lt;/td&gt;
			&lt;td&gt;Asctec Hummingbird&lt;/td&gt;
			&lt;td&gt;Z+F Imager S010 3D (terrestrial)&lt;/td&gt;
			&lt;td&gt;Xtion Pro live &lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Intérieur&lt;/td&gt;
			&lt;td&gt;Comparaison entre l'algorithme Microsoft Kinect Fusion et un lidar terrestre&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Vempati2017&quot;&gt;(Vempati, Gilitschenski, Nieto, Beardsley, &amp;amp; Siegwart, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Cartographie 3D intérieur en temps-réel avec UAV&lt;/td&gt;
			&lt;td&gt;DJI M100&lt;/td&gt;
			&lt;td&gt;Leica Multistation MS50 (sert de référence)&lt;/td&gt;
			&lt;td&gt;Intel RealSense R200&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;capteur DUO-MLX visual-inertial&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Simulation and test intérieur&lt;/td&gt;
			&lt;td&gt;SLAM avec GPU parallélisé pour gérer ses ressources mémoire, 5mm de résolution à 60Hz, filtre de Kalman étendu, ICP pour cartographie&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Ozaslan2017&quot;&gt;(Ozaslan et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Inspection de tunnel et pipeline avec UAV&lt;/td&gt;
			&lt;td&gt;DJI F550&lt;/td&gt;
			&lt;td&gt;Velodyne Puck Lite&lt;/td&gt;
			&lt;td&gt;MChameleon 3 caméra&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;PickHawk&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Intérieur&lt;/td&gt;
			&lt;td&gt;Cartographie local pour l'estimation de la pose&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Mascarich2018&quot;&gt;(Mascarich et al., 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Inspection de site nucléaire et tunnel avec UAV&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Capteur de profondeur de type Time of flight&lt;/td&gt;
			&lt;td&gt;Chameleon 3 caméra&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Intérieur&lt;/td&gt;
			&lt;td&gt;Détection des radiations et de leur localisation&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Papachristos2019&quot;&gt;(Papachristos, Khattak, Mascarich, &amp;amp; Alexis, 2019)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Exploration autonome et cartographie de mines souterraines&lt;/td&gt;
			&lt;td&gt;Quadrotor&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Intérieur&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mesure-avec-dirigeable&quot;&gt;Mesure avec dirigeable&lt;/h3&gt;
&lt;div style=&quot;overflow-x: visible;&quot;&gt;
&lt;table class=&quot;large&quot;&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Article&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Subject&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;UAV&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;lidar&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Camera&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GPS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;IMU&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GNSS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;INS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Test&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Note&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Pan2015&quot;&gt;(Pan et al., 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Système pour suivre les lignes éléctriques afin de détecter des problèmes&lt;/td&gt;
			&lt;td&gt;Petit dirigeable à l'hélium&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Koska2017&quot;&gt;(Koska et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Comparaison entre Lidar sur dirigeable et caméra sur UAV&lt;/td&gt;
			&lt;td&gt;Dirigeable ACC15X, 12m de long, 2.8m de diamètre (57m^3), 15kg de charge&lt;/td&gt;
			&lt;td&gt;Sick LD-LRS1000 (2D avec rotation)&lt;/td&gt;
			&lt;td&gt;Canon EOS 100D, FLIR SC645&lt;/td&gt;
			&lt;td&gt;IMAR iTracer-F200&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Dirigeable crée par AirshipClub.com, problème de précision, problème avec la structure mais plus précis avec le dirigeable sur de larges zones qu'avec l'UAV&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&quot;estimation-de-la-position-et-trajectoire-avec-lidar&quot;&gt;Estimation de la position et trajectoire avec lidar&lt;/h3&gt;
&lt;div style=&quot;overflow-x: visible;&quot;&gt;
&lt;table class=&quot;large&quot;&gt;
	&lt;thead&gt;
		&lt;tr class=&quot;header&quot;&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Article&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Sujet&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;UAV&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;lidar&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Caméra&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GPS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;IMU&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GNSS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;INS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Test&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Notes&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Downs2004&quot;&gt;(Downs, Madhavan, &amp;amp; Hong, 2004)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Meilleure estimation de la position de l'UAV avec un lidar que par GPS&lt;/td&gt;
			&lt;td&gt;Flying Eye&lt;/td&gt;
			&lt;td&gt;LADAR system (UAV)/LMS-Z420i au sol&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;ICP pour traiter 2 séries de mesure, comparaison des données de UAV à celles au sol pour mesurer la précision&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Hwang2012&quot;&gt;(Hwang &amp;amp; Tahk, 2012)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Mesure de la position d'un UAV avec lidar&lt;/td&gt;
			&lt;td&gt;Simualation d'un avion&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Simulation afin de comparer 2 algorithmiques pour localisation&lt;/td&gt;
			&lt;td&gt;Le lidar mesure le relief, comparaison entre le filtre de Kalman et la Cross Correlation&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Han2012&quot;&gt;(Han et al., 2012)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Problème de la mesure de la position d'une cible par apport à un drone&lt;/td&gt;
			&lt;td&gt;Petit avion&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Images extraites d'une base de données pour tester l'algorithme de détection de contours, GPS+IMU pour estimer la position de l'UAV, ICP pour traiter les données, discussion sur le nombre de cycle d'ICP et leur influence sur les résultats&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Gee2017&quot;&gt;(Gee, James, Van Der Mark, Delmas, &amp;amp; Gimel’Farb, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Fusion de plusieurs nuages de points issus d'un lidar en vue d'utiliser l'algorithme SLAM&lt;/td&gt;
			&lt;td&gt;DJI Phantom Quadcopter&lt;/td&gt;
			&lt;td&gt;Velodyne puck VLP-16&lt;/td&gt;
			&lt;td&gt;GoPro Hero 3+&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Reconstruction des données, lidar statique au sol (caméra sur UAV), approximation de trajectoires avec les points puis ICP et SLAM&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Shetty2017&quot;&gt;(Shetty &amp;amp; Gao, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Fusion des données GPS et lidar pour corriger l'erreur du GPS dans un environnement urbain&lt;/td&gt;
			&lt;td&gt;Quadrotor&lt;/td&gt;
			&lt;td&gt;Velodyne VLP-16 puck lite&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;LEA-6T GPS&lt;/td&gt;
			&lt;td&gt;Xsens-Mti-30 IMU&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Modélisation de l'erreur de covariance du nuage de point, pose de l'UAV par Unscented Kalaman filter, matching des données lidar avec modèle 3D d'une ville, ICP pour faire correspondre les nuages de points&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Zhen&quot;&gt;(Zhen &amp;amp; Scherer, n.d.)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Test une méthode multi-plateforme avec lidar et l'algorithme SLAM pour UAV (2D-3D)&lt;/td&gt;
			&lt;td&gt;DJI M100 DJI M600&lt;/td&gt;
			&lt;td&gt;Rotating Hokuyo Rotating Velodyne VLP-16&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Simulation et en extérieur&lt;/td&gt;
			&lt;td&gt;Kalman filter (ESKF), Gaussian Particle Filter (GPF), vitesse faible pour éviter erreur de position&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Youn2018&quot;&gt;(Youn, Kim, Kim, Yoo, &amp;amp; Lee, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Détection de l'environnement 3D pour plannifier, se déplacer et surveiller le traffic dans le ciel&lt;/td&gt;
			&lt;td&gt;Cessma 208B&lt;/td&gt;
			&lt;td&gt;ALS50-III&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Découpage du monde en cube de certaines tailles (différents niveaux de découpage suivant 20 degré de lattitude), 20 niveaux au total&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Gomes2018&quot;&gt;(Gomes, Guerreiro, Cunha, Silvestre, &amp;amp; Oliveira, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Mesure de la déviation de trajectoire avec des données issues d'un lidar sur UAV&lt;/td&gt;
			&lt;td&gt;Mikrokopter Quadro XL&lt;/td&gt;
			&lt;td&gt;Hokuyo UTM30LX&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Microstrain IMU&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Intérieur&lt;/td&gt;
			&lt;td&gt;Méthode de detection de contours avec nuage de points, estimation de la position&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;center&gt;&lt;h3&gt;Mesure de quelques caractéristiques du paysage&lt;/h3&gt;&lt;/center&gt;
&lt;div style=&quot;overflow-x: visible;&quot;&gt;
&lt;table class=&quot;large&quot;&gt;
	&lt;thead&gt;
		&lt;tr class=&quot;header&quot;&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Article&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Sujet&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;UAV&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;lidar&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Caméra&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GPS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;IMU&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GNSS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;INS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Test&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Notes&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Liu2011&quot;&gt;(Liu, Li, Lei, Liu, &amp;amp; Wu, 2011)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Analyse du sol avec UAV et lidar pour détecter et anticiper des glissements de terrain&lt;/td&gt;
			&lt;td&gt;Helicoptère&lt;/td&gt;
			&lt;td&gt;lidar sur helicoptère&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;DGPS&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Traitement sur point cloud et images&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Durst2011&quot;&gt;(Durst, Baylot, &amp;amp; McKinley, 2011)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Utilisation d'un drone et lidar pour l'étude des propiétés des routes (type de véhicule, courbature, taille,...)&lt;/td&gt;
			&lt;td&gt;Buckeye drone&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Le lidar fait la mesure de l’élévation, le chemin est repéré par un traitement sur image&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Wallace2012&quot;&gt;(Wallace, Lucieer, Watson, &amp;amp; Turner, 2012)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Recherches pour détecter des arbres dans une forêt (taille, position, diamètre)&lt;/td&gt;
			&lt;td&gt;Oktokopter Droidworsc/Micropter AD-8 (terraLuma)&lt;/td&gt;
			&lt;td&gt;Ibeo LUX laser scanner&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Filtre de Kalman pour donner la position&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Wallace2012a&quot;&gt;(Wallace, Lucieer, &amp;amp; Watson, 2012)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Mesure des effets de l'environnement au sol et des paramètres de mesures pour la prise de données sur des arbres&lt;/td&gt;
			&lt;td&gt;Drone TerraLuma&lt;/td&gt;
			&lt;td&gt;Ibeo LUX laser scanner&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Candigliota2012&quot;&gt;(Candigliota, Immordino, Moretti, &amp;amp; Indirli, 2012)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Analyse de la structure d'une ville après un tremblement de terre pour éviter de futures dégâts&lt;/td&gt;
			&lt;td&gt;Quadrotor&lt;/td&gt;
			&lt;td&gt;Leica Geosystems HDS 3000&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;DGPS&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;ICP pour traiter les données&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Zhou2013&quot;&gt;(Zhou et al., 2013)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Utilisation de différentes altitude et vitesse pour prendre des données sur un paysage&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Wallace2013&quot;&gt;(Wallace, 2013)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Test de nouvelles caractéristiques pour l'analyse de la structure d'une forêt de manière probabilistique&lt;/td&gt;
			&lt;td&gt;Drone TerraLuma&lt;/td&gt;
			&lt;td&gt;Ibeo LUX laser scanner&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Roca2014&quot;&gt;(Roca, Armesto, Lagüela, &amp;amp; Díaz-Vilariño, 2014)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Test d'un UAV avec lidar pour la mesure du sol&lt;/td&gt;
			&lt;td&gt;Hisystems GmbH&lt;/td&gt;
			&lt;td&gt;Hokuyo UTM-30LX&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Filtre de Kalman pour la position, test effectué sur une maison&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Esposito2014&quot;&gt;(Esposito et al., 2014)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Mesure des caractéristiques des arbres (taille, forme,...) pour valider le fonctionnement d'un lidar sur un UAV&lt;/td&gt;
			&lt;td&gt;Ultralight helicoptère&lt;/td&gt;
			&lt;td&gt;YellowScan lidar&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Wallace2014&quot;&gt;(Wallace, Lucieer, &amp;amp; Watson, 2014)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Mesure l'influence des algorithmes de détection et de la densité de points sur la précision de la détection des arbres et de leurs caractéristiques&lt;/td&gt;
			&lt;td&gt;Drone TerraLuma&lt;/td&gt;
			&lt;td&gt;Ibeo LUX laser scanner&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Ni2015&quot;&gt;(Ni, Liu, Zhang, Sun, &amp;amp; Yang, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Fait l'inventaire d'une forêt avec UAV et lidar&lt;/td&gt;
			&lt;td&gt;Yun-5 aircraft&lt;/td&gt;
			&lt;td&gt;Leica ALS 60&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Mandlburger2015&quot;&gt;(Mandlburger et al., 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Analyse les caractéristiques d'un cours d'eau avec UAV et lidar (dynamique, délimitation,...)&lt;/td&gt;
			&lt;td&gt;Ricopter UAV&lt;/td&gt;
			&lt;td&gt;Riegl VUX-Sys, VUX-1, VQ-880-G&lt;/td&gt;
			&lt;td&gt;Sony Alpha 6000 RGB&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Reiss2016&quot;&gt;(Reiss et al., 2016)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Cartographie et enregistrement de ruines avec lidar sur UAV&lt;/td&gt;
			&lt;td&gt;Asctec Falcon 8, Sensefly e-Bee&lt;/td&gt;
			&lt;td&gt;Faro Focus 3D S-120 (UAV), Optec 3D-HD ILRIS (terrestre)&lt;/td&gt;
			&lt;td&gt;Sony Alpha 6000 RGB&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Fusion des données terrestre et aérienne par photogramétrie&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Guo2017&quot;&gt;(Guo et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Cartographie de forêt avec UAV et lidar&lt;/td&gt;
			&lt;td&gt;8 rotor UAV&lt;/td&gt;
			&lt;td&gt;Velodyne puck VLP-16&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Novatel IMU&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Calibration des équipements, obtention des différentes caractéristiques sur la forêt&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Wei2017&quot;&gt;(Wei, Yang, Jiang, Cao, &amp;amp; Wu, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Filtrer les effets de la végétation sur les mesures de paysage&lt;/td&gt;
			&lt;td&gt;8 rotor UAV&lt;/td&gt;
			&lt;td&gt;Riegl VUX-1&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Trimble Applanix AP20-IMU&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Chiang2017&quot;&gt;(Chiang, Tsai, Li, &amp;amp; El-Sheimy, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Reconstruction d'un bâtiment avec UAV et lidar&lt;/td&gt;
			&lt;td&gt;Petit hélicoptère&lt;/td&gt;
			&lt;td&gt;Velodyne lidar VLP-16&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;C-Migits III&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Nouvelle stratégie ICP afin de traiter la déformation des points, Filtre de Kalman pour données, comparaison avec lidar terrestre&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Chen2017&quot;&gt;(Chen, McDermid, Castilla, &amp;amp; Linke, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Mesure de la végétation boréale avec UAV et lidar&lt;/td&gt;
			&lt;td&gt;Quadcoptère&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Hauteur de la végétation mesurée, RTK GNSS pour la position, utilisation de données lidar dans base de données, croisements des données pour générer une carte des mesures&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Sankey2017&quot;&gt;(Sankey, Donager, McVay, &amp;amp; Sankey, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Cartographie d'une forêt avec lidar sur UAV&lt;/td&gt;
			&lt;td&gt;Octocoptère&lt;/td&gt;
			&lt;td&gt;Velodyne HDL-32E (UAV), Riegl VZ-1000(terrestre)&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Comparaison via le lidar terrestre, détermination des espéces d'arbres présent grâce à la réflexance du laser, limiter par la densité de peuplement des arbres&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Christiansen2017&quot;&gt;(Christiansen, Laursen, Jørgensen, Skovsen, &amp;amp; Gislum, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Cartographie et mesure de la taille de culture avec UAV et lidar&lt;/td&gt;
			&lt;td&gt;DJI Matrice-100 quadcoptère&lt;/td&gt;
			&lt;td&gt;Velodyne VLP-16&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;VN-200 IMU&lt;/td&gt;
			&lt;td&gt;Trimble BD920 GNSS&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Traitement des données pour isoler le champ puis mesurer sa hauteur, dépend grandement des valeurs du GPS&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Gawel2017&quot;&gt;(Gawel et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Fait la cartographie d'une zone sinistré avec UAV et lidar, puis envoi ensuite les données à des robots terrestres pour utiliser l'algorithme SLAM&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Filtre de étendu Kalman, ICP pour fusionner les données, robot mobile avec lidar, fusion des données UAV et UGV&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Elaksher2017&quot;&gt;(Elaksher, Bhandari, Carreon Limones, &amp;amp; Lauf, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Cartographie de champs avec UAV et lidar&lt;/td&gt;
			&lt;td&gt;DJI S900 hexacoptère&lt;/td&gt;
			&lt;td&gt;Velodyne VLP-16&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Classification des points (sol ou végétation)&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#PututAshShidiq2017&quot;&gt;(Putut Ash Shidiq et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Topographie de forêt avec UAV et lidar afin de différencier le sol des arbres&lt;/td&gt;
			&lt;td&gt;DJI Matrice-600&lt;/td&gt;
			&lt;td&gt;YellowScan lidar&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Morsdorf2017&quot;&gt;(Morsdorf et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Topographie de forêt avec lidar sur UAV et comparaison avec lidar terrestre&lt;/td&gt;
			&lt;td&gt;Scout B1-100 helicoptère&lt;/td&gt;
			&lt;td&gt;Riegl VUX-1UAV (drone), Riegl VZ1000 (terrestre)&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;xTS xNAV550 GPS&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;4 m/s de vitesse, erreur de 1m sur la hauteur des arbres&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Thiel2017&quot;&gt;(Thiel &amp;amp; Schmullius, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Comparaison entre les nuages de points obtenus par camera sur UAV et lidar sur UGV, pour trouver des caractéristiques sur les forêts&lt;/td&gt;
			&lt;td&gt;Geocopter X8000&lt;/td&gt;
			&lt;td&gt;Riegl VZ 1000 TLS (terrestre)&lt;/td&gt;
			&lt;td&gt;Sony NEX-7 RGB&lt;/td&gt;
			&lt;td&gt;DGPS&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Trame des maxima, taille canopé et niveau de détection, 8 m/s pour UAV, comparaison avec lidar terrestre, traitement des données pour avoir des caractéristiques sur les forêts&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Huang2018&quot;&gt;(Huang, Yeh, Tseng, &amp;amp; Hsu, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Mesure les propriétés des vagues de la mer, du changement du littoral et des marées avec UAV et lidar&lt;/td&gt;
			&lt;td&gt;DJI S1000&lt;/td&gt;
			&lt;td&gt;Hokuyo UTM-30LX&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Xsens-Mti-30 IMU&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;RTK GNSS, calibration et mesure des données, comparaison des données lidar avec capteur de pression Doppler Velocimetry (Son Tek ADV-Oceans)&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Cramer2018&quot;&gt;(Cramer, Haala, Laupheimer, Mandlburger, &amp;amp; Havel, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Mesure du sol et paysage avec un lidar haute précision sur UAV(3-5mm)&lt;/td&gt;
			&lt;td&gt;Ricopter multi-copter pateforme&lt;/td&gt;
			&lt;td&gt;Riegl VUX-1LR&lt;/td&gt;
			&lt;td&gt;Sony Alpha 6000 RGB&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;8 m/s de vitesse, 50m de hauteur, comparaison avec mesure au sol (tacheometrie)&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Govedarica2018&quot;&gt;(Govedarica, Jakovljevic, &amp;amp; Álvarez Taboada, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Étude du risque d'inondation avec UAV et lidar&lt;/td&gt;
			&lt;td&gt;WingtraOno drone&lt;/td&gt;
			&lt;td&gt;LMS-Q680i-Full (avion)&lt;/td&gt;
			&lt;td&gt;42 MP Sony RX1RII&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Technique DEM (digital elevation models), lidar comme référence pour caméra&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Hinterhofer2018&quot;&gt;(Hinterhofer et al., 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Utilisation d'un UAV et lidar sur un site nucléaire sinistré&lt;/td&gt;
			&lt;td&gt;Ricopter-M&lt;/td&gt;
			&lt;td&gt;Riegl VUX-1UAV &lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Cartographier le terrain et mesurer le taux gamma de radiation&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Yan2018&quot;&gt;(Yan et al., 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Mesure de la prodution forestière par UAV et lidar&lt;/td&gt;
			&lt;td&gt;GV 1300 multirotor &lt;/td&gt;
			&lt;td&gt;Velodyne VLP-16E&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;IMU-IGM-S1&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Segmentation des arbres par algorithme&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Liu2018&quot;&gt;(Liu, Shen, Cao, Wang, &amp;amp; Cao, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Mesure de la strutcure d'une forêt avec UAV et lidar&lt;/td&gt;
			&lt;td&gt;GV 1900 multi-rotor UAV&lt;/td&gt;
			&lt;td&gt;Velodyne puck VLP-16&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;IMU-IGM-S1&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Polewski2019&quot;&gt;(Polewski, Yao, Cao, &amp;amp; Gao, 2019)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Méthode pour obtenir la position des arbres en utilisant un nuage de points obtenu avec UAV et lidar&lt;/td&gt;
			&lt;td&gt;Quadrotor&lt;/td&gt;
			&lt;td&gt;Velodyne puck VLP-16 (UAV), velodyne puck VLP-16 (UGV)&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;GPS Novatel (UAV)&lt;/td&gt;
			&lt;td&gt;IMU Novatel SPAN-MEMS (UAV)&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;POS (UGV)&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;lidar terrestre porté par une personne sur sac à dos pendant les tests&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;center&gt;&lt;h3&gt;Mesure d'objets&lt;/h3&gt;&lt;/center&gt;
&lt;div style=&quot;overflow-x: visible;&quot;&gt;
&lt;table class=&quot;large&quot;&gt;
	&lt;thead&gt;
		&lt;tr class=&quot;header&quot;&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Article&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Sujet&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;UAV&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;lidar&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Caméra&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GPS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;IMU&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GNSS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;INS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Test&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Notes&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Lin2014&quot;&gt;(Lin &amp;amp; West, 2014)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Mesure et cartographie d'objets avec une géométrie oblique&lt;/td&gt;
			&lt;td&gt;Microdrone md4-200&lt;/td&gt;
			&lt;td&gt;Sensei MLS system (UAV), Ibeo Lux Laser (véhicule terrestre)&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Fusion des données entre UAV et UGV&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Gu2015&quot;&gt;(Gu &amp;amp; Zhang, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Localisation d'objets avec une plateforme UAV rapide&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Augmente la rapidité avec des algorithmes (K-d tree, AK-d tree), altitude trop élevée implique de moins bonne performance&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Moore2017&quot;&gt;(Moore et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Inspection de lignes éléctriques avec UAV&lt;/td&gt;
			&lt;td&gt;Octorotor&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Ajout d'un lidar pour éviter une collision et plannifier un chemin, utilisation de plusieurs drones pour parcourir la ligne, transformation des données lidar en forme polygominale, évitement de collision des drones en temps réel&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Teng2017&quot;&gt;(Teng et al., 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Inspection de lignes éléctriques avec UAV&lt;/td&gt;
			&lt;td&gt;Hexarotor&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Isole les vibrations de l'UAV du lidar, détection des lignes hautes tensions affaisées&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Nikolov2017&quot;&gt;(Nikolov &amp;amp; Madsen, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Inspection de pâles d'éoliennes avec UAV et lidar&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;RPlidar&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;BNO055g-DOF IMU&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Simplification en 2D de la forme des pâles, analyse de celles-ci&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Chen2018&quot;&gt;(Chen, Yang, Song, Peng, &amp;amp; Huang, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Mesure de la distance entre les lignes éléctriques et le sol en vue de détecter des problèmes&lt;/td&gt;
			&lt;td&gt;Drone mini helicoptère&lt;/td&gt;
			&lt;td&gt;Riegl VZ400&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;POS&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Algorithme de différentiation sol et câble, mesure courbure des câbles&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;center&gt;&lt;h3&gt;Test de lidar sur UAV&lt;/h3&gt;&lt;/center&gt;
&lt;div style=&quot;overflow-x: visible;&quot;&gt;
&lt;table class=&quot;large&quot;&gt;
	&lt;thead&gt;
		&lt;tr class=&quot;header&quot;&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Article&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Sujet&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;UAV&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;lidar&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Caméra&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GPS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;IMU&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GNSS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;INS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Test&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Notes&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Li2015&quot;&gt;(Li, Yan, Jing, &amp;amp; Zhao, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Analyse des vibrations de différents UAV pour l'utilisation d'un lidar sur ceux-ci&lt;/td&gt;
			&lt;td&gt;Gasoline helicoptère&lt;/td&gt;
			&lt;td&gt;HDL-32 lidar&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Sélection d'un rotor adapté, mesure et tentative d'atténuation des vibrations avec IMU&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Tulldahl2015&quot;&gt;(Tulldahl, Bissmarck, Larsson, Grönwall, &amp;amp; Tolt, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Évaluation de la précision d'un lidar sur UAV&lt;/td&gt;
			&lt;td&gt;Tarot-810 hexacoptère&lt;/td&gt;
			&lt;td&gt;Velodyne HDL-32E&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Traitement des données (calibration dynamique)&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Yang2015&quot;&gt;(Yang &amp;amp; Chen, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Utilisation d'un lidar sur un mini-UAV&lt;/td&gt;
			&lt;td&gt;Rotor wing mini UAV&lt;/td&gt;
			&lt;td&gt;Riegl LMS-Q160&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Traitement des données pour avoir la forme des objets repérés par le lidar (ICP), fusion de la forme, des points et images obtenu par la pose de l'UAV et lidar&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Kasturi2016&quot;&gt;(Kasturi, Milanovic, Atwood, &amp;amp; Yang, 2016)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Développement d'un mini scanner pour drone avec MEMS (composants optique et miroirs)&lt;/td&gt;
			&lt;td&gt;DJI Phantom II&lt;/td&gt;
			&lt;td&gt;Playzer&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Intérieur&lt;/td&gt;
			&lt;td&gt;Test du prototype, différents mode de scan par laser, différents mode de prise de mesure, tracking d'objets par laser, contrôle android du Playzer via Bluetooth&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Mastrangelo2018&quot;&gt;(Mastrangelo, von Niederhausern, Nelson, &amp;amp; Fuller, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Obtention et accès à des images 3D en temps réel depuis UAV&lt;/td&gt;
			&lt;td&gt;LASE drone&lt;/td&gt;
			&lt;td&gt;ASC TigerCub camera, Arete AirTrac laser, Sentech color camera, Hood Tech gimbal&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Acquisition des données avec correction de la pose&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Torresan2018&quot;&gt;(Torresan et al., 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Intégration d'un lidar sur UAV pour mesurer ses performances&lt;/td&gt;
			&lt;td&gt;Hexarotor&lt;/td&gt;
			&lt;td&gt;LUX 4L&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;VN-300 GNSS&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Filtre de Kalman étendu, calibration des mesures, étude accès sur la précision et l'efficacité du GNSS&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Nasrollahi2018&quot;&gt;(Nasrollahi, Bolourian, Zhu, &amp;amp; Hammad, 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Construction d'UAV équippé d'un lidar pour l'inspection de structure&lt;/td&gt;
			&lt;td&gt;DJI Matrice 100&lt;/td&gt;
			&lt;td&gt;Hokuyo UTM-30LX&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Intérieur&lt;/td&gt;
			&lt;td&gt;Mode stationnaire pour tester la cartographie 3D&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;center&gt;&lt;h3&gt;Algorithmes pour l'odométrie et comparaison entre lidar sur UAV et lidar sur robot terrestre&lt;/h3&gt;&lt;/center&gt;
&lt;div style=&quot;overflow-x: visible;&quot;&gt;
&lt;table class=&quot;large&quot;&gt;
	&lt;thead&gt;
		&lt;tr class=&quot;header&quot;&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Article&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Sujet&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;UAV&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;lidar&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Caméra&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GPS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;IMU&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;GNSS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;INS&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Test&lt;/th&gt;
			&lt;th style=&quot;text-align: center;&quot;&gt;Notes&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Tulldahl2014&quot;&gt;(Tulldahl &amp;amp; Larsson, 2014)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Comparaison de données de lidar sur UAV avec lidar terrestre&lt;/td&gt;
			&lt;td&gt;Tarot-810 hexacoptère&lt;/td&gt;
			&lt;td&gt;Velodyne HDL-32E&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;MEMS-IMU&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Comparaison de données via lidar terrestre sur véhicule et statique&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Yousif2015&quot;&gt;(Yousif, Bab-Hadiashar, &amp;amp; Hoseinnezhad, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Description des algorithmes et stratégies utilisés pour l'odométrie&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Enquête&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Lawson2015&quot;&gt;(Lawson, 2015)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Fusion de nuages de points obtenus par de multiple UAV&lt;/td&gt;
			&lt;td&gt;Quadrocoptère construit&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Kinect RGB&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Intérieur avec 2 drones&lt;/td&gt;
			&lt;td&gt;Génération d'un nuage de points donné à un algorithme de fusion de données utilisant ICP, besoin de plusieurs superpositions pour avoir de meilleurs résultats&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Petras2016&quot;&gt;(Petras, Petrasova, Jeziorska, &amp;amp; Mitasova, 2016)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Utilisation de données obtenues par UAV et lidar via un logiciel appelé Grass GIS&lt;/td&gt;
			&lt;td&gt;Avion&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;Microsoft Kinect&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Plus accès sur le traitement de données, densité des points testés pour réduire les points redondants&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Gasparovic2017&quot;&gt;(Gašparović, Seletković, Berta, &amp;amp; Balenović, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Évaluation de données prises par UAV et lidar durant des conditions non-optimales (vent, nuages, densité de points, ...)&lt;/td&gt;
			&lt;td&gt;DJI Phantom 4 Pro, avion Pilatus P6&lt;/td&gt;
			&lt;td&gt;Optech ALTM Gemini 167 (airplane)&lt;/td&gt;
			&lt;td&gt;FC6310 caméra (drone)&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Corrélation photo et lidar, comparaison données lidar avec nuages de points issus de photo&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Persad2017&quot;&gt;(Persad &amp;amp; Armenakis, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Comparaison d'approche de fusion de données collectées par différents systèmes (lidar sur UAV et lidar terrestre)&lt;/td&gt;
			&lt;td&gt;Geo-X8000&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Les résultats dépendent beaucoup de la configuration et des paramètres des nuages de points&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Kwon2017&quot;&gt;(Kwon, Park, Moon, Jung, &amp;amp; Park, 2017)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Fusion rapide de données 3D atypiques dans différentes situations sur des chantiers de constructions (lidar sur UAV and lidar terrestre)&lt;/td&gt;
			&lt;td&gt;DJI Phantom 3 avanced&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;RTK pour estimation de position&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Fuad2018&quot;&gt;(Fuad et al., 2018)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Influence de l'altitude sur la précision des mesures&lt;/td&gt;
			&lt;td&gt;AL3 S1000&lt;/td&gt;
			&lt;td&gt;AL3-32&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;Plus l'altitude augmente (20m, 40m, 60m), plus la précision diminue (RMS 0.323m, 0.450m, 0.616m)&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;&lt;a href=&quot;#Park2019&quot;&gt;(Park, Kim, Cho, &amp;amp; Kang, 2019)&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt;Fusion de données obtenues par différentes plateformes et différents capteurs (UAV et UGV)&lt;/td&gt;
			&lt;td&gt;Quadrotor et UGV&lt;/td&gt;
			&lt;td&gt;lidar (UGV)&lt;/td&gt;
			&lt;td&gt;Caméra (UAV)&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;O&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;-&lt;/td&gt;
			&lt;td&gt;Extérieur&lt;/td&gt;
			&lt;td&gt;ICP pour traiter les données, SLAM pour UGV, élimination des points redondants puis ICP, le drone doit prendre des images entre 30 degré et 90 degré pour optimiser les résultats&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h1 id=&quot;références&quot;&gt;Références&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Polewski2019&quot;&gt;Polewski, P., Yao, W., Cao, L., &amp;amp; Gao, S. (2019). Marker-free coregistration of UAV and backpack LiDAR point clouds in forested areas. &lt;i&gt;ISPRS Journal of Photogrammetry and Remote Sensing&lt;/i&gt;, &lt;i&gt;147&lt;/i&gt;(July 2018), 307–318. https://doi.org/10.1016/j.isprsjprs.2018.11.020&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Polewski2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Papachristos2019&quot;&gt;Papachristos, C., Khattak, S., Mascarich, F., &amp;amp; Alexis, K. (2019). &lt;i&gt;Autonomous Navigation and Mapping in Underground Mines Using Aerial Robots&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Papachristos2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Park2019&quot;&gt;Park, J., Kim, P., Cho, Y. K., &amp;amp; Kang, J. (2019). Framework for automated registration of UAV and UGV point clouds using local features in images. &lt;i&gt;Automation in Construction&lt;/i&gt;, &lt;i&gt;98&lt;/i&gt;(November 2018), 175–182. https://doi.org/10.1016/j.autcon.2018.11.024&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Park2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Cramer2018&quot;&gt;Cramer, M., Haala, N., Laupheimer, D., Mandlburger, G., &amp;amp; Havel, P. (2018). Ultra-High Precision Uav-Based Lidar and Dense Image Matching, &lt;i&gt;XLII&lt;/i&gt;(October), 10–12.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Cramer2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Gomes2018&quot;&gt;Gomes, A., Guerreiro, B. J., Cunha, R., Silvestre, C., &amp;amp; Oliveira, P. (2018). Sensor-based 3-D pose estimation and control of rotary-wing UAVs using a 2-D LiDAR. &lt;i&gt;Advances in Intelligent Systems and Computing&lt;/i&gt;, &lt;i&gt;693&lt;/i&gt;, 718–729. https://doi.org/10.1007/978-3-319-70833-1_58&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Gomes2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Hinterhofer2018&quot;&gt;Hinterhofer, T., Ullrich, A., Hofstätter, M., Pfennigbauer, M., Schraml, S., &amp;amp; Rothbacher, D. (2018). UAV-based LiDAR and gamma probe with real-time data processing and downlink for survey of nuclear disaster locations. &lt;i&gt;Chemical, Biological, Radiological, Nuclear, and Explosives (CBRNE) Sensing XIX&lt;/i&gt;, (May 2018), 11. https://doi.org/10.1117/12.2304353&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Hinterhofer2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Mastrangelo2018&quot;&gt;Mastrangelo, J., von Niederhausern, K., Nelson, R. D., &amp;amp; Fuller, D. (2018). Real-time LIDAR from ScanEagle UAV. &lt;i&gt;Ground/Air Multisensor Interoperability, Integration, and Networking for Persistent ISR IX&lt;/i&gt;, (May 2018), 33. https://doi.org/10.1117/12.2304393&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Mastrangelo2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Fuad2018&quot;&gt;Fuad, N. A., Ismail, Z., Majid, Z., Darwin, N., Ariff, M. F. M., Idris, K. M., &amp;amp; Yusoff, A. R. (2018). Accuracy evaluation of digital terrain model based on different flying altitudes and conditional of terrain using UAV LiDAR technology. &lt;i&gt;IOP Conference Series: Earth and Environmental Science&lt;/i&gt;, &lt;i&gt;169&lt;/i&gt;(1). https://doi.org/10.1088/1755-1315/169/1/012100&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Fuad2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Youn2018&quot;&gt;Youn, J., Kim, D., Kim, T., Yoo, J. H., &amp;amp; Lee, B. J. (2018). Development of Uav Air Roads By Using 3D Grid System. &lt;i&gt;ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences&lt;/i&gt;, &lt;i&gt;XLII-4&lt;/i&gt;(October), 731–735. https://doi.org/10.5194/isprs-archives-XLII-4-731-2018&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Youn2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Liu2018&quot;&gt;Liu, K., Shen, X., Cao, L., Wang, G., &amp;amp; Cao, F. (2018). Estimating forest structural attributes using UAV-LiDAR data in Ginkgo plantations. &lt;i&gt;ISPRS Journal of Photogrammetry and Remote Sensing&lt;/i&gt;, &lt;i&gt;146&lt;/i&gt;(November), 465–482. https://doi.org/10.1016/j.isprsjprs.2018.11.001&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Liu2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Huang2018&quot;&gt;Huang, Z. C., Yeh, C. Y., Tseng, K. H., &amp;amp; Hsu, W. Y. (2018). A UAV-RTK lidar system for wave and tide measurements in coastal zones. &lt;i&gt;Journal of Atmospheric and Oceanic Technology&lt;/i&gt;, &lt;i&gt;35&lt;/i&gt;(8), 1557–1570. https://doi.org/10.1175/JTECH-D-17-0199.1&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Huang2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Yan2018&quot;&gt;Yan, W., Guan, H., Cao, L., Yu, Y., Gao, S., Lu, J. Y., … Lu, J. Y. (2018). An Automated Hierarchical Approach for Three-Dimensional Segmentation of Single Trees Using UAV LiDAR Data. &lt;i&gt;Remote Sensing&lt;/i&gt;, &lt;i&gt;10&lt;/i&gt;(12), 1999. https://doi.org/10.3390/rs10121999&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Yan2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Chen2018&quot;&gt;Chen, C., Yang, B., Song, S., Peng, X., &amp;amp; Huang, R. (2018). Automatic clearance anomaly detection for transmission line corridors utilizing UAV-Borne LIDAR data. &lt;i&gt;Remote Sensing&lt;/i&gt;, &lt;i&gt;10&lt;/i&gt;(4). https://doi.org/10.3390/rs10040613&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Chen2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Govedarica2018&quot;&gt;Govedarica, M., Jakovljevic, G., &amp;amp; Álvarez Taboada, F. (2018). Flood risk assessment based on LiDAR and UAV points clouds and DEM. &lt;i&gt;Remote Sensing for Agriculture, Ecosystems, and Hydrology XX&lt;/i&gt;, (October 2018), 102. https://doi.org/10.1117/12.2513278&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Govedarica2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Torresan2018&quot;&gt;Torresan, C., Berton, A., Carotenuto, F., Chiavetta, U., Miglietta, F., Zaldei, A., &amp;amp; Gioli, B. (2018). Development and performance assessment of a low-cost UAV laser scanner system (LasUAV). &lt;i&gt;Remote Sensing&lt;/i&gt;, &lt;i&gt;10&lt;/i&gt;(7), 1–17. https://doi.org/10.3390/rs10071094&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Torresan2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Mascarich2018&quot;&gt;Mascarich, F., Wilson, T., Khattak, S., Dang, T., Papachristos, C., &amp;amp; Alexis, K. (2018). WM2018 Conference, March 18 – 22, 2018, Phoenix, Arizona, USA Autonomous 3D and Radiation Mapping in Tunnel Environments Using Aerial Robots – 18156 Frank Mascarich, Taylor Wilson, Shehryar Khattak, Tung Dang, Christos Papachristos, Kostas Alexis Universi, 1–12.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Mascarich2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Nasrollahi2018&quot;&gt;Nasrollahi, M., Bolourian, N., Zhu, Z., &amp;amp; Hammad, A. (2018). Designing LiDAR-equipped UAV Platform for Structural Inspection. &lt;i&gt;Proceedings of the 35th International Symposium on Automation and Robotics in Construction (ISARC)&lt;/i&gt;, (July). https://doi.org/10.22260/isarc2018/0152&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Nasrollahi2018/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Teng2017&quot;&gt;Teng, G. E., Zhou, M., Li, C. R., Wu, H. H., Li, W., Meng, F. R., … Ma, L. (2017). Mini-UAV LIDAR for power line inspection. &lt;i&gt;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives&lt;/i&gt;, &lt;i&gt;42&lt;/i&gt;(2W7), 297–300. https://doi.org/10.5194/isprs-archives-XLII-2-W7-297-2017&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Teng2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Morsdorf2017&quot;&gt;Morsdorf, F., Eck, C., Zgraggen, C., Imbach, B., Schneider, F. D., &amp;amp; Kükenbrink, D. (2017). UAV-based LiDAR acquisition for the derivation of high-resolution forest and ground information. &lt;i&gt;The Leading Edge&lt;/i&gt;, &lt;i&gt;36&lt;/i&gt;(7), 566–570. https://doi.org/10.1190/tle36070566.1&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Morsdorf2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Gawel2017&quot;&gt;Gawel, A., Dube, R., Surmann, H., Nieto, J., Siegwart, R., &amp;amp; Cadena, C. (2017). 3D registration of aerial and ground robots for disaster response: An evaluation of features, descriptors, and transformation estimation. &lt;i&gt;SSRR 2017 - 15th IEEE International Symposium on Safety, Security and Rescue Robotics, Conference&lt;/i&gt;, 27–34. https://doi.org/10.1109/SSRR.2017.8088136&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Gawel2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Gasparovic2017&quot;&gt;Gašparović, M., Seletković, A., Berta, A., &amp;amp; Balenović, I. (2017). The Evaluation of Photogrammetry-Based DSM from Low-Cost UAV by LiDAR-Based DSM. &lt;i&gt;South-East European Forestry&lt;/i&gt;, &lt;i&gt;8&lt;/i&gt;(2). https://doi.org/10.15177/seefor.17-16&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Gasparovic2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Christiansen2017&quot;&gt;Christiansen, M. P., Laursen, M. S., Jørgensen, R. N., Skovsen, S., &amp;amp; Gislum, R. (2017). Designing and testing a UAV mapping system for agricultural field surveying. &lt;i&gt;Sensors (Switzerland)&lt;/i&gt;, &lt;i&gt;17&lt;/i&gt;(12), 1–19. https://doi.org/10.3390/s17122703&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Christiansen2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;AjayKumar2017&quot;&gt;Ajay Kumar, G., Patil, A. K., Patil, R., Park, S. S., &amp;amp; Chai, Y. H. (2017). A LiDAR and IMU integrated indoor navigation system for UAVs and its application in real-time pipeline classification. &lt;i&gt;Sensors (Switzerland)&lt;/i&gt;, &lt;i&gt;17&lt;/i&gt;(6). https://doi.org/10.3390/s17061268&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/AjayKumar2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Sankey2017&quot;&gt;Sankey, T., Donager, J., McVay, J., &amp;amp; Sankey, J. B. (2017). UAV lidar and hyperspectral fusion for forest monitoring in the southwestern USA. &lt;i&gt;Remote Sensing of Environment&lt;/i&gt;, &lt;i&gt;195&lt;/i&gt;, 30–43. https://doi.org/10.1016/j.rse.2017.04.007&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Sankey2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Chen2017&quot;&gt;Chen, S., McDermid, G. J., Castilla, G., &amp;amp; Linke, J. (2017). Measuring vegetation height in linear disturbances in the boreal forest with UAV photogrammetry. &lt;i&gt;Remote Sensing&lt;/i&gt;, &lt;i&gt;9&lt;/i&gt;(12). https://doi.org/10.3390/rs9121257&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Chen2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Nikolov2017&quot;&gt;Nikolov, I., &amp;amp; Madsen, C. (2017). LiDAR-based 2D Localization and Mapping System using Elliptical Distance Correction Models for UAV Wind Turbine Blade Inspection. &lt;i&gt;Proceedings of the 12th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications&lt;/i&gt;, (Visigrapp), 418–425. https://doi.org/10.5220/0006124304180425&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Nikolov2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Kwon2017&quot;&gt;Kwon, S., Park, J. W., Moon, D., Jung, S., &amp;amp; Park, H. (2017). Smart Merging Method for Hybrid Point Cloud Data using UAV and LIDAR in Earthwork Construction. &lt;i&gt;Procedia Engineering&lt;/i&gt;, &lt;i&gt;196&lt;/i&gt;(June), 21–28. https://doi.org/10.1016/j.proeng.2017.07.168&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Kwon2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Elaksher2017&quot;&gt;Elaksher, A., Bhandari, S., Carreon Limones, C. A., &amp;amp; Lauf, R. (2017). Potential of UAV lidar systems for geospatial mapping. &lt;i&gt;Lidar Remote Sensing for Environmental Monitoring 2017&lt;/i&gt;, (August 2017), 20. https://doi.org/10.1117/12.2275482&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Elaksher2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;PututAshShidiq2017&quot;&gt;Putut Ash Shidiq, I., Wibowo, A., Kusratmoko, E., Indratmoko, S., Ardhianto, R., &amp;amp; Prasetyo Nugroho, B. (2017). Urban forest topographical mapping using UAV LIDAR. &lt;i&gt;IOP Conference Series: Earth and Environmental Science&lt;/i&gt;, &lt;i&gt;98&lt;/i&gt;(1). https://doi.org/10.1088/1755-1315/98/1/012034&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/PututAshShidiq2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Guo2017&quot;&gt;Guo, Q., Su, Y., Hu, T., Zhao, X., Wu, F., Li, Y., … Wang, X. (2017). An integrated UAV-borne lidar system for 3D habitat mapping in three forest ecosystems across China. &lt;i&gt;International Journal of Remote Sensing&lt;/i&gt;, &lt;i&gt;38&lt;/i&gt;(8-10), 2954–2972. https://doi.org/10.1080/01431161.2017.1285083&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Guo2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Wei2017&quot;&gt;Wei, L., Yang, B., Jiang, J., Cao, G., &amp;amp; Wu, M. (2017). Vegetation filtering algorithm for UAV-borne lidar point clouds: a case study in the middle-lower Yangtze River riparian zone. &lt;i&gt;International Journal of Remote Sensing&lt;/i&gt;, &lt;i&gt;38&lt;/i&gt;(8-10), 2991–3002. https://doi.org/10.1080/01431161.2016.1252476&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Wei2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Thiel2017&quot;&gt;Thiel, C., &amp;amp; Schmullius, C. (2017). Comparison of UAV photograph-based and airborne lidar-based point clouds over forest from a forestry application perspective. &lt;i&gt;International Journal of Remote Sensing&lt;/i&gt;, &lt;i&gt;38&lt;/i&gt;(8-10), 2411–2426. https://doi.org/10.1080/01431161.2016.1225181&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Thiel2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Gee2017&quot;&gt;Gee, T., James, J., Van Der Mark, W., Delmas, P., &amp;amp; Gimel’Farb, G. (2017). Lidar guided stereo simultaneous localization and mapping (SLAM) for UAV outdoor 3-D scene reconstruction. &lt;i&gt;International Conference Image and Vision Computing New Zealand&lt;/i&gt;, 1–6. https://doi.org/10.1109/IVCNZ.2016.7804433&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Gee2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Persad2017&quot;&gt;Persad, R. A., &amp;amp; Armenakis, C. (2017). Comparison of 2d and 3D approaches for the alignment of UAV and lidar point clouds. &lt;i&gt;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives&lt;/i&gt;, &lt;i&gt;42&lt;/i&gt;(2W6), 275–279. https://doi.org/10.5194/isprs-archives-XLII-2-W6-275-2017&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Persad2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Chiang2017&quot;&gt;Chiang, K. W., Tsai, G. J., Li, Y. H., &amp;amp; El-Sheimy, N. (2017). Development of LiDAR-Based UAV System for Environment Reconstruction. &lt;i&gt;IEEE Geoscience and Remote Sensing Letters&lt;/i&gt;, &lt;i&gt;14&lt;/i&gt;(10), 1790–1794. https://doi.org/10.1109/LGRS.2017.2736013&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Chiang2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Moore2017&quot;&gt;Moore, A. J., Schubert, M., Rymer, N., Balachandran, S., Consiglio, M., Munoz, C., … Schneider Georgia Power, P. (2017). UAV Inspection of Electrical Transmission Infrastructure with Path Conformance Autonomy and Lidar-based Geofences NASA Report on UTM Reference Mission Flights at Southern Company Flights November 2016 NASA STI Program . . . in Profile.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Moore2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Edwards2017&quot;&gt;Edwards, A. S. (2017). Autonomous 3D Mapping and Surveillance of Mines with MAVs, (March).&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Edwards2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Shetty2017&quot;&gt;Shetty, A., &amp;amp; Gao, G. X. (2017). Covariance Estimation for GPS-LiDAR Sensor Fusion for UAVs, 1–5.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Shetty2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Koska2017&quot;&gt;Koska, B., Jirka, V., Urban, R., Křemen, T., Hesslerová, P., Jon, J., … Fogl, M. (2017). Suitability, characteristics, and comparison of an airship UAV with lidar for middle size area mapping. &lt;i&gt;International Journal of Remote Sensing&lt;/i&gt;, &lt;i&gt;38&lt;/i&gt;(8-10), 2973–2990. https://doi.org/10.1080/01431161.2017.1285086&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Koska2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Vempati2017&quot;&gt;Vempati, A. S., Gilitschenski, I., Nieto, J., Beardsley, P., &amp;amp; Siegwart, R. (2017). Onboard real-time dense reconstruction of large-scale environments for UAV. &lt;i&gt;IEEE International Conference on Intelligent Robots and Systems&lt;/i&gt;, &lt;i&gt;2017-September&lt;/i&gt;, 3479–3486. https://doi.org/10.1109/IROS.2017.8206189&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Vempati2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Ozaslan2017&quot;&gt;Ozaslan, T., Taylor, C. J., Kumar, V., Keller, J., Wozencraft, J. M., Loianno, G., &amp;amp; Hood, T. (2017). Autonomous Navigation and Mapping for Inspection of Penstocks and Tunnels With MAVs. &lt;i&gt;IEEE Robotics and Automation Letters&lt;/i&gt;, &lt;i&gt;2&lt;/i&gt;(3), 1740–1747. https://doi.org/10.1109/lra.2017.2699790&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Ozaslan2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Petras2016&quot;&gt;Petras, V., Petrasova, A., Jeziorska, J., &amp;amp; Mitasova, H. (2016). Processing UAV and LiDAR point clouds in grass GIS. &lt;i&gt;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives&lt;/i&gt;, &lt;i&gt;41&lt;/i&gt;(July), 945–952. https://doi.org/10.5194/isprsarchives-XLI-B7-945-2016&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Petras2016/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Kasturi2016&quot;&gt;Kasturi, A., Milanovic, V., Atwood, B. H., &amp;amp; Yang, J. (2016). UAV-borne lidar with MEMS mirror-based scanning capability, (May 2016), 98320M. https://doi.org/10.1117/12.2224285&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Kasturi2016/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Reiss2016&quot;&gt;Reiss, M. L. L., Da Rocha, R. S., Ferraz, R. S., Cruz, V. C., Morador, L. Q., Yamawaki, M. K., … Mezzomo, W. (2016). Data integration acquired from micro-UAV and terrestrial laser scanner for the 3D mapping of jesuit ruins of são miguel das missões. &lt;i&gt;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives&lt;/i&gt;, &lt;i&gt;41&lt;/i&gt;(July), 315–321. https://doi.org/10.5194/isprsarchives-XLI-B5-315-2016&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Reiss2016/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Lawson2015&quot;&gt;Lawson, A. (2015). Cooperative 3-D Map Generation Using Multiple UAVs. &lt;i&gt;University Scholar Projects&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Lawson2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Liu2015&quot;&gt;Liu, S., Mohta, K., Shen, S., &amp;amp; Kumar, V. (2015). Towards Collaborative Mapping and Exploration Using Multiple Micro Aerial Robots BT - Experimental Robotics: The 14th International Symposium on Experimental Robotics. &lt;i&gt;Experimental Robotics III&lt;/i&gt;. https://doi.org/10.1007/bfb0027579&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Liu2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Pan2015&quot;&gt;Pan, W. W., Dou, Y. J., Wang, G. L., Wu, M. X., Ren, R. G., &amp;amp; Xu, X. (2015). Development and test of blimp-based compact LIDAR powewr-line inspection system. &lt;i&gt;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives&lt;/i&gt;, &lt;i&gt;40&lt;/i&gt;(3W2), 155–159. https://doi.org/10.5194/isprsarchives-XL-3-W2-155-2015&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Pan2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Li2015&quot;&gt;Li, Z., Yan, Y., Jing, Y., &amp;amp; Zhao, S. G. (2015). The design and testing of a LiDAR platform for a UAV for heritage mapping. &lt;i&gt;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives&lt;/i&gt;, &lt;i&gt;40&lt;/i&gt;(1W4), 17–24. https://doi.org/10.5194/isprsarchives-XL-1-W4-17-2015&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Li2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Yousif2015&quot;&gt;Yousif, K., Bab-Hadiashar, A., &amp;amp; Hoseinnezhad, R. (2015). An Overview to Visual Odometry and Visual SLAM: Applications to Mobile Robotics. &lt;i&gt;Intelligent Industrial Systems&lt;/i&gt;, &lt;i&gt;1&lt;/i&gt;(4), 289–311. https://doi.org/10.1007/s40903-015-0032-7&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Yousif2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Gu2015&quot;&gt;Gu, T., &amp;amp; Zhang, N. (2015). Application of iterative closest point algorithm in automatic flight of speedy UAV. &lt;i&gt;2014 IEEE Chinese Guidance, Navigation and Control Conference, CGNCC 2014&lt;/i&gt;, 1456–1459. https://doi.org/10.1109/CGNCC.2014.7007407&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Gu2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Mandlburger2015&quot;&gt;Mandlburger, G., Pfennigbauer, M., Riegl, U., Haring, A., Wieser, M., Glira, P., &amp;amp; Winiwarter, L. (2015). Complementing airborne laser bathymetry with UAV-based lidar for capturing alluvial landscapes, (October 2015), 96370A. https://doi.org/10.1117/12.2194779&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Mandlburger2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Tulldahl2015&quot;&gt;Tulldahl, H. M., Bissmarck, F., Larsson, H., Grönwall, C., &amp;amp; Tolt, G. (2015). Accuracy evaluation of 3D lidar data from small UAV, &lt;i&gt;964903&lt;/i&gt;(October 2015), 964903. https://doi.org/10.1117/12.2194508&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Tulldahl2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Yang2015&quot;&gt;Yang, B., &amp;amp; Chen, C. (2015). Automatic registration of UAV-borne sequent images and LiDAR data. &lt;i&gt;ISPRS Journal of Photogrammetry and Remote Sensing&lt;/i&gt;, &lt;i&gt;101&lt;/i&gt;, 262–274. https://doi.org/10.1016/j.isprsjprs.2014.12.025&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Yang2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Ni2015&quot;&gt;Ni, W., Liu, J., Zhang, Z., Sun, G., &amp;amp; Yang, A. (2015). Evaluation of UAV-based forest inventory system compared with LiDAR data. &lt;i&gt;International Geoscience and Remote Sensing Symposium (IGARSS)&lt;/i&gt;, &lt;i&gt;2015-Novem&lt;/i&gt;, 3874–3877. https://doi.org/10.1109/IGARSS.2015.7326670&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Ni2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Esposito2014&quot;&gt;Esposito, S., Mura, M., Fallavollita, P., Balsi, M., Chirici, G., Oradini, A., &amp;amp; Marchetti, M. (2014). Performance evaluation of lightweight LiDAR for UAV applications. &lt;i&gt;International Geoscience and Remote Sensing Symposium (IGARSS)&lt;/i&gt;, 792–795. https://doi.org/10.1109/IGARSS.2014.6946543&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Esposito2014/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Roca2014&quot;&gt;Roca, D., Armesto, J., Lagüela, S., &amp;amp; Díaz-Vilariño, L. (2014). LIDAR-equipped UAV for building information modelling. &lt;i&gt;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives&lt;/i&gt;, &lt;i&gt;40&lt;/i&gt;(5), 523–527. https://doi.org/10.5194/isprsarchives-XL-5-523-2014&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Roca2014/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Tulldahl2014&quot;&gt;Tulldahl, H. M., &amp;amp; Larsson, H. (2014). Lidar on small UAV for 3D mapping, &lt;i&gt;925009&lt;/i&gt;(October 2014), 925009. https://doi.org/10.1117/12.2068448&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Tulldahl2014/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Wallace2014&quot;&gt;Wallace, L., Lucieer, A., &amp;amp; Watson, C. S. (2014). Evaluating tree detection and segmentation routines on very high resolution UAV LiDAR ata. &lt;i&gt;IEEE Transactions on Geoscience and Remote Sensing&lt;/i&gt;, &lt;i&gt;52&lt;/i&gt;(12), 7619–7628. https://doi.org/10.1109/TGRS.2014.2315649&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Wallace2014/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Lin2014&quot;&gt;Lin, Y., &amp;amp; West, G. (2014). Attempt of UAV oblique images and MLS point clouds for 4D modelling of roadside pole-like objects, &lt;i&gt;9262&lt;/i&gt;(November 2014), 92620Q. https://doi.org/10.1117/12.2068287&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Lin2014/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Zhou2013&quot;&gt;Zhou, G., Yang, B., Zhang, W., Tao, X., Zhao, W., Yue, T., … Yang, C. (2013). Simulation study of new generation of airborne scannerless LiDAR system. &lt;i&gt;International Geoscience and Remote Sensing Symposium (IGARSS)&lt;/i&gt;, (February 2015), 524–527. https://doi.org/10.1109/IGARSS.2013.6721208&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Zhou2013/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Wallace2013&quot;&gt;Wallace, L. (2013). Assessing the stability of canopy maps produced from UAV-LiDAR data. &lt;i&gt;International Geoscience and Remote Sensing Symposium (IGARSS)&lt;/i&gt;, (Figure 1), 3879–3882. https://doi.org/10.1109/IGARSS.2013.6723679&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Wallace2013/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Wallace2012a&quot;&gt;Wallace, L. O., Lucieer, A., &amp;amp; Watson, C. S. (2012). Assessing the Feasibility of Uav-Based Lidar for High Resolution Forest Change Detection. &lt;i&gt;ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences&lt;/i&gt;, &lt;i&gt;XXXIX-B7&lt;/i&gt;(September), 499–504. https://doi.org/10.5194/isprsarchives-XXXIX-B7-499-2012&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Wallace2012a/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Wallace2012&quot;&gt;Wallace, L., Lucieer, A., Watson, C., &amp;amp; Turner, D. (2012). Development of a UAV-LiDAR system with application to forest inventory. &lt;i&gt;Remote Sensing&lt;/i&gt;, &lt;i&gt;4&lt;/i&gt;(6), 1519–1543. https://doi.org/10.3390/rs4061519&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Wallace2012/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Michael2012&quot;&gt;Michael, N., Shen, S., Motha, K., Mulgaonkar, Y., Kumar, V., Nagatani, K., … Tadokoro, S. (2012). Collaborative mapping of an earthquake‐damaged building via ground and aerial robots. &lt;i&gt;\Ldots of Field Robotics&lt;/i&gt;, &lt;i&gt;29&lt;/i&gt;(5), 832–841. https://doi.org/10.1002/rob&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Michael2012/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Hwang2012&quot;&gt;Hwang, Y., &amp;amp; Tahk, M.-jea. (2012). Terrain Referenced UAV Navigation with Lidar – a Comparison of Sequential Processing and Batch Processing Algorithms. &lt;i&gt;28th INTERNATIONAL CONGRESS OF THE AERONAUTICAL SCIENCES&lt;/i&gt;, 1–7.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Hwang2012/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Candigliota2012&quot;&gt;Candigliota, E., Immordino, F., Moretti, L., &amp;amp; Indirli, M. (2012). Remote sensing, laser scanner survey and GIS integrated method for assessment and preservation of historic centers: the example of Arsita. &lt;i&gt;In Proceedings of the 15th World Conference on Earthquake Engineering - WCEE&lt;/i&gt;, 1–9.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Candigliota2012/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Han2012&quot;&gt;Han, K., Aeschliman, C., Park, J., Kak, A. C., Kwon, H., &amp;amp; Pack, D. J. (2012). UAV vision: Feature based accurate ground target localization through propagated initializations and interframe homographies. &lt;i&gt;Proceedings - IEEE International Conference on Robotics and Automation&lt;/i&gt;, 944–950. https://doi.org/10.1109/ICRA.2012.6225073&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Han2012/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Durst2011&quot;&gt;Durst, P. J., Baylot, A., &amp;amp; McKinley, B. (2011). Techniques for inferring terrain parameters related to ground vehicle mobility using UAV born IFSAR and LIDAR data. &lt;i&gt;Proceedings of SPIE - The International Society for Optical Engineering&lt;/i&gt;, &lt;i&gt;8020&lt;/i&gt;(May 2011). https://doi.org/10.1117/12.883510&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Durst2011/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Liu2011&quot;&gt;Liu, C., Li, W., Lei, W., Liu, L., &amp;amp; Wu, H. (2011). Architecture planning and geo-disasters assessment mapping of landslide by using airborne lidar data and UAV images, (October 2011), 82861Q. https://doi.org/10.1117/12.912525&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Liu2011/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Downs2004&quot;&gt;Downs, A., Madhavan, R., &amp;amp; Hong, T. (2004). Registration of range data from unmanned aerial and ground vehicles. &lt;i&gt;Proceedings - Applied Imagery Pattern Recognition Workshop&lt;/i&gt;, &lt;i&gt;2003-Janua&lt;/i&gt;, 45–50. https://doi.org/10.1109/AIPR.2003.1284247&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Downs2004/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Zhen&quot;&gt;Zhen, W., &amp;amp; Scherer, S. A Unified 3D Mapping Framework using a 3D or 2D LiDAR. &lt;i&gt;Robotics&lt;/i&gt;, 1–10.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Zhen/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Maxime Vaidis</name><email>vaidis.maxime@gmail.com</email></author><category term="publications" /><category term="ICP" /><category term="registration" /><category term="mapping" /><category term="robot" /><category term="localization" /><summary type="html">Cette enquête présente une vue générale des projets utilisant des lidars (Technologie de mesure de distance et détection par laser) sur des UAV (Véhicule Aérien Autonome).</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22publications/survey-lidar-UAV_feature.jpg%22,%20%22teaser%22=%3E%22publications/survey-lidar-UAV_teaser.jpg%22,%20%22thumb%22=%3Enil,%20%22credit%22=%3E%22H2H%20Associates,%20DroneZon%22%7D" /></entry><entry><title type="html">Projet Scutigera et cartographie souterraine</title><link href="https://norlab.ulaval.ca/research/scutigera_fr/" rel="alternate" type="text/html" title="Projet Scutigera et cartographie souterraine" /><published>2019-02-13T00:00:00-05:00</published><updated>2019-02-13T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/research/scutigera_fr</id><content type="html" xml:base="https://norlab.ulaval.ca/research/scutigera_fr/">&lt;p&gt;L’exploration de larges cavernes en utilisant les outils classiques de scan 3D est toujours un veritable défi. L’espace est assez limité pour permettre l’installation de tripodes équipés de Lidar (Technologie de mesure de distance et détection par laser) haute précision, et les drones (quadromoteurs par exemples) pausent problèmes dans ces endroits étroits du fait des turbulences dans l’air qu’ils causent via les parois rocheuses, ainsi que de leur faible autonomie de batterie. C’est pourquoi ce projet a pour but de développer l’utilisation d’un dirigeable semi-rigide (du type mini-zepplin ou ballon gonflé à l’hélium) afin d’aider à l’observation de ces larges environnements souterrains.&lt;/p&gt;

&lt;p&gt;Plus précisement, le but de ces recherches est d’explorer différentes solutions de scan 3D pour des véhicules volants avec des contraintes de charge matériel. Ce véhicule volant est actuellement en cours de développement par le laboratoire NXI Gestatio (Prof.Reeves, UQAM), avec l’intention de pouvoir y ajouter des capteurs de distance dessus afin de reconstruire son environnement en 3D. Ceci est une extension d’un ancien projet utilisant des cubes gonflés à l’hélium en vue d’une représentation artistique [3], dans lequel une démonstration de cette technologie dans de larges cavernes avait déjà été envisagé. Le laboratoire Norlab aura comme responsabilité l’exploration de solution robuste pour la perception en 3D d’environnement souterrrain menant à des problèmes d’incertitude de positionnement du robot mais également de précision des mesures.&lt;/p&gt;

&lt;p&gt;L’algorithme de reconstrution d’environnement se basera sur la librairie en C++ libpointmatcher (https://github.com/ethz-asl/libpointmatcher), étant une librairie modulable contenant de multiples algorithmes de reconstrution de nuage de point et étant actuellement utilisée dans de multiples projets de recherche à travers le monde. Cette librairie est actuellement mise à jour et développée par le laboratoire Norlab afin d’explorer différents environnement pour le scan 3D [1].
Dépendament de la vitesse de déplacement entre le robot et le capteur 3D Lidar, des solutions de reconstruction de trajectoire en 3D pourront être envisagées [2]. Le prototype final sera testé dans des cavernes naturelles, comme par exemple celle nouvellement découverte à Montréal, la caverne St-Leonard. Récemment, les spéléologues y ont découvert une nouvelle chambre mesurant pas moins de 250 mètres de long et étant difficile d’accès.&lt;/p&gt;

&lt;h1 id=&quot;team&quot;&gt;Team&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Coordinateur du projet&lt;/strong&gt;: &lt;a href=&quot;https://design.uqam.ca/professeur/nicolas-reeves/&quot;&gt;Nicolas Reeves&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Gestion de projet&lt;/strong&gt;: &lt;a href=&quot;http://www.davidstonge.info/&quot;&gt;David St-Onge&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Chef Scientifique - cartographie 3D&lt;/strong&gt;: &lt;a href=&quot;../../people/f_pomerleau/&quot;&gt;François Pomerleau&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Chercheur - cartographie 3D&lt;/strong&gt;: &lt;a href=&quot;../../people/m_vaidis/&quot;&gt;Maxime Vaidis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Pomerleau2013b&quot;&gt;Pomerleau, F., Colas, F., Siegwart, R., &amp;amp; Magnenat, S. (2013). Comparing ICP variants on real-world data sets: Open-source library and experimental protocol. &lt;i&gt;Autonomous Robots&lt;/i&gt;, &lt;i&gt;34&lt;/i&gt;(3), 133–148.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Pomerleau2013b/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="project" /><category term="mapping" /><category term="robot" /><category term="caves" /><category term="airship" /><summary type="html">L’exploration de larges cavernes en utilisant les outils classiques de scan 3D est toujours un veritable défi. L’espace est assez limité pour permettre l’installation de tripodes équipés de Lidar (Technologie de mesure de distance et détection par laser) haute précision, et les drones (quadromoteurs par exemples) pausent problèmes dans ces endroits étroits du fait des turbulences dans l’air qu’ils causent via les parois rocheuses, ainsi que de leur faible autonomie de batterie. C’est pourquoi ce projet a pour but de développer l’utilisation d’un dirigeable semi-rigide (du type mini-zepplin ou ballon gonflé à l’hélium) afin d’aider à l’observation de ces larges environnements souterrains.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22projects/scutigera_feature.jpg%22,%20%22teaser%22=%3E%22projects/scutigera_teaser.jpg%22,%20%22thumb%22=%3Enil,%20%22credit%22=%3E%22Radio-Canada/Soci%C3%A9t%C3%A9%20qu%C3%A9b%C3%A9coise%20de%20sp%C3%A9l%C3%A9ologie,%20Scanner%20Sombre%22%7D" /></entry><entry><title type="html">Scutigera Project</title><link href="https://norlab.ulaval.ca/research/scutigera/" rel="alternate" type="text/html" title="Scutigera Project" /><published>2019-02-13T00:00:00-05:00</published><updated>2019-02-13T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/research/scutigera</id><content type="html" xml:base="https://norlab.ulaval.ca/research/scutigera/">&lt;p&gt;Exploration of large caves is challenging using traditional mapping tools. There are limited places to install a tripod equipped with a highly accurate Lidar (Light Detection And Ranging) and flying drones (i.e., quadrotors) in tight environments causes trouble with air disturbances produced by surrounding walls, along with their limited battery time. This project investigate the use of a semi-rigid airship (e.g., Zeppelin or blimp) to support geological observations of large underground environments.&lt;/p&gt;

&lt;p&gt;More precisely, the goal of this project is to investigate different 3D mapping solutions for a flying vehicle with a limited payload. The flying vehicle is currently being built by the NXI Gestatio Laboratory (Prof.Reeves, University of Quebec at Montreal), with the intention to install 3D sensors allowing the robot to reconstruct its environment in 3D. It is the extension of a formal project using blimps in an artistic context &lt;a href=&quot;#DStOnge2017&quot;&gt;(St-Onge et al., 2017)&lt;/a&gt;, where a demonstration of the technology in a large cave trigged further research interests. The Northern Robotics Laboratory will be responsible to investigate 3D perception solutions robust to underground environmental conditions leading to the uncertainty of the robot pose and to mapping the caves with enough accuracy.&lt;/p&gt;

&lt;p&gt;The mapping algorithms will be based on the C++ library &lt;a href=&quot;https://github.com/ethz-asl/libpointmatcher&quot;&gt;libpointmatcher&lt;/a&gt;, a modular library containing multiple algorithms used inside registration algorithms and currently used in multiple research projects around the world. This library is currently maintained and developed by Norlab to investigate different conditions for 3D mapping &lt;a href=&quot;#Pomerleau2013b&quot;&gt;(Pomerleau, Colas, Siegwart, &amp;amp; Magnenat, 2013)&lt;/a&gt;.
Depending on the speed ratio between the robot and the 3D scanner, solutions along smooth 3D trajectory reconstruction &lt;a href=&quot;#Zhang2015&quot;&gt;(Zhang &amp;amp; Singh, 2015)&lt;/a&gt; is expected. The final prototype will be tested in a real cave, which could be the newly discovered cave of St-Leonard. Recently, spelunkers discovered a new chamber in this cave measuring 250-metres long that is difficult to explore and raising scientific interests.&lt;/p&gt;

&lt;h1 id=&quot;team&quot;&gt;Team&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Project Coordinator&lt;/strong&gt;: &lt;a href=&quot;https://design.uqam.ca/professeur/nicolas-reeves/&quot;&gt;Nicolas Reeves&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Project Management&lt;/strong&gt;: &lt;a href=&quot;http://www.davidstonge.info/&quot;&gt;David St-Onge&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scientific Lead - 3D mapping&lt;/strong&gt;: &lt;a href=&quot;../../people/f_pomerleau/&quot;&gt;François Pomerleau&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Researcher - 3D mapping&lt;/strong&gt;: &lt;a href=&quot;../../people/m_vaidis/&quot;&gt;Maxime Vaidis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;DStOnge2017&quot;&gt;St-Onge, D., Brèches, P.-Y., Sharf, I., Reeves, N., Rekleitis, I., Abouzakhm, P., … Giguère, P. (2017). Control, localization and human interaction with an autonomous lighter-than-air performer. &lt;i&gt;Robotic and Autonomous Systems&lt;/i&gt;, &lt;i&gt;88&lt;/i&gt;, 165–186.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/DStOnge2017/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Zhang2015&quot;&gt;Zhang, J., &amp;amp; Singh, S. (2015). LOAM: Lidar odometry and mapping in real-time. &lt;i&gt;IEEE Transactions on Robotics&lt;/i&gt;, &lt;i&gt;32&lt;/i&gt;(7), 141–148.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Zhang2015/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Pomerleau2013b&quot;&gt;Pomerleau, F., Colas, F., Siegwart, R., &amp;amp; Magnenat, S. (2013). Comparing ICP variants on real-world data sets: Open-source library and experimental protocol. &lt;i&gt;Autonomous Robots&lt;/i&gt;, &lt;i&gt;34&lt;/i&gt;(3), 133–148.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Pomerleau2013b/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;

&lt;h1 id=&quot;link&quot;&gt;Link&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.nxigestatio.org/OBSERVATOIRES/scutigera.html&quot;&gt;Scutigera project NXI Gestatio Laboratory link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="project" /><category term="mapping" /><category term="robot" /><category term="caves" /><category term="airship" /><summary type="html">Exploration of large caves is challenging using traditional mapping tools. There are limited places to install a tripod equipped with a highly accurate Lidar (Light Detection And Ranging) and flying drones (i.e., quadrotors) in tight environments causes trouble with air disturbances produced by surrounding walls, along with their limited battery time. This project investigate the use of a semi-rigid airship (e.g., Zeppelin or blimp) to support geological observations of large underground environments.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22projects/scutigera_feature.jpg%22,%20%22teaser%22=%3E%22projects/scutigera_teaser.jpg%22,%20%22thumb%22=%3Enil,%20%22credit%22=%3E%22Radio-Canada/Soci%C3%A9t%C3%A9%20qu%C3%A9b%C3%A9coise%20de%20sp%C3%A9l%C3%A9ologie,%20Scanner%20Sombre%22%7D" /></entry><entry><title type="html">Maxime Vaidis</title><link href="https://norlab.ulaval.ca/people/m_vaidis_fr/" rel="alternate" type="text/html" title="Maxime Vaidis" /><published>2019-01-30T00:00:00-05:00</published><updated>2019-01-30T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/people/m_vaidis_fr</id><content type="html" xml:base="https://norlab.ulaval.ca/people/m_vaidis_fr/">&lt;p&gt;Maxime Vaidis est actuellement un étudiant au doctorat au laboratoire Norlab.
Il a effectué une formation en mathématiques et physique de deux ans dans les Classes Préparatoire aux Grandes Écoles de Faidherbe (Lille, France). Il possède également deux diplômes de Master, l’un en Génie éléctrique obtenu à l’UQAC (Université du Québec à Chicoutimi, Canada) et l’autre en Télécommunication et Informatique obtenu à Télécom Saint Etienne (Université Jean Monnet-Saint-Etienne, France).
Il a effectué un stage à l’université de l’UQAC au laboratoire LAIMI (Laboratoire d’Automatisme et d’Intéractions 3D Multimodales) durant lequel il a participé au développement d’une semelle intelligente et à la création d’un nouveau type d’essaim de robots et de son intéraction avec l’opérateur humain.
Il a également travaillé pour l’entreprise ConformiT à travers un contrat de recherche visant à développer un système de prévention d’accident au travail utilsant le Deep Learning.
Son travail actuel est de développer un robot pouvant scanner et cartographier des grottes en utilisant des capteurs Lidar.&lt;/p&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Diplôme de Master en Génie Éléctrique à l’UQAC (Université du Québec à Chicoutimi, Canada), 2016-2018&lt;/li&gt;
  &lt;li&gt;Diplôme de Master en Télécommunication et Informatique à Télécom Saint Etienne (Université Jean Monnet-Saint-Etienne, France), 2014-2018&lt;/li&gt;
  &lt;li&gt;Classes Préparatoire aux Grandes Écoles en Mathématiques et Physique à Faidherbe (Lille, France), 2012-2014&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;</content><author><name>Maxime Vaidis</name><email>vaidis.maxime@gmail.com</email></author><summary type="html">Maxime Vaidis est actuellement un étudiant au doctorat au laboratoire Norlab. Il a effectué une formation en mathématiques et physique de deux ans dans les Classes Préparatoire aux Grandes Écoles de Faidherbe (Lille, France). Il possède également deux diplômes de Master, l’un en Génie éléctrique obtenu à l’UQAC (Université du Québec à Chicoutimi, Canada) et l’autre en Télécommunication et Informatique obtenu à Télécom Saint Etienne (Université Jean Monnet-Saint-Etienne, France). Il a effectué un stage à l’université de l’UQAC au laboratoire LAIMI (Laboratoire d’Automatisme et d’Intéractions 3D Multimodales) durant lequel il a participé au développement d’une semelle intelligente et à la création d’un nouveau type d’essaim de robots et de son intéraction avec l’opérateur humain. Il a également travaillé pour l’entreprise ConformiT à travers un contrat de recherche visant à développer un système de prévention d’accident au travail utilsant le Deep Learning. Son travail actuel est de développer un robot pouvant scanner et cartographier des grottes en utilisant des capteurs Lidar.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/m_vaidis.jpg%22,%20%22teaser%22=%3E%22/people/m_vaidis_avatar.jpg%22%7D" /></entry><entry><title type="html">Maxime Vaidis</title><link href="https://norlab.ulaval.ca/people/m_vaidis/" rel="alternate" type="text/html" title="Maxime Vaidis" /><published>2019-01-30T00:00:00-05:00</published><updated>2019-01-30T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/people/m_vaidis</id><content type="html" xml:base="https://norlab.ulaval.ca/people/m_vaidis/">&lt;p&gt;Maxime Vaidis is currently a Ph.D student in Norlab laboratory.
He got a formation in mathematics and physics of two years in the preparatory classes for the Grandes Ecoles at Faidherbe (Lille, France) as well as two Master’s degrees, one in electrical Engineering from UQAC (University of Quebec At Chicoutimi, Canada), and an other one in Telecommunication and computer Engineering from  Telecom Saint Etienne (University of Jean Monnet-Saint-Etienne, France).
He did an internship at UQAC in LAIMI laboratory (Automatic and 3D Multimodal Intelligent Interaction Laboratory), during which he participated in the develoment of a smart insole and a creation of a new type of robot’s swarm and his interaction which a human operator.
He also worked for ConformiT compagny through a research contrat to develop a new accident-prevention system working with some Deep learning.
His current works are about to develop a robot which can map some caves with Lidar sensors.&lt;/p&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Master’s degree in electrical Engineering at UQAC (University of Quebec At Chicoutimi, Canada), 2016-2018&lt;/li&gt;
  &lt;li&gt;Master’s degree in Telecommunication and computer Engineering from  Telecom Saint Etienne (University of Jean Monnet-Saint-Etienne, France), 2014-2018&lt;/li&gt;
  &lt;li&gt;Preparatory classes for the Grandes Ecoles in Mathematics and Physics at Faidherbe (Lille, France), 2012-2014&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;</content><author><name>Maxime Vaidis</name><email>vaidis.maxime@gmail.com</email></author><summary type="html">Maxime Vaidis is currently a Ph.D student in Norlab laboratory. He got a formation in mathematics and physics of two years in the preparatory classes for the Grandes Ecoles at Faidherbe (Lille, France) as well as two Master’s degrees, one in electrical Engineering from UQAC (University of Quebec At Chicoutimi, Canada), and an other one in Telecommunication and computer Engineering from Telecom Saint Etienne (University of Jean Monnet-Saint-Etienne, France). He did an internship at UQAC in LAIMI laboratory (Automatic and 3D Multimodal Intelligent Interaction Laboratory), during which he participated in the develoment of a smart insole and a creation of a new type of robot’s swarm and his interaction which a human operator. He also worked for ConformiT compagny through a research contrat to develop a new accident-prevention system working with some Deep learning. His current works are about to develop a robot which can map some caves with Lidar sensors.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/m_vaidis.jpg%22,%20%22teaser%22=%3E%22/people/m_vaidis_avatar.jpg%22%7D" /></entry><entry><title type="html">Information for Prospective Students</title><link href="https://norlab.ulaval.ca/research/prospective-students/" rel="alternate" type="text/html" title="Information for Prospective Students" /><published>2018-11-30T00:00:00-05:00</published><updated>2018-11-30T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/research/prospective-students</id><content type="html" xml:base="https://norlab.ulaval.ca/research/prospective-students/">&lt;p&gt;Here are some information for prospective students who want to apply to a position at Norlab.
Read those information carefully before communicating with us.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For international students&lt;/strong&gt;, because of the immigration procedure and the risk of recruiting with limited information, we will only answer emails which are recommended by a professor known by the laboratory.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For Canadian students&lt;/strong&gt;, it is expected that you will ask for funding to the &lt;a href=&quot;http://www.nserc-crsng.gc.ca/Students-Etudiants/PG-CS/index_eng.asp&quot;&gt;Natural Sciences and Engineering Research Council of Canada (NSERC)&lt;/a&gt;, and students from Quebec are expected to also ask for funding to the &lt;a href=&quot;http://www.frqnt.gouv.qc.ca/en/bourses-et-subventions&quot;&gt;Fonds de recherche du Québec Nature et technologies (FRQNT)&lt;/a&gt;.
It takes typically 8 months to receive and answer from the funding agencies, so you need to plan at least a year in advance if you want to do research in our lab.
If you have a high profile, we offer support to write a strong proposal. 
Those grants are highly competitive, so you will need to work on research skills, grads, and social implications through your undergraduate studies.&lt;/p&gt;

&lt;p&gt;We try to keep an international level of research, so are expectations might be higher than anticipated.
Here is a breakdown of workload and support from Norlab for each level of researcher:&lt;/p&gt;

&lt;div class=&quot;grid&quot;&gt;
&lt;div class=&quot;three-cols&quot;&gt;
    &lt;h1 class=&quot;col-title&quot;&gt; M. Sc. &lt;/h1&gt;
    &lt;p&gt;Workload:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Minimum 2 years&lt;/li&gt;
      &lt;li&gt;Minimum 1 publication&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#suggested-lectures&quot;&gt;3-4 lectures&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Support:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Grant of $17 000 / year&lt;/li&gt;
      &lt;li&gt;Bonus of $5 000 from Norlab if you have a grant from NSERC or FRQNT&lt;/li&gt;
      &lt;li&gt;A maximum of $650 in grants for merit&lt;/li&gt;
      &lt;li&gt;Travel expenses to &lt;a href=&quot;#targeted-journals-and-conferences&quot;&gt;international conferences&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/div&gt;

&lt;div class=&quot;three-cols&quot;&gt;
    &lt;h1 class=&quot;col-title&quot;&gt; Ph. D. &lt;/h1&gt;
    &lt;p&gt;Workload:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Minimum 3 years&lt;/li&gt;
      &lt;li&gt;Minimum 3 publications&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#suggested-lectures&quot;&gt;3 lectures&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Support:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Grant of $21 000 / year&lt;/li&gt;
      &lt;li&gt;Bonus of $8 000 from Norlab if you have a grant from NSERC or FRQNT&lt;/li&gt;
      &lt;li&gt;A total of $3 500 in grants for a regular progression&lt;/li&gt;
      &lt;li&gt;A maximum of $8 500 in grants for merit (including $750 / publication and $1000 / conference)&lt;/li&gt;
      &lt;li&gt;International students receive a tuition fee exemption&lt;/li&gt;
      &lt;li&gt;Possibility of 4-8 months training &lt;a href=&quot;#our-international-network&quot;&gt;abroad&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Travel expenses to &lt;a href=&quot;#targeted-journals-and-conferences&quot;&gt;international conferences&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

  &lt;/div&gt;

&lt;div class=&quot;three-cols&quot;&gt;
    &lt;h1 class=&quot;col-title&quot;&gt; Postdoc &lt;/h1&gt;
    &lt;p&gt;Workload:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Project management&lt;/li&gt;
      &lt;li&gt;Active publications&lt;/li&gt;
      &lt;li&gt;Student supervision&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Support:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Negotiable salary&lt;/li&gt;
      &lt;li&gt;Salary includes benefits such as pension and insurances&lt;/li&gt;
      &lt;li&gt;International postdoc can ask for a provincial tax exemption&lt;/li&gt;
      &lt;li&gt;Travel expenses to &lt;a href=&quot;#targeted-journals-and-conferences&quot;&gt;international conferences&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

  &lt;/div&gt;

&lt;/div&gt;
&lt;p&gt;&lt;!-- class=&quot;grid&quot;--&gt;&lt;/p&gt;

&lt;p&gt;… and for all levels, you should&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;be self-driven, autonomous, ethical, and meticulous&lt;/li&gt;
  &lt;li&gt;develop communication skills with international standards&lt;/li&gt;
  &lt;li&gt;have an active implication in the development and maintenance of lab’s  infrastructure&lt;/li&gt;
  &lt;li&gt;support teaching activities through paid contracts, when needed&lt;/li&gt;
  &lt;li&gt;demonstrate collegiality through social activities of the lab&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This information is given as an average and the specific details will depend on the status and particularities of each candidate.&lt;/p&gt;

&lt;h1 id=&quot;suggested-lectures&quot;&gt;Suggested Lectures&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Introduction to mobile robotics (GLO-7021)&lt;/li&gt;
  &lt;li&gt;Learning through deep neural networks (GLO-7030)&lt;/li&gt;
  &lt;li&gt;Advance techniques in artificial intelligence (IFT-7025)&lt;/li&gt;
  &lt;li&gt;Numerical vision (GIF-7001)&lt;/li&gt;
  &lt;li&gt;Algorithmic photography (GIF-7105)&lt;/li&gt;
  &lt;li&gt;Elements of robotics (GMC-7046)&lt;/li&gt;
  &lt;li&gt;Active sensors (GMT-7007)&lt;/li&gt;
  &lt;li&gt;Advanced satellite positioning (GMT-7037)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;targeted-journals-and-conferences&quot;&gt;Targeted Journals and Conferences&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;International Journal of Robotics Research&lt;/li&gt;
  &lt;li&gt;Journal of Field Robotics (JFR)&lt;/li&gt;
  &lt;li&gt;Autonomous Robots&lt;/li&gt;
  &lt;li&gt;IEEE Robotics and Automation Letters (RA-L)&lt;/li&gt;
  &lt;li&gt;IEEE International Conference on Robotics and Automation (ICRA) - location rotating through North America, Europe, and Asia each year.&lt;/li&gt;
  &lt;li&gt;IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) - location rotating through North America, Europe, and Asia each year.&lt;/li&gt;
  &lt;li&gt;International Conference on Field and Service Robotics (FSR) - location rotating through North America, Europe, and Asia each year.&lt;/li&gt;
  &lt;li&gt;International Conference on Robotics: Science and Systems (RSS) - typically in the US.&lt;/li&gt;
  &lt;li&gt;Conference on Computer and Robot Vision (CRV) - typically in Canada.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;our-international-network&quot;&gt;Our International Network&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Switzerland: ETH Zurich&lt;/li&gt;
  &lt;li&gt;Hong Kong: Hong Kong University of Science and Technology&lt;/li&gt;
  &lt;li&gt;China: ShanghaiTech&lt;/li&gt;
  &lt;li&gt;England: Oxford&lt;/li&gt;
  &lt;li&gt;Australia: Queensland University of Technology’s (QUT)&lt;/li&gt;
  &lt;li&gt;Germany: University of Bonn&lt;/li&gt;
  &lt;li&gt;France: Georgia Tech Lorraine; Institut Pascal&lt;/li&gt;
  &lt;li&gt;USA: Jet Propulsion Laboratory; University of Nevada&lt;/li&gt;
  &lt;li&gt;Canada: University of Toronto; McGill&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;how-to-apply&quot;&gt;How to apply&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;Read about grant opportunities from &lt;a href=&quot;http://www.nserc-crsng.gc.ca/Students-Etudiants/PG-CS/index_eng.asp&quot;&gt;NSERC&lt;/a&gt; and &lt;a href=&quot;http://www.frqnt.gouv.qc.ca/en/bourses-et-subventions&quot;&gt;FRQNT&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Read about the &lt;a href=&quot;/research/#projects&quot;&gt;past and current projects&lt;/a&gt; to make sure that the general topic highly motivate you&lt;/li&gt;
  &lt;li&gt;Read about graduated studies on the &lt;a href=&quot;https://www.fesp.ulaval.ca/&quot;&gt;Faculty of graduated and postdoctoral studies&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Make sure that we are advertising an open position on our web site, then…&lt;/li&gt;
  &lt;li&gt;Contact us for a meeting by mentioning a specific project.&lt;/li&gt;
&lt;/ol&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="howto" /><category term="grants" /><category term="salary" /><category term="students" /><summary type="html">Here are some information for prospective students who want to apply to a position at Norlab. Read those information carefully before communicating with us.</summary></entry><entry><title type="html">Manipulation</title><link href="https://norlab.ulaval.ca/research/manipulation/" rel="alternate" type="text/html" title="Manipulation" /><published>2018-11-23T00:00:00-05:00</published><updated>2018-11-23T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/research/manipulation</id><content type="html" xml:base="https://norlab.ulaval.ca/research/manipulation/">&lt;p style=&quot;text-align: center;&quot;&gt;
	&lt;a class=&quot;btn-info&quot; href=&quot;/research/prospective-students&quot;&gt;Open position for a Ph.D. student!&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;This project is financed through &lt;a href=&quot;http://www.chistera.eu&quot;&gt;CHIST-ERA&lt;/a&gt; and is part of an international research project named &lt;em&gt;Perception-guided robust and reproducible robotic grasping and manipulation&lt;/em&gt;.
In this project, the team of researchers will address the problem of autonomous robotic grasping of objects in challenging scenes.&lt;/p&gt;

&lt;p&gt;We consider two industrially and economically important open challenges which require advanced vision-guided grasping:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;“Bin-picking” for manufacturing, where components must be grasped from a random, self-occluding heap inside a bin or box. 
Parts may have known models, but will only be partially visible in the heap and may have complex shapes. 
Shiny/reflective metal parts make 3D vision difficult, and the bin walls provide difficult reach-to-grasp and visibility constraints.&lt;/li&gt;
  &lt;li&gt;Waste materials handling, which may be hazardous (e.g., nuclear) waste, or materials for recycling in the circular economy. 
Here the robot has no prior models of object shapes, and grasped materials may also be deformable (e.g., contaminated gloves, hoses).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;More specifically, Norlab will be responsible to investigate 3D perception solutions robust to harsh environmental conditions leading to the grasping of reflective, transparent, or flexible objects.
The initial solutions will be proposed using an UR10e equipped with a flash lidar on the wrist.&lt;/p&gt;

&lt;h1 id=&quot;team&quot;&gt;Team&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Principal Investigator&lt;/strong&gt;: &lt;a href=&quot;https://robot.gmc.ulaval.ca/en/members/current-members/clement-gosselin/&quot;&gt;Clément Gosselin&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PI on Perception&lt;/strong&gt;: &lt;a href=&quot;../../people/f_pomerleau/&quot;&gt;François Pomerleau&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;International Collaborators&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Italy: &lt;a href=&quot;http://www.centropiaggio.unipi.it/~bicchi&quot;&gt;Antonio Bicchi&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;United Kingdom: &lt;a href=&quot;https://www.birmingham.ac.uk/staff/profiles/metallurgy/stolkin-rustam.aspx&quot;&gt;Rustam Stolkin&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Technical Lead&lt;/strong&gt;: TBD&lt;/li&gt;
&lt;/ul&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="project" /><category term="mapping" /><category term="robot. arm" /><category term="gripper" /><category term="flash lidar" /><summary type="html">Open position for a Ph.D. student!</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22projects/manipulation_feature.jpg%22,%20%22teaser%22=%3E%22projects/manipulation_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry></feed>