@article{Zhen,
abstract = {{\textless}p{\textgreater}Simultaneous Localization and Mapping (SLAM) has been considered as a solved
problem thanks to the progress made in the past few years. However, the great
majority of LiDAR-based SLAM algorithms are designed for a specific type of
payload and therefore don't generalize across different platforms. In practice,
this drawback causes the development, deployment and maintenance of an
algorithm difficult. Consequently, our work focuses on improving the
compatibility across different sensing payloads. Specifically, we extend the
Cartographer SLAM library to handle different types of LiDAR including fixed or
rotating, 2D or 3D LiDARs. By replacing the localization module of Cartographer
and maintaining the sparse pose graph (SPG), the proposed framework can create
high-quality 3D maps in real-time on different sensing payloads. Additionally,
it brings the benefit of simplicity with only a few parameters need to be
adjusted for each sensor type.
{\textless}/p{\textgreater}},
archivePrefix = {arXiv},
arxivId = {arXiv:1810.12515v1},
author = {Zhen, Weikun and Scherer, Sebastian},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhen, Scherer - Unknown - A Unified 3D Mapping Framework using a 3D or 2D LiDAR.pdf:pdf},
journal = {Robotics},
mendeley-groups = {Scutigera},
pages = {1--10},
title = {{A Unified 3D Mapping Framework using a 3D or 2D LiDAR.}},
project = {survey-Lidar-UAV}
}
@article{Downs2004,
abstract = {In the research reported in this paper, we propose to overcome the unavailability of Global Positioning System (GPS) using combined information obtained from a scanning LADAR rangefinder on an Unmanned Ground Vehicle (UGV) and a LADAR mounted on an Unmanned Aerial Vehicle (UAV) that flies over the terrain being traversed. The approach to estimate and update the position of the UGV involves registering range data from the two LADARs using a combination of a feature-based registration method and a modified version of the well-known Iterative Closest Point (ICP) algorithm. Registration of range data thus guarantees an estimate of the vehicle's position even when only one of the vehicles has GPS information. Additionally, such registration over time (i.e., from sample to sample), enables position information to be maintained even when both vehicles can no longer maintain GPS contact. The approach has been validated by conducting systematic experiments on complex real-world data.},
author = {Downs, A. and Madhavan, R. and Hong, T.},
doi = {10.1109/AIPR.2003.1284247},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Downs, Madhavan, Hong - 2004 - Registration of range data from unmanned aerial and ground vehicles.pdf:pdf},
isbn = {0769520294},
issn = {21642516},
journal = {Proceedings - Applied Imagery Pattern Recognition Workshop},
mendeley-groups = {Scutigera},
pages = {45--50},
title = {{Registration of range data from unmanned aerial and ground vehicles}},
volume = {2003-Janua},
year = {2004},
project = {survey-Lidar-UAV}
}
@article{Durst2011,
abstract = {Predicting ground vehicle performance requires in-depth knowledge, captured as numeric parameters, of the terrain on which the vehicles will be operating. For off-road performance, predictions are based on rough terrain ride comfort, which is described using a parameter entitled root-mean-square (RMS) surface roughness. Likewise, on-road vehicle performance depends heavily on the slopes of the individual road segments. Traditional methods of computing RMS and road slope values call for high-resolution (inch-scale) surface elevation data. At this scale, surface elevation data is both difficult and time consuming to collect. Nevertheless, a current need exists to attribute large geographic areas with RMS and road slope values in order to better support vehicle mobility predictions, and high-resolution surface data is neither available nor collectible for many of these regions. On the other hand, meter scale data can be quickly and easily collected for these areas using unmanned aerial vehicle (UAV) based IFSAR and LIDAR sensors. A statistical technique for inferring RMS values for large areas using a combination of fractal dimension and spectral analysis of five-meter elevation data is presented. Validation of the RMS prediction technique was based on 43 vehicle ride courses with 30-centimeter surface elevation data. Also presented is a model for classifying road slopes for long road sections using five-meter elevation data. The road slope model was validated against one-meter LIDAR surface elevation profiles. These inference algorithms have been successfully implemented for regions of northern Afghanistan, and some initial results are presented. {\textcopyright} 2011 SPIE.},
author = {Durst, P J and Baylot, A and McKinley, B},
doi = {10.1117/12.883510},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Durst, Baylot, McKinley - 2011 - Techniques for inferring terrain parameters related to ground vehicle mobility using UAV born IFSAR and.pdf:pdf},
isbn = {0277786X (ISSN); 9780819485946 (ISBN)},
issn = {0277786X},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
keywords = {Afghanistan,Elevation data,Forecasting,Fractal dimension,Geographic areas,Ground vehicle mobility,Ground vehicles,High resolution,IFSAR,In-depth knowledge,Inference algorithm,Inference engines,LIDAR,LIDAR data,LIDAR sensors,Landforms,Meter scale,Optical radar,Prediction techniques,Ride comforts,Road section,Road segments,Road slope,Roads and streets,Root mean squares,Rough terrains,Spectrum analysis,Statistical techniques,Support vehicles,Surface data,Surface elevation data,Surface elevations,Surface properties,Surface roughness,Surface roughness (RMS),Teaching,Terrain characterization,UAV,Unmanned aerial vehicles (UAV),Unmanned vehicles,Vehicle mobility,Vehicle performance,Vehicle ride},
mendeley-groups = {Scutigera},
number = {May 2011},
title = {{Techniques for inferring terrain parameters related to ground vehicle mobility using UAV born IFSAR and LIDAR data}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052772387{\&}partnerID=40{\&}md5=636b20dff22b6f9e5b5ec9296f3439d9},
volume = {8020},
year = {2011},
project = {survey-Lidar-UAV}
}
@article{Liu2011,
abstract = {After the operation of GPS/IMU direct geo-referencing, segmentation, filtering, classification of scattered point data and aerial triangulation on airborne LiDAR(Light Detection and Ranging) data, the accurate and high-resolution DEM of the study area in the west part of Zengcheng city, Guangdong, China was constructed. In addition, unmanned aerial vehicle (UAV) images were used for ground objects identification. Landslides occur frequently in summer in the city because of heavy rainfall. The LiDAR data (point cloud) and the mosaic images were then combined to produce the suitability distribution maps by considering Several factors, such as slope gradient, slope aspect, on-the-spot investigation data etc The maps can then be used to analyze the potential risk of landslides and assess the risk level around some buildings. The experiment results show that the method based on LiDAR data and UAV images can rapidly and accurately survey the terrain of the study area and also provides useful information for architectural design. {\textcopyright} 2011 Copyright Society of Photo-Optical Instrumentation Engineers (SPIE).},
author = {Liu, Chun and Li, Weiyue and Lei, Weigang and Liu, Lin and Wu, Hangbin},
doi = {10.1117/12.912525},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - A LiDAR and IMU integrated indoor navigation system for UAVs and its application in real-time pipeline classifi(6).pdf:pdf},
isbn = {0277786X (ISSN); 9780819489333 (ISBN)},
issn = {0277786X},
mendeley-groups = {Scutigera},
number = {October 2011},
pages = {82861Q},
title = {{Architecture planning and geo-disasters assessment mapping of landslide by using airborne lidar data and UAV images}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.912525},
year = {2011},
project = {survey-Lidar-UAV}
}
@article{Wallace2012,
abstract = {We present the development of a low-cost Unmanned Aerial Vehicle-Light Detecting and Ranging (UAV-LiDAR) system and an accompanying workflow to produce 3D point clouds. UAV systems provide an unrivalled combination of high temporal and spatial resolution datasets. The TerraLuma UAV-LiDAR system has been developed to take advantage of these properties and in doing so overcome some of the current limitations of the use of this technology within the forestry industry. A modified processing workflow including a novel trajectory determination algorithm fusing observations from a GPS receiver, an Inertial Measurement Unit (IMU) and a High Definition (HD) video camera is presented. The advantages of this workflow are demonstrated using a rigorous assessment of the spatial accuracy of the final point clouds. It is shown that due to the inclusion of video the horizontal accuracy of the final point cloud improves from 0.61 m to 0.34 m (RMS error assessed against ground control). The effect of the very high density point clouds (up to 62 points per m2) produced by the UAV-LiDAR system on the measurement of tree location, height and crown width are also assessed by performing repeat surveys over individual isolated trees. The standard deviation of tree height is shown to reduce from 0.26 m, when using data with a density of 8 points perm2, to 0.15mwhen the higher density data was used. Improvements in the uncertainty of the measurement of tree location, 0.80 m to 0.53 m, and crown width, 0.69 m to 0.61 m are also shown.},
author = {Wallace, Luke and Lucieer, Arko and Watson, Christopher and Turner, Darren},
doi = {10.3390/rs4061519},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wallace et al. - 2012 - Development of a UAV-LiDAR system with application to forest inventory.pdf:pdf},
isbn = {2072-4292},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Forestry,Kalman filter,LiDAR,MEMS IMU,Sensor integration,Unmanned aerial vehicles},
mendeley-groups = {Scutigera},
number = {6},
pages = {1519--1543},
title = {{Development of a UAV-LiDAR system with application to forest inventory}},
volume = {4},
year = {2012},
project = {survey-Lidar-UAV}
}
@article{Han2012,
abstract = {Our work presents solutions to two related vexing problems in feature-based localization of ground targets in Unmanned Aerial Vehicle (UAV) images: (i) A good initial guess at the pose estimate that would speed up the convergence to the final pose estimate for each image frame in a video sequence; and (ii)Time-bounded estimation of the position of the ground target. We address both these problems within the framework of the Iterative Closest Point (ICP) algorithm that now has a rich tradition of usage in computer vision and robotics applications. We solve the first of the two problems by frame-to-frame propagation of the computed pose estimates for the purpose of the initializations needed by ICP. The second problem is solved by terminating the iterative estimation process at the expiration of the available time for each image frame. We show that when frame-to-frame homography is factored into the iterative calculations, the accuracy of the position calculated at the time of bailing out of the iterations is nearly always sufficient for the goals of UAV vision.},
author = {Han, Kyuseo and Aeschliman, Chad and Park, Johnny and Kak, Avinash C. and Kwon, Hyukseong and Pack, Daniel J.},
doi = {10.1109/ICRA.2012.6225073},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han et al. - 2012 - UAV vision Feature based accurate ground target localization through propagated initializations and interframe homog.pdf:pdf},
isbn = {9781467314039},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
mendeley-groups = {Scutigera},
pages = {944--950},
publisher = {IEEE},
title = {{UAV vision: Feature based accurate ground target localization through propagated initializations and interframe homographies}},
year = {2012},
project = {survey-Lidar-UAV}
}
@article{Wallace2012a,
abstract = {Airborne LiDAR data has become an important tool for both the scientific and industry based investigation of forest structure. The uses of discrete return observations have now reached a maturity level such that the operational use of this data is becoming increasingly common. However, due to the cost of data collection, temporal studies into forest change are often not feasible or completed at infrequent and at uneven intervals. To achieve high resolution temporal LiDAR surveys, this study has developed a micro-Unmanned Aerial Vehicle (UAV) equipped with a discrete return 4-layer LiDAR device and miniaturised positioning sensors. This UAV has been designed to be low-cost and to achieve maximum flying time. In order to achieve these objectives and overcome the accuracy restrictions presented by miniaturised sensors a novel processing strategy based on a Kalman smoother algorithm has been developed. This strategy includes the use of the structure from motion algorithm in estimating camera orientation, which is then used to restrain IMU drift. The feasibility of such a platform for monitoring forest change is shown by demonstrating that the pointing accuracy of this UAV LiDAR device is within the accuracy requirements set out by the Australian Intergovernmental Committee on Surveying and Mapping (ICSM) standards},
author = {Wallace, L. O. and Lucieer, A. and Watson, C. S.},
doi = {10.5194/isprsarchives-XXXIX-B7-499-2012},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wallace, Lucieer, Watson - 2012 - Assessing the Feasibility of Uav-Based Lidar for High Resolution Forest Change Detection.pdf:pdf},
isbn = {15285359},
issn = {1682-1777},
journal = {ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
keywords = {change detection,forestry,lidar,unmanned aerial systems},
mendeley-groups = {Scutigera},
number = {September},
pages = {499--504},
pmid = {14563740},
title = {{Assessing the Feasibility of Uav-Based Lidar for High Resolution Forest Change Detection}},
url = {http://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XXXIX-B7/499/2012/},
volume = {XXXIX-B7},
year = {2012},
project = {survey-Lidar-UAV}
}
@article{Candigliota2012,
author = {Candigliota, E. and Immordino, F. and Moretti, L. and Indirli, Maurizio},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Candigliota et al. - 2012 - Remote sensing, laser scanner survey and GIS integrated method for assessment and preservation of historic c.pdf:pdf},
journal = {In Proceedings of the 15th World Conference on Earthquake Engineering - WCEE},
mendeley-groups = {Scutigera},
pages = {1--9},
title = {{Remote sensing, laser scanner survey and GIS integrated method for assessment and preservation of historic centers: the example of Arsita}},
year = {2012},
project = {survey-Lidar-UAV}
}
@article{Hwang2012,
author = {Hwang, Yeonha and Tahk, Min-jea},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hwang, Tahk - 2012 - Terrain Referenced UAV Navigation with Lidar – a Comparison of Sequential Processing and Batch Processing Algorit.pdf:pdf},
journal = {28th INTERNATIONAL CONGRESS OF THE AERONAUTICAL SCIENCES},
keywords = {cross-correlation matching,dsmac,extended kalman filter,sitan,tercom},
mendeley-groups = {Scutigera},
pages = {1--7},
title = {{Terrain Referenced UAV Navigation with Lidar – a Comparison of Sequential Processing and Batch Processing Algorithms}},
year = {2012},
project = {survey-Lidar-UAV}
}
@article{Zhou2013,
author = {Zhou, Guoqing and Yang, Bo and Zhang, Wuming and Tao, Xiaodong and Zhao, Wei and Yue, Tao and Zhou, Xiang and Yang, Chuntao},
doi = {10.1109/IGARSS.2013.6721208},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2013 - Simulation study of new generation of airborne scannerless LiDAR system.pdf:pdf},
isbn = {9781479911141},
journal = {International Geoscience and Remote Sensing Symposium (IGARSS)},
keywords = {Array APD LIDAR sensor,Array APD LIDAR sensor of scanning,accuracy evaluation model,civil small UAV},
mendeley-groups = {Scutigera},
number = {February 2015},
pages = {524--527},
title = {{Simulation study of new generation of airborne scannerless LiDAR system}},
year = {2013},
project = {survey-Lidar-UAV}
}
@article{Wallace2013,
abstract = {The use of Unmanned Aerial Vehicles (UAVs) as a remote sensing platform offers a unique combination of high resolution data collected within relatively low cost targeted missions. This paper investigates the use of UAV-borne Light Detecting and Ranging (LIDAR) systems (UAVL) as a platform to gain knowledge of the canopy structure within forested environments. Repeat datasets were collected with a UAVL system over six Eucalyptus Globulus plots with varying levels of canopy cover. The relative stability of four metrics for estimating canopy structure, First Cover Index (FCI), Last Cover Index (LCI), a Grid based method (GCI) and an Alpha shape based method (ACI) were assessed using these repeat datasets. It is shown that the repeatability of the GCI metric is subject to variations in plot level point density (standard deviation of 4.06 {\%}). Instabilities in the FCI (1.91 {\%}) and LCI (2.28 {\%}) metrics were found to be related to the properties of the sensor and the lasers interaction with the canopy. The ACI metric (1.86 {\%}) was found to be the most stable.},
author = {Wallace, Luke},
doi = {10.1109/IGARSS.2013.6723679},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wallace - 2013 - Assessing the stability of canopy maps produced from UAV-LiDAR data.pdf:pdf},
isbn = {9781479911141},
issn = {2153-6996},
journal = {International Geoscience and Remote Sensing Symposium (IGARSS)},
keywords = {Canopy Cover,Forestry,LiDAR,Unmanned aerial vehicles},
mendeley-groups = {Scutigera},
number = {Figure 1},
pages = {3879--3882},
publisher = {IEEE},
title = {{Assessing the stability of canopy maps produced from UAV-LiDAR data}},
year = {2013},
project = {survey-Lidar-UAV}
}
@article{Esposito2014,
abstract = {{\textcopyright} 2014 IEEE.In this work a new lightweight LiDAR solution designed for UAV application will be investigated. In particular, we show that using this multi-echo LiDAR it is possible to obtain DTM reconstruction of the densely forested area surveyed in good agreement with the local technical regional map (CTR). We have also estimated the mean height of the trees from the estimated CHM with relative error equal to 5{\%}.},
author = {Esposito, Salvatore and Mura, Matteo and Fallavollita, Paolo and Balsi, Marco and Chirici, Gherardo and Oradini, Arturo and Marchetti, Marco},
doi = {10.1109/IGARSS.2014.6946543},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Esposito et al. - 2014 - Performance evaluation of lightweight LiDAR for UAV applications.pdf:pdf},
isbn = {9781479957750},
issn = {0301-4797},
journal = {International Geoscience and Remote Sensing Symposium (IGARSS)},
keywords = {RPAS,UAV,airborne LiDAR,forestry},
mendeley-groups = {Scutigera},
pages = {792--795},
publisher = {IEEE},
title = {{Performance evaluation of lightweight LiDAR for UAV applications}},
year = {2014},
project = {survey-Lidar-UAV}
}
@article{Roca2014,
abstract = {The trend to minimize electronic devices in the last decades accounts for Unmanned Airborne Vehicles (UAVs) as well as for sensor technologies and imaging devices, resulting in a strong revolution in the surveying and mapping industries. However, only within the last few years the LIDAR sensor technology has achieved sufficiently reduction in terms of size and weight to be considered for UAV platforms. This paper presents an innovative solution to capture point cloud data from a Lidar-equipped UAV and further perform the 3D modelling of the whole envelope of buildings in BIM format. A mini-UAV platform is used (weigh less than 5 kg and up to 1.5 kg of sensor payload), and data from two different acquisition methodologies is processed and compared with the aim at finding the optimal configuration for the generation of 3D models of buildings for energy studies.},
author = {Roca, D. and Armesto, J. and Lag{\"{u}}ela, S. and D{\'{i}}az-Vilari{\~{n}}o, L.},
doi = {10.5194/isprsarchives-XL-5-523-2014},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roca et al. - 2014 - LIDAR-equipped UAV for building information modelling.pdf:pdf},
issn = {16821750},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {BIM,Buildings,GPS,Lidar,Point clouds,Uav},
mendeley-groups = {Scutigera},
number = {5},
pages = {523--527},
title = {{LIDAR-equipped UAV for building information modelling}},
volume = {40},
year = {2014},
project = {survey-Lidar-UAV}
}
@article{Wallace2014,
abstract = {Light detection and Ranging (LiDAR) is becoming an increasingly used tool to support decision-making processes within forest operations. Area-based methods that derive information on the condition of a forest based on the distribution of points within the canopy have been proven to produce reliable and consistent results. Individual tree-based methods, however, are not yet used operationally in the industry. This is due to problems in detecting and delineating individual trees under varying forest conditions resulting in an underestimation of the stem count and biases toward larger trees. The aim of this paper is to use high-resolution LiDAR data captured from a small multirotor unmanned aerial vehicle platform to determine the influence of the detection algorithm and point density on the accuracy of tree detection and delineation. The study was conducted in a four-year-old Eucalyptus globulus stand representing an important stage of growth for forest management decision-making process. Five different tree detection routines were implemented, which delineate trees directly from the point cloud, voxel space, and the canopy height model (CHM). The results suggest that both algorithm and point density are important considerations in the accuracy of the detection and delineation of individual trees. The best performing method that utilized both the CHM and the original point cloud was able to correctly detect 98{\%} of the trees in the study area. Increases in point density (from 5 to 50 {\$}hbox{\{}points/m{\}}{\^{}}{\{}2{\}}{\$}) lead to significant improvements (of up to 8{\%}) in the rate of omission for algorithms that made use of the high density of the data.},
author = {Wallace, Luke and Lucieer, Arko and Watson, Christopher S.},
doi = {10.1109/TGRS.2014.2315649},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wallace, Lucieer, Watson - 2014 - Evaluating tree detection and segmentation routines on very high resolution UAV LiDAR ata.pdf:pdf},
isbn = {0196-2892 VO - 52},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Forestry,lasers,remote sensing,remotely piloted aircraft},
mendeley-groups = {Scutigera},
number = {12},
pages = {7619--7628},
pmid = {16485148},
publisher = {IEEE},
title = {{Evaluating tree detection and segmentation routines on very high resolution UAV LiDAR ata}},
volume = {52},
year = {2014},
project = {survey-Lidar-UAV}
}
@article{Lin2014,
author = {Lin, Yi and West, Geoff},
doi = {10.1117/12.2068287},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, West - 2014 - Attempt of UAV oblique images and MLS point clouds for 4D modelling of roadside pole-like objects.pdf:pdf},
isbn = {9781628413298},
issn = {1996756X},
keywords = {4d modelling,mls,oblique imaging,pole-like object,uav},
mendeley-groups = {Scutigera},
number = {November 2014},
pages = {92620Q},
title = {{Attempt of UAV oblique images and MLS point clouds for 4D modelling of roadside pole-like objects}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2068287},
volume = {9262},
year = {2014},
project = {survey-Lidar-UAV}
}
@article{Tulldahl2014,
abstract = {Small UAV:s (Unmanned Aerial Vehicles) are currently in an explosive$\backslash$ntechnical development phase. The performance of UAV-system components$\backslash$nsuch as inertial navigation sensors, propulsion, control processors and$\backslash$nalgorithms are gradually improving. Simultaneously, lidar technologies$\backslash$nare continuously developing in terms of reliability, accuracy, as well$\backslash$nas speed of data collection, storage and processing. The lidar$\backslash$ndevelopment towards miniature systems with high data rates has, together$\backslash$nwith recent UAV development, a great potential for new three dimensional$\backslash$n(3D) mapping capabilities. Compared to lidar mapping from manned$\backslash$nfull-size aircraft a small unmanned aircraft can be cost efficient over$\backslash$nsmall areas and more flexible for deployment. An advantage with high$\backslash$nresolution lidar compared to 3D mapping from passive (multi angle)$\backslash$nphotogrammetry is the ability to penetrate through vegetation and detect$\backslash$npartially obscured targets. Another advantage is the ability to obtain$\backslash$n3D data over the whole survey area, without the limited performance of$\backslash$npassive photogrammetry in low contrast areas. The purpose of our work is$\backslash$nto demonstrate 3D lidar mapping capability from a small multirotor UAV.$\backslash$nWe present the first experimental results and the mechanical and$\backslash$nelectrical integration of the Velodyne HDL-32E lidar on a six-rotor$\backslash$naircraft with a total weight of 7 kg. The rotating lidar is mounted at$\backslash$nan angle of 20 degrees from the horizontal plane giving a vertical$\backslash$nfield-of-view of 10-50 degrees below the horizon in the aircraft forward$\backslash$ndirections. For absolute positioning of the 3D data, accurate$\backslash$npositioning and orientation of the lidar sensor is of high importance.$\backslash$nWe evaluate the lidar data position accuracy both based on inertial$\backslash$nnavigation system (INS) data, and on INS data combined with lidar data.$\backslash$nThe INS sensors consist of accelerometers, gyroscopes, GPS,$\backslash$nmagnetometers, and a pressure sensor for altimetry. The lidar range$\backslash$nresolution and accuracy is documented as well as the capability for$\backslash$ntarget surface reflectivity estimation based on measurements on$\backslash$ncalibration standards. Initial results of the general mapping capability$\backslash$nincluding the detection through partly obscured environments is$\backslash$ndemonstrated through field data collection and analysis.},
author = {Tulldahl, H. Michael and Larsson, H{\aa}kan},
doi = {10.1117/12.2068448},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tulldahl, Larsson - 2014 - Lidar on small UAV for 3D mapping.pdf:pdf},
isbn = {978-1-62841-313-7},
issn = {0277-786X},
mendeley-groups = {Scutigera},
number = {October 2014},
pages = {925009},
pmid = {21314686},
title = {{Lidar on small UAV for 3D mapping}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2068448},
volume = {925009},
year = {2014},
project = {survey-Lidar-UAV}
}
@article{Lawson2015,
abstract = {This report aims to demonstrate the feasibility of building a global 3-D map from multiple UAV robots in a GPS-denied, indoor environment. Presented are the design of each robot and the reasoning behind choosing its hardware and software components, the process in which a single robot obtains a individual 3-D map entirely onboard, and lastly how the mapping concept is extended to multiple robotic agents to form a global 3-D map using a centralized server. In the latter section, this report focuses on two algorithms, Online Mapping and Map Fusion, developed to facilitate the cooperative approach. A limited selection of experiments and test results are also presented to demonstrate application of these algorithms in a real-world setting},
author = {Lawson, Andrew},
journal = {University Scholar Projects},
mendeley-groups = {Scutigera},
title = {{Cooperative 3-D Map Generation Using Multiple UAVs}},
year = {2015},
project = {survey-Lidar-UAV}
}
@article{Yang2015,
abstract = {Use of direct geo-referencing data leads to registration failure between sequent images and LiDAR data captured by mini-UAV platforms because of low-cost sensors. This paper therefore proposes a novel automatic registration method for sequent images and LiDAR data captured by mini-UAVs. First, the proposed method extracts building outlines from LiDAR data and images and estimates the exterior orientation parameters (EoPs) of the images with building objects in the LiDAR data coordinate framework based on corresponding corner points derived indirectly by using linear features. Second, the EoPs of the sequent images in the image coordinate framework are recovered using a structure from motion (SfM) technique, and the transformation matrices between the LiDAR coordinate and image coordinate frameworks are calculated using corresponding EoPs, resulting in a coarse registration between the images and the LiDAR data. Finally, 3D points are generated from sequent images by multi-view stereo (MVS) algorithms. Then the EoPs of the sequent images are further refined by registering the LiDAR data and the 3D points using an iterative closest-point (ICP) algorithm with the initial results from coarse registration, resulting in a fine registration between sequent images and LiDAR data. Experiments were performed to check the validity and effectiveness of the proposed method. The results show that the proposed method achieves high-precision robust co-registration of sequent images and LiDAR data captured by mini-UAVs.},
author = {Yang, Bisheng and Chen, Chi},
doi = {10.1016/j.isprsjprs.2014.12.025},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - A LiDAR and IMU integrated indoor navigation system for UAVs and its application in real-time pipeline classificat.pdf:pdf},
isbn = {0924-2716},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {LiDAR data,Linear features,Multi-view stereo,Registration,Sequent images,Unmanned aerial vehicles mapping},
mendeley-groups = {Scutigera},
pages = {262--274},
publisher = {International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)},
title = {{Automatic registration of UAV-borne sequent images and LiDAR data}},
url = {http://dx.doi.org/10.1016/j.isprsjprs.2014.12.025},
volume = {101},
year = {2015},
project = {survey-Lidar-UAV}
}
@article{Ni2015,
abstract = {{\textcopyright} 2015 IEEE.Forest spatial structure is essential for researches on forest ecosystem dynamics. Considering that the field measurement of forest structures over large field plot is labor-intensive and time-consuming, a forest inventory system is developed based on unmanned aerial vehicle (UAV). This study presented the initial evaluation of this system by comparisons with LiDAR data. Results showed that most trees appeared in LiDAR canopy height model (CHM) could also be detected in UAV CHM. The UAV system could measure forest height at plot level with R2=0.87 and RMSE=1.9 m taking CHM from LiDAR as reference data.},
author = {Ni, Wenjian and Liu, Jianli and Zhang, Zhiyu and Sun, Guoqing and Yang, Aqiang},
doi = {10.1109/IGARSS.2015.7326670},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ni et al. - 2015 - Evaluation of UAV-based forest inventory system compared with LiDAR data.pdf:pdf},
isbn = {9781479979295},
issn = {2153-6996},
journal = {International Geoscience and Remote Sensing Symposium (IGARSS)},
keywords = {UAV,computer vision,forest biomass,forest structures,photogrammetry,stereo image},
mendeley-groups = {Scutigera},
pages = {3874--3877},
publisher = {IEEE},
title = {{Evaluation of UAV-based forest inventory system compared with LiDAR data}},
volume = {2015-Novem},
year = {2015},
project = {survey-Lidar-UAV}
}
@article{Pan2015,
abstract = {{\textless}p{\textgreater}This paper introduces a compact LIDAR system designed to inspect overhead transmission line for maintenance purposes. This LIDAR system is carried by a small unmanned helium airship, which is guided by GPS and laser ranging to fly automatically along the power-line over a limited distance. The 3D coordinates of the power line, power tower and power line channel features are gathered by LIDAR. Test have been accomplished using this blimp-based compact LIDAR power-line inspection system. Its inspections of a 500kV power lines also shows the high efficient inspection, less risk to personnel and more inspections per day compared with manual inspection.{\textless}/p{\textgreater}},
author = {Pan, W. W. and Dou, Y. J. and Wang, G. L. and Wu, M. X. and Ren, R. G. and Xu, X.},
doi = {10.5194/isprsarchives-XL-3-W2-155-2015},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pan et al. - 2015 - Development and test of blimp-based compact LIDAR power-line inspection system.pdf:pdf},
issn = {16821750},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {Compact LIDAR,Flight along power-line,Safety hazards analysis,Transmission line inspection,Unmanned blimps},
mendeley-groups = {Scutigera},
number = {3W2},
pages = {155--159},
title = {{Development and test of blimp-based compact LIDAR powewr-line inspection system}},
volume = {40},
year = {2015},
project = {survey-Lidar-UAV}
}
@article{Li2015,
abstract = {{\textless}p{\textgreater}In the discovering, identifying and mapping work of heritage objects in forest or desert areas, LiDAR ensures work efficiency and can provide the most complete and accurate 3D data. In the field of heritage documentation in China, the integration of LiDAR and small UAV is highly desirable. However, due to issues on the vibration of flying platform, load capacity, safety and other factors, not all UAVs can be used as LiDAR carriers. Therefore, the selection and design of suitable UAVs are very important. Little research has been done in this area and related experiments, complete test data and clear conclusions are hard to find. After long-term selection, design, trial-manufacturing and testing, the authors compare the vibration, capacity, reliability, stability of many UAV types, and finally develop two UAV platforms which are most suitable for carrying LiDAR for heritage mapping projects.{\textless}/p{\textgreater}},
author = {Li, Zhe and Yan, Yu and Jing, Yabing and Zhao, Shu Guang},
doi = {10.5194/isprsarchives-XL-1-W4-17-2015},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2015 - The design and testing of a LiDAR platform for a UAV for heritage mapping.pdf:pdf},
issn = {16821750},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {Architectural relics,Laser scanning,LiDAR,VTOL aircraft,Vibration interference},
mendeley-groups = {Scutigera},
number = {1W4},
pages = {17--24},
title = {{The design and testing of a LiDAR platform for a UAV for heritage mapping}},
volume = {40},
year = {2015},
project = {survey-Lidar-UAV}
}
@article{Yousif2015,
abstract = {This paper is intended to pave the way for new researchers in the field of robotics and autonomous systems, particularly thosewho are interested in robot localization and mapping. We discuss the fundamentals of robot navigation requirements and provide a reviewof the state of the art tech- niques that form the bases of established solutions formobile robots localization and mapping. The topicswediscuss range from basic localization techniques such as wheel odometry and dead reckoning, to the more advance Visual Odometry (VO) and Simultaneous Localization and Mapping (SLAM) techniques. We discuss VO in both monocular and stereo vision systems using feature matching/tracking and optical flow techniques.We discuss and compare the basics of most common SLAM methods such as the Extended Kalman Fil- ter SLAM (EKF-SLAM), Particle Filter and the most recent RGB-D SLAM. We also provide techniques that form the building blocks to those methods such as feature extraction (i.e. SIFT, SURF, FAST), feature matching, outlier removal and data association techniques.},
author = {Yousif, Khalid and Bab-Hadiashar, Alireza and Hoseinnezhad, Reza},
doi = {10.1007/s40903-015-0032-7},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yousif, Bab-Hadiashar, Hoseinnezhad - 2015 - An Overview to Visual Odometry and Visual SLAM Applications to Mobile Robotics.pdf:pdf},
isbn = {2199-854X},
issn = {2363-6912},
journal = {Intelligent Industrial Systems},
mendeley-groups = {Scutigera},
number = {4},
pages = {289--311},
pmid = {28536934},
title = {{An Overview to Visual Odometry and Visual SLAM: Applications to Mobile Robotics}},
url = {http://link.springer.com/10.1007/s40903-015-0032-7},
volume = {1},
year = {2015},
project = {survey-Lidar-UAV}
}
@article{Gu2015,
abstract = {In order to realize the autonomous location and attitude estimation for speedy UAV, this paper designs an improved Iterative Closest Points (ICP) algorithm for fixed-wing UAV with a laser range finder mounted onboard. This improved ICP adopts a K-d tree and AK-d tree mixed closest point searching strategy to enhance its rapidity, and an automatic trim approach to drop out outlier points to improve its reliability. In order to check the feasibility of the proposed algorithm, flight experiment is conducted. Experiment result demonstrates the good performance of the algorithm.},
author = {Gu, Tianyuan and Zhang, Ning},
doi = {10.1109/CGNCC.2014.7007407},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gu, Zhang - 2015 - Application of iterative closest point algorithm in automatic flight of speedy UAV.pdf:pdf},
isbn = {9781479946990},
journal = {2014 IEEE Chinese Guidance, Navigation and Control Conference, CGNCC 2014},
mendeley-groups = {Scutigera},
pages = {1456--1459},
publisher = {IEEE},
title = {{Application of iterative closest point algorithm in automatic flight of speedy UAV}},
year = {2015},
project = {survey-Lidar-UAV}
}
@article{Mandlburger2015,
abstract = {In this paper we report on a flight experiment employing airborne laser bathymetry (ALB) and unmanned aerial vehicle (UAV) based laser scanning (ULS) for capturing very high resolution topography of shallow water areas and the surrounding littoral zone at the pre-alpine Pielach River in Austria. The aim of the research is to assess how information gained from non-bathymetric, ultra-high resolution ULS can support the ALB data. We focus first on the characterization of the water surface of a lowland river and provide validation results using the data of a topographic airborne laser scanning (ALS) sensor and a low flying ULS system. By repeat ULS survey of a the meandering river reach we are able to quantify short-term water level changes due to surface waves in high resolution. Based on a hydrodynamic-numerical (HN) model we assess the accuracy of the water surface derived from a water penetrating ALB sensor. In the second part of the paper we investigate the ability of ALB, ALS, and ULS to describe the complex topography and vegetation structure of the alluvial area. This is carried out by comparing the Digital Terrain Models (DTM) derived from different sensor configurations. Finally we demonstrate the potential of ULS for estimating single tree positions and stem diameters for detailed floodplain roughness characterization in HN simulations. The key findings are: (i) NIR scan data from ALS or ULS provide more precise water level height estimates (no bias, 1$\sigma$: 2 cm) compared to ALB (bias: 3 cm, 1$\sigma$: 4 cm), (ii) within the studied reach short-term water level dynamics irrelevant for ALB data acquisition considering a 60 cm footprint diameter, and (iii) stem diameters can be estimated based on ULS point clouds but not from ALS and ALB.},
author = {Mandlburger, Gottfried and Pfennigbauer, Martin and Riegl, Ursula and Haring, Alexander and Wieser, Martin and Glira, Philipp and Winiwarter, Lukas},
doi = {10.1117/12.2194779},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mandlburger et al. - 2015 - Complementing airborne laser bathymetry with UAV-based lidar for capturing alluvial landscapes.pdf:pdf},
isbn = {9781628418477},
issn = {1996756X},
mendeley-groups = {Scutigera},
number = {October 2015},
pages = {96370A},
pmid = {15499497},
title = {{Complementing airborne laser bathymetry with UAV-based lidar for capturing alluvial landscapes}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2194779},
year = {2015},
project = {survey-Lidar-UAV}
}
@article{Tulldahl2015,
abstract = {A UAV (Unmanned Aerial Vehicle) with an integrated lidar can be an efficient system for collection of high-resolution
and accurate three-dimensional (3D) data. In this paper we evaluate the accuracy of a system consisting of a lidar sensor
on a small UAV. High geometric accuracy in the produced point cloud is a fundamental qualification for detection and
recognition of objects in a single-flight dataset as well as for change detection using two or several data collections over
the same scene. Our work presented here has two purposes: first to relate the point cloud accuracy to data processing
parameters and second, to examine the influence on accuracy from the UAV platform parameters. In our work, the
accuracy is numerically quantified as local surface smoothness on planar surfaces, and as distance and relative height
accuracy using data from a terrestrial laser scanner as reference. The UAV lidar system used is the Velodyne HDL-32E
lidar on a multirotor UAV with a total weight of 7 kg. For processing of data into a geographically referenced point
cloud, positioning and orientation of the lidar sensor is based on inertial navigation system (INS) data combined with
lidar data. The combination of INS and lidar data is achieved in a dynamic calibration process that minimizes the
navigation errors in six degrees of freedom, namely the errors of the absolute position (x, y, z) and the orientation (pitch,
roll, yaw) measured by GPS/INS. Our results show that low-cost and light-weight MEMS based
(microelectromechanical systems) INS equipment with a dynamic calibration process can obtain significantly improved
accuracy compared to processing based solely on INS data.},
author = {Tulldahl, H. M. and Bissmarck, Fredrik and Larsson, H{\aa}kan and Gr{\"{o}}nwall, Christina and Tolt, Gustav},
doi = {10.1117/12.2194508},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tulldahl et al. - 2015 - Accuracy evaluation of 3D lidar data from small UAV.pdf:pdf},
isbn = {9781628418590},
issn = {1996756X},
keywords = {3d imaging,accuracy,dynamic calibration,lidar,point clouds,pre-processing,see-through media,uav},
mendeley-groups = {Scutigera},
number = {October 2015},
pages = {964903},
title = {{Accuracy evaluation of 3D lidar data from small UAV}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2194508},
volume = {964903},
year = {2015},
project = {survey-Lidar-UAV}
}
@article{Petras2016,
abstract = {Today's methods of acquiring Earth surface data, namely lidar and unmanned aerial vehicle (UAV) imagery, non-selectively collect or generate large amounts of points. Point clouds from different sources vary in their properties such as number of returns, density, or quality. We present a set of tools with applications for different types of points clouds obtained by a lidar scanner, structure from motion technique (SfM), and a low-cost 3D scanner. To take advantage of the vertical structure of multiple return lidar point clouds, we demonstrate tools to process them using 3D raster techniques which allow, for example, the development of custom vegetation classification methods. Dense point clouds obtained from UAV imagery, often containing redundant points, can be decimated using various techniques before further processing. We implemented and compared several decimation techniques in regard to their performance and the final digital surface model (DSM). Finally, we will describe the processing of a point cloud from a low-cost 3D scanner, namely Microsoft Kinect, and its application for interaction with physical models. All the presented tools are open source and integrated in GRASS GIS, a multi-purpose open source GIS with remote sensing capabilities. The tools integrate with other open source projects, specifically Point Data Abstraction Library (PDAL), Point Cloud Library (PCL), and OpenKinect libfreenect2 library to benefit from the open source point cloud ecosystem. The implementation in GRASS GIS ensures long term maintenance and reproducibility by the scientific community but also by the original authors themselves.},
author = {Petras, V. and Petrasova, A. and Jeziorska, J. and Mitasova, H.},
doi = {10.5194/isprsarchives-XLI-B7-945-2016},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petras et al. - 2016 - Processing UAV and LiDAR point clouds in grass GIS.pdf:pdf},
isbn = {0924-2716},
issn = {16821750},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {3D rasters,Binning,Decimation,Kinect,LAS,PCL,PDAL,Sampling},
mendeley-groups = {Scutigera},
number = {July},
pages = {945--952},
title = {{Processing UAV and LiDAR point clouds in grass GIS}},
volume = {41},
year = {2016},
project = {survey-Lidar-UAV}
}
@article{Reiss2016,
abstract = {The Jesuit Missions the Guaranis were one of the great examples of cultural, social, and scientific of the eighteenth century, which had its decline from successive wars that followed the exchange of territories domain occupied by Portugal and Spain with the Madrid Treaty of January 13, 1750. One of the great examples of this development is materialized in the ruins of 30 churches and villages that remain in a territory that now comprises part of Brazil, Argentina and Paraguay. These Churches, S{\~{a}}o Miguel das Miss{\~{o}}es is among the Brazilian ruins, the best preserved. The ruins of S{\~{a}}o Miguel das Miss{\~{o}}es were declared a UNESCO World Cultural Heritage in 1983 and the Institute of National Historical Heritage (IPHAN) is the Brazilian Federal agency that manages and maintains this heritage. In order to produce a geographic database to assist the IPHAN in the management of the Ruins of S{\~{a}}o Miguel das Miss{\~{o}}es it was proposed a three-dimensional mapping of these ruins never performed in this location before. The proposal is integrated data acquired from multiple sensors: Two micro-UAV, an Asctec Falcon 8 (rotary wing) and a Sensefly e-Bee (fixed wing); photos from terrestrial cameras; two terrestrial LIDAR sensors, one Faro Focus 3D S-120 and Optec 3D-HD ILRIS. With this abundance of sensors has been possible to perform comparisons and integration of the acquired data, and produce a 3D reconstruction of the church with high completeness and accuracy (better than 25 mm), as can be seen in the presentation of this work.},
author = {Reiss, M. L.L. and {Da Rocha}, R. S. and Ferraz, R. S. and Cruz, V. C. and Morador, L. Q. and Yamawaki, M. K. and Rodrigues, E. L.S. and Cole, J. O. and Mezzomo, W.},
doi = {10.5194/isprsarchives-XLI-B5-315-2016},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reiss et al. - 2016 - Data integration acquired from micro-UAV and terrestrial laser scanner for the 3D mapping of jesuit ruins of s{\~{a}}o.pdf:pdf},
isbn = {16821750 (ISSN)},
issn = {16821750},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {Cultural heritage,Fixed and rotary wings,Micro-UAV,Photogrammetry,Terrestrial lidar},
mendeley-groups = {Scutigera},
number = {July},
pages = {315--321},
title = {{Data integration acquired from micro-UAV and terrestrial laser scanner for the 3D mapping of jesuit ruins of s{\~{a}}o miguel das miss{\~{o}}es}},
volume = {41},
year = {2016},
project = {survey-Lidar-UAV}
}
@article{Kasturi2016,
abstract = {Firstly, we demonstrated a wirelessly controlled MEMS scan module with imaging and laser tracking capability which can be mounted and flown on a small UAV quadcopter. The MEMS scan module was reduced down to a small volume of {\textless}90mm x 60mm x 40mm, weighing less than 40g and consuming less than 750mW of power using a {\~{}}5mW laser. This MEMS scan module was controlled by a smartphone via Bluetooth while flying on a drone, and could project vector content, text, and perform laser based tracking. Also, a “point-and-range” LiDAR module was developed for UAV applications based on low SWaP (Size, Weight and Power) gimbal-less MEMS mirror beam-steering technology and off-the-shelf OEM LRF modules. For demonstration purposes of an integrated laser range finder module, we used a simple off-the-shelf OEM laser range finder (LRF) with a 100m range, +/-1.5mm accuracy, and 4Hz ranging capability. The LRFs receiver optics were modified to accept 20{\&}deg; of angle, matching the transmitter‟s FoR. A relatively large (5.0mm) diameter MEMS mirror with +/-10{\&}deg; optical scanning angle was utilized in the demonstration to maintain the small beam divergence of the module. The complete LiDAR prototype can fit into a small volume of {\textless}70mm x 60mm x 60mm, and weigh {\textless}50g when powered by the UAV‟s battery. The MEMS mirror based LiDAR system allows for ondemand ranging of points or areas within the FoR without altering the UAV‟s position. Increasing the LRF ranging frequency and stabilizing the pointing of the laser beam by utilizing the onboard inertial sensors and the camera are additional goals of the next design.},
author = {Kasturi, Abhishek and Milanovic, Veljko and Atwood, Bryan H. and Yang, James},
doi = {10.1117/12.2224285},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kasturi et al. - 2016 - UAV-borne lidar with MEMS mirror-based scanning capability.pdf:pdf},
isbn = {9781510600737},
issn = {1996756X},
keywords = {drone,laser imaging,laser range finder,laser tracking,lidar,mems mirrors,uav},
mendeley-groups = {Scutigera},
number = {May 2016},
pages = {98320M},
pmid = {25004709},
title = {{UAV-borne lidar with MEMS mirror-based scanning capability}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2224285},
year = {2016},
project = {survey-Lidar-UAV}
}
@article{Morsdorf2017,
abstract = {Laser scanning of forested areas helps in analyzing and understanding various aspects of forest conditions, including distribution of plants and trees, height distribution of trees, tree density, size and volume of wood, as well as ground surface properties. However, laser scanning of forest areas is also very challenging for many reasons. The best time for scanning is before trees leaf out in the spring or after trees cast their leaves in autumn before snowfall so an unmanned aerial vehicle (UAV) laser scanner can penetrate the forest from the tops of the trees down to the ground surface. To receive highly accurate laser data and high point density, the flight planning must be adjusted judiciously. Flight planning will be even more complex in steep terrain where the UAV cannot operate at a constant altitude. This paper discusses a UAV-based 3D laser data recording - light detection and ranging (LiDAR) scanning - of a forestry area with high accuracy and point cloud resolution. In addition, the point cloud of airborne laser scanning is compared with local terrestrial laser-scanning results. The forest area consists of mixed forests containing varying tree sizes and branch deformation. This paper summarizes our latest results in UAV-based LiDAR acquisition over a forest area to extract detailed forest and ground information and finds that UAV-based laser scanning is well suited for provision of both high-quality forest structural and terrain elevation information.},
author = {Morsdorf, Felix and Eck, Christoph and Zgraggen, Carlo and Imbach, Benedikt and Schneider, Fabian D. and K{\"{u}}kenbrink, Daniel},
doi = {10.1190/tle36070566.1},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Morsdorf et al. - 2017 - UAV-based LiDAR acquisition for the derivation of high-resolution forest and ground information.pdf:pdf},
issn = {1070-485X},
journal = {The Leading Edge},
mendeley-groups = {Scutigera},
number = {7},
pages = {566--570},
title = {{UAV-based LiDAR acquisition for the derivation of high-resolution forest and ground information}},
url = {http://library.seg.org/doi/10.1190/tle36070566.1},
volume = {36},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Gawel2017,
abstract = {Global registration of heterogeneous ground and aerial mapping data is a challenging task. This is especially difficult in disaster response scenarios when we have no prior information on the environment and cannot assume the regular order of man-made environments or meaningful semantic cues. In this work we extensively evaluate different approaches to globally register UGV generated 3D point-cloud data from LiDAR sensors with UAV generated point-cloud maps from vision sensors. The approaches are realizations of different selections for: a) local features: key-points or segments; b) descriptors: FPFH, SHOT, or ESF; and c) transformation estimations: RANSAC or FGR. Additionally, we compare the results against standard approaches like applying ICP after a good prior transformation has been given. The evaluation criteria include the distance which a UGV needs to travel to successfully localize, the registration error, and the computational cost. In this context, we report our findings on effectively performing the task on two new Search and Rescue datasets. Our results have the potential to help the community take informed decisions when registering point-cloud maps from ground robots to those from aerial robots.},
archivePrefix = {arXiv},
arxivId = {1709.00587},
author = {Gawel, Abel and Dube, Renaud and Surmann, Hartmut and Nieto, Juan and Siegwart, Roland and Cadena, Cesar},
doi = {10.1109/SSRR.2017.8088136},
eprint = {1709.00587},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gawel et al. - 2017 - 3D registration of aerial and ground robots for disaster response An evaluation of features, descriptors, and tran.pdf:pdf},
isbn = {9781538639221},
issn = {00121797},
journal = {SSRR 2017 - 15th IEEE International Symposium on Safety, Security and Rescue Robotics, Conference},
mendeley-groups = {Scutigera},
pages = {27--34},
pmid = {3056761},
title = {{3D registration of aerial and ground robots for disaster response: An evaluation of features, descriptors, and transformation estimation}},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Gasparovic2017,
abstract = {{\textcopyright} 2017 by the Croatian Forest Research Institute. Background and Purpose: Unmanned aerial vehicles (UAVs) are flexible to solve various surveying tasks which make them useful in many disciplines, including forestry. The main goal of this research is to evaluate the quality of photogrammetrybased digital surface model (DSM) from low-cost UAV's images collected in non-optimal weather (windy and cloudy weather) and environmental (inaccessibility for regular spatial distribution of ground control points - GCPs) conditions. Materials and Methods: The UAV-based DSMs without (DSM P ) and with using GCPs (DSM P-GCP ) were generated. The vertical agreement assessment of the UAV-based DSMs was conducted by comparing elevations of 60 checkpoints of a regular 100 m sampling grid obtained from LiDAR-based DSM (DSM L ) with the elevations of planimetrically corresponding points obtained from DSM P and DSM P-GCP . Due to the non-normal distribution of residuals (vertical differences between UAV- and LiDAR-based DSMs), a vertical agreement was assessed by using robust measures: median, normalised median absolute deviation (NMAD), 68.3{\%} quantile and 95{\%} quantile. Results: As expected, DSM P-GCP shows higher accuracy, i.e. higher vertical agreement with DSM L than DSM P . The median, NMAD, 68.3{\%} quantile, 95{\%} quantile and RMSE* (without outliers) values for DSM P are 2.23 m, 3.22 m, 4.34 m, 15.04 m and 5.10 m, respectively, whereas for DSM P-GCP amount to -1.33 m, 2.77 m, 0.11 m, 8.15 m and 3.54 m, respectively. Conclusions: The obtained results confirmed great potential of images obtained by low-cost UAV for forestry applications, even if they are surveyed in non-optimal weather and environmental conditions. This could be of importance for cases when urgent UAV surveys are needed (e.g. detection and estimation of forest damage) which do not allow careful and longer survey planning. The vertical agreement assessment of UAV-based DSMs with LiDAR-based DSM confirmed the importance of GCPs for image orientation and DSM generation. Namely, a considerable improvement in vertical accuracy of UAV-based DSMs was observed when GCPs were used.},
author = {Ga{\v{s}}parovi{\'{c}}, Mateo and Seletkovi{\'{c}}, Ante and Berta, Alen and Balenovi{\'{c}}, Ivan},
doi = {10.15177/seefor.17-16},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ga{\v{s}}parovi{\'{c}} et al. - 2017 - The Evaluation of Photogrammetry-Based DSM from Low-Cost UAV by LiDAR-Based DSM.pdf:pdf},
issn = {18476481},
journal = {South-east European forestry},
mendeley-groups = {Scutigera},
number = {2},
title = {{The Evaluation of Photogrammetry-Based DSM from Low-Cost UAV by LiDAR-Based DSM}},
url = {https://www.seefor.eu/vol-8-no-2-gasparovic-et-al-the-evaluation-of-photogrammetry.html},
volume = {8},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Christiansen2017,
abstract = {A Light Detection and Ranging (LiDAR) sensor mounted on an Unmanned Aerial Vehicle (UAV) can map the overflown environment in point clouds. Mapped canopy heights allow for the estimation of crop biomass in agriculture. The work presented in this paper contributes to sensory UAV setup design for mapping and textual analysis of agricultural fields. LiDAR data are combined with data from Global Navigation Satellite System (GNSS) and Inertial Measurement Unit (IMU) sensors to conduct environment mapping for point clouds. The proposed method facilitates LiDAR recordings in an experimental winter wheat field. Crop height estimates ranging from 0.35–0.58 m are correlated to the applied nitrogen treatments of 0–300     kg  N ha     . The LiDAR point clouds are recorded, mapped, and analysed using the functionalities of the Robot Operating System (ROS) and the Point Cloud Library (PCL). Crop volume estimation is based on a voxel grid with a spatial resolution of 0.04 × 0.04 × 0.001 m. Two different flight patterns are evaluated at an altitude of 6 m to determine the impacts of the mapped LiDAR measurements on crop volume estimations.},
author = {Christiansen, Martin Peter and Laursen, Morten Stigaard and J{\o}rgensen, Rasmus Nyholm and Skovsen, S{\o}ren and Gislum, Ren{\'{e}}},
doi = {10.3390/s17122703},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Christiansen et al. - 2017 - Designing and testing a UAV mapping system for agricultural field surveying.pdf:pdf},
isbn = {1424-8220},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Aerial robotics,Canopy estimation,Crop monitoring,Point cloud,Winter wheat mapping},
mendeley-groups = {Scutigera},
number = {12},
pages = {1--19},
pmid = {29168783},
title = {{Designing and testing a UAV mapping system for agricultural field surveying}},
volume = {17},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{AjayKumar2017,
abstract = {Mapping the environment of a vehicle and localizing a vehicle within that unknown environment are complex issues. Although many approaches based on various types of sensory inputs and computational concepts have been successfully utilized for ground robot localization, there is difficulty in localizing an unmanned aerial vehicle (UAV) due to variation in altitude and motion dynamics. This paper proposes a robust and efficient indoor mapping and localization solution for a UAV integrated with low-cost Light Detection and Ranging (LiDAR) and Inertial Measurement Unit (IMU) sensors. Considering the advantage of the typical geometric structure of indoor environments, the planar position of UAVs can be efficiently calculated from a point-to-point scan matching algorithm using measurements from a horizontally scanning primary LiDAR. The altitude of the UAV with respect to the floor can be estimated accurately using a vertically scanning secondary LiDAR scanner, which is mounted orthogonally to the primary LiDAR. Furthermore, a Kalman filter is used to derive the 3D position by fusing primary and secondary LiDAR data. Additionally, this work presents a novel method for its application in the real-time classification of a pipeline in an indoor map by integrating the proposed navigation approach. Classification of the pipeline is based on the pipe radius estimation considering the region of interest (ROI) and the typical angle. The ROI is selected by finding the nearest neighbors of the selected seed point in the pipeline point cloud, and the typical angle is estimated with the directional histogram. Experimental results are provided to determine the feasibility of the proposed navigation system and its integration with real-time application in industrial plant engineering.},
author = {{Ajay Kumar}, G. and Patil, Ashok Kumar and Patil, Rekha and Park, Seong Sill and Chai, Young Ho},
doi = {10.3390/s17061268},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ajay Kumar et al. - 2017 - A LiDAR and IMU integrated indoor navigation system for UAVs and its application in real-time pipeline classi.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {3D model reconstruction,Classification,Indoor UAV tracking,Indoor mapping,Indoor navigation,Pipeline,Scan matching},
mendeley-groups = {Scutigera},
number = {6},
pmid = {28574474},
title = {{A LiDAR and IMU integrated indoor navigation system for UAVs and its application in real-time pipeline classification}},
volume = {17},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Sankey2017,
abstract = {Forest vegetation classification and structure measurements are fundamental steps for planning, monitoring, and evaluating large-scale forest changes including restoration treatments. High spatial and spectral resolution remote sensing data are critically needed to classify vegetation and measure their 3-dimensional (3D) canopy structure at the level of individual species. Here we test high-resolution lidar, hyperspectral, and multispectral data collected from unmanned aerial vehicles (UAV) and demonstrate a lidar-hyperspectral image fusion method in treated and control forests with varying tree density and canopy cover as well as in an ecotone environment to represent a gradient of vegetation and topography in northern Arizona, U.S.A. The fusion performs better (88{\%} overall accuracy) than either data type alone, particularly for species with similar spectral signatures, but different canopy sizes. The lidar data provides estimates of individual tree height (R2 = 0.90; RMSE = 2.3 m) and crown diameter (R2 = 0.72; RMSE = 0.71 m) as well as total tree canopy cover (R2 = 0.87; RMSE = 9.5{\%}) and tree density (R2 = 0.77; RMSE = 0.69 trees/cell) in 10 m cells across thin only, burn only, thin-and-burn, and control treatments, where tree cover and density ranged between 22 and 50{\%} and 1–3.5 trees/cell, respectively. The lidar data also produces highly accurate digital elevation model (DEM) (R2 = 0.92; RMSE = 0.75 m). In comparison, 3D data derived from the multispectral data via structure-from-motion produced lower correlations with field-measured variables, especially in dense and structurally complex forests. The lidar, hyperspectral, and multispectral sensors, and the methods demonstrated here can be widely applied across a gradient of vegetation and topography for monitoring landscapes undergoing large-scale changes such as the forests in the southwestern U.S.A.},
author = {Sankey, Temuulen and Donager, Jonathon and McVay, Jason and Sankey, Joel B.},
doi = {10.1016/j.rse.2017.04.007},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sankey et al. - 2017 - UAV lidar and hyperspectral fusion for forest monitoring in the southwestern USA.pdf:pdf},
isbn = {0034-4257},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {3D modelling,Airborne data,Crown diameter,DEM,Drone,Structure from motion (SFM),Tree delineation,UAS},
mendeley-groups = {Scutigera},
pages = {30--43},
publisher = {Elsevier Inc.},
title = {{UAV lidar and hyperspectral fusion for forest monitoring in the southwestern USA}},
url = {http://dx.doi.org/10.1016/j.rse.2017.04.007},
volume = {195},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Chen2017,
abstract = {Monitoring vegetation recovery typically requires ground measurements of vegetation height, which is labor-intensive and time-consuming. Recently, unmanned aerial vehicles (UAVs) have shown great promise for characterizing vegetation in a cost-efficient way, but the literature on specific methods and cost savings is scant. In this study, we surveyed vegetation height on seismic lines in Alberta's Boreal Forest using a point-intercept sampling strategy, and compared them to height estimates derived from UAV-based photogrammetric point clouds. In order to derive UAV-based vegetation height, we tested three different approaches to estimate terrain elevation: (1) UAV{\_}RTK, where photogrammetric point clouds were normalized using terrain measurements obtained from a real-time kinematic global navigation satellite system (RTK GNSS) surveys; (2) UAV{\_}LiDAR, where photogrammetric data were normalized using pre-existing LiDAR (Light Detection and Ranging) data; and (3) UAV{\_}UAV, where UAV photogrammetry data were used alone. Comparisons were done at two scales: point level (n = 1743) and site level (n = 30). The point-level root-mean-square errors (RMSEs) of UAV{\_}RTK, UAV{\_}LiDAR, and UAV{\_}UAV were 28 cm, 31 cm, and 30 cm, respectively. The site-level RMSEs were 11 cm, 15 cm, and 8 cm, respectively. At the aggregated site level, we found that UAV photogrammetry could replace traditional field-based vegetation surveys of mean vegetation height across the range of conditions assessed in this study, with an RMSE less than 10 cm. Cost analysis indicates that using UAV-based point clouds is more cost-effective than traditional field vegetation surveys.},
archivePrefix = {arXiv},
arxivId = {PII S0034-4257(99)00067-X},
author = {Chen, Shijuan and McDermid, Gregory J. and Castilla, Guillermo and Linke, Julia},
doi = {10.3390/rs9121257},
eprint = {PII S0034-4257(99)00067-X},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2017 - Measuring vegetation height in linear disturbances in the boreal forest with UAV photogrammetry.pdf:pdf},
isbn = {2072-4292},
issn = {20724292},
journal = {Remote Sensing},
keywords = {3D,Accuracy assessment,Point clouds,Remote sensing,UAV,Vegetation},
mendeley-groups = {Scutigera},
number = {12},
pmid = {15481248},
title = {{Measuring vegetation height in linear disturbances in the boreal forest with UAV photogrammetry}},
volume = {9},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Nikolov2017,
abstract = {The wind energy sector faces a constant need for annual inspections of wind turbine blades for damage, erosion and cracks. These inspections are an important part of the wind turbine life cycle and can be very costly and hazardous to specialists. This has led to the use of automated drone inspections and the need for accurate, robust and inexpensive systems for localization of drones relative to the wing. Due to the lack of visual and geometrical features on the wind turbine blade, conventional SLAM algorithms have a limited use. We propose a cost-effective, easy to implement and extend system for on-site outdoor localization and mapping in low feature environment using the inexpensive RPLIDAR and an 9-DOF IMU. Our algorithm geometrically simplifies the wind turbine blade 2D cross-section to an elliptical model and uses it for distance and shape correction. We show that the proposed algorithm gives localization error between 1 and 20 cm depending on the position of the LiDAR compared to the blade and a maximum mapping error of 4 cm at distances between 1.5 and 3 meters from the blade. These results are satisfactory for positioning and capturing the overall shape of the blade.},
author = {Nikolov, Ivan and Madsen, Claus},
doi = {10.5220/0006124304180425},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nikolov, Madsen - 2017 - LiDAR-based 2D Localization and Mapping System using Elliptical Distance Correction Models for UAV Wind Turbine.pdf:pdf},
isbn = {978-989-758-225-7},
journal = {Proceedings of the 12th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
mendeley-groups = {Scutigera},
number = {Visigrapp},
pages = {418--425},
title = {{LiDAR-based 2D Localization and Mapping System using Elliptical Distance Correction Models for UAV Wind Turbine Blade Inspection}},
url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006124304180425},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Kwon2017,
abstract = {In recent years, much progress has been made in the construction sector through the use of automation and information technology. Due to an increasing demand for 3D modeling of spatial information, a variety of techniques have been developed. In addition, point cloud data generation technology using laser scanners and PhotoScan is attracting attention as a means of creating 3D model data on construction sites. In this paper, 3D point cloud data to be used in earthwork projects is generated using a hybrid scanning method (a laser scanner and UAV aerial photograph data are used in combination), while verifying the usability of the 3D point cloud data by merging the generated data. The objective of this study is to present a hybrid scanning method for the 3D modeling of earthwork in construction operations. Utilizing the hybrid scanning method proposed in this paper, it is possible to quickly and accurately process 3D mapping of atypical ground shapes that continually change according to the construction situation. This study is expected to be used as fundamental research in the Intelligent Task Planning System, which can extract the amount of progress in earthwork projects.},
author = {Kwon, Soonwook and Park, Jae Woo and Moon, Daeyoon and Jung, Suwan and Park, Heesung},
doi = {10.1016/j.proeng.2017.07.168},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kwon et al. - 2017 - Smart Merging Method for Hybrid Point Cloud Data using UAV and LIDAR in Earthwork Construction.pdf:pdf},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {3D modelling,Laser scanner,Point Cloud Data,UAV,photogrammetry},
mendeley-groups = {Scutigera},
number = {June},
pages = {21--28},
publisher = {The Author(s)},
title = {{Smart Merging Method for Hybrid Point Cloud Data using UAV and LIDAR in Earthwork Construction}},
url = {http://dx.doi.org/10.1016/j.proeng.2017.07.168},
volume = {196},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Elaksher2017,
abstract = {Recently, developments in airborne sensors and easy to fly, reliable, low-cost commercial Unmanned Aerial Vehicles,
UAVs, have opened a new era for high quality and reliable mapping from UAVs using remote sensing techniques. The
restricted payload capacity of low-cost UAVs imposes constraints on the quality of their navigation systems and the sensors
they can carry. Therefore, LIDAR sensors with limited sample rate are utilized within the UAV system. This article
introduces several applications that utilizes UAV-LIDAR systems, processing of a sample dataset downloaded from the
internet and a new system that is being developed and flown. Our data was collected with DJI S900 Hexacopter and a
VLP-16 LIDAR system from Velodyne. We then process the raw data to generate the 3D point cloud. The test site is a
farming site so we classified the points into ground points and vegetation points. The results are very promising as an early
research investigation. Currently, we are planning for other flights with more rigorous systems and quantitative evaluation.},
author = {Elaksher, Ahmed and Bhandari, Subodh and {Carreon Limones}, Christian A. and Lauf, Rachel},
doi = {10.1117/12.2275482},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elaksher et al. - 2017 - Potential of UAV lidar systems for geospatial mapping.pdf:pdf},
isbn = {9781510612693},
issn = {1996756X},
journal = {Lidar Remote Sensing for Environmental Monitoring 2017},
keywords = {uav lidar mapping},
mendeley-groups = {Scutigera},
number = {August 2017},
pages = {20},
title = {{Potential of UAV lidar systems for geospatial mapping}},
url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10406/2275482/Potential-of-UAV-lidar-systems-for-geospatial-mapping/10.1117/12.2275482.full},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{PututAshShidiq2017,
abstract = {{\textcopyright} Published under licence by IOP Publishing Ltd. Topographical data is highly needed by many parties, such as government institution, mining companies and agricultural sectors. It is not just about the precision, the acquisition time and data processing are also carefully considered. In relation with forest management, a high accuracy topographic map is necessary for planning, close monitoring and evaluating forest changes. One of the solution to quickly and precisely mapped topography is using remote sensing system. In this study, we test high-resolution data using Light Detection and Ranging (LiDAR) collected from unmanned aerial vehicles (UAV) to map topography and differentiate vegetation classes based on height in urban forest area of University of Indonesia (UI). The semi-automatic and manual classifications were applied to divide point clouds into two main classes, namely ground and vegetation. There were 15,806,380 point clouds obtained during the post-process, in which 2.39{\%} of it were detected as ground.},
author = {{Putut Ash Shidiq}, Iqbal and Wibowo, Adi and Kusratmoko, Eko and Indratmoko, Satria and Ardhianto, Ronni and {Prasetyo Nugroho}, Budi},
doi = {10.1088/1755-1315/98/1/012034},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Putut Ash Shidiq et al. - 2017 - Urban forest topographical mapping using UAV LIDAR.pdf:pdf},
issn = {17551315},
journal = {IOP Conference Series: Earth and Environmental Science},
keywords = {DEM,LIDAR,drone,topography,vegetation},
mendeley-groups = {Scutigera},
number = {1},
title = {{Urban forest topographical mapping using UAV LIDAR}},
volume = {98},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Guo2017,
abstract = {We fabricated silicon–germanium (Si1−xGex) based HIT solar cells with x=0, 0.25, 0.41 and 0.56 in order to quantify the effect of germanium fraction on key solar cell performance parameters. The p-type absorber layer consists of 2 and 4$\mu$m Si1−xGex layer grown on p+ silicon substrate using a graded buffer layer to reduce the threading dislocation density. The emitter is n+ amorphous-Si. A thin strained-Si layer is grown on the c-Si1−xGex layer prior to a-Si deposition and is believed to improve a-Si–H/c-Si1−xGex interface quality. The short-circuit current (Jsc) increases, from ∼14mA/cm2 for Si cells to 21mA/cm2 for Si0.44Ge0.56 cells with 2$\mu$m-thick active layers, while open-circuit voltage decreases. The spectral response of the Si1−xGex solar cells improves due to a reduction in absorption depth and smaller band-gap associated with the higher germanium fractions.},
author = {Guo, Qinghua and Su, Yanjun and Hu, Tianyu and Zhao, Xiaoqian and Wu, Fangfang and Li, Yumei and Liu, Jin and Chen, Linhai and Xu, Guangcai and Lin, Guanghui and Zheng, Yi and Lin, Yiqiong and Mi, Xiangcheng and Fei, Lin and Wang, Xugao},
doi = {10.1080/01431161.2017.1285083},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - A LiDAR and IMU integrated indoor navigation system for UAVs and its application in real-time pipeline classifi(5).pdf:pdf},
issn = {13665901},
journal = {International Journal of Remote Sensing},
mendeley-groups = {Scutigera},
number = {8-10},
pages = {2954--2972},
publisher = {Taylor {\&} Francis},
title = {{An integrated UAV-borne lidar system for 3D habitat mapping in three forest ecosystems across China}},
url = {http://dx.doi.org/10.1080/01431161.2017.1285083},
volume = {38},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Wei2017,
abstract = {A vegetation filtering algorithm is proposed for unmanned aerial vehicle (UAV)-borne lidar point clouds collected in the middle-lower Yangtze River riparian zone covered with multilayer and high-density vegetation. The proposed algorithm aims at generating digital elevation model, which consists of the following steps. First, multi-echo analysis is adopted for coarse filtering of point clouds. Then, morphological calculation is used to extract the ground seed points. Next, the trend surface of the local terrain is fitted. Meanwhile, the vegetation points are removed with the ground points preserved via random sample consensus. Experiments demonstrate that the performances of the algorithm were more accurate than Terrasolid's TerraScan when dealing with UAV-borne lidar point clouds in limited sample of a multilayer and high-density vegetation covering areas. The research results also show that by using a special filtering approach it is possible to classify laser points into terrain and vegetation automatically even for thoroughly mixed vegetation and terrain points and penetration rate of below 15{\%}. {\textcopyright} 2016 Informa UK Limited, trading as Taylor {\&} Francis Group},
author = {Wei, Lixin and Yang, Biao and Jiang, Jianping and Cao, Guanzhong and Wu, Mingfei},
doi = {10.1080/01431161.2016.1252476},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - A LiDAR and IMU integrated indoor navigation system for UAVs and its application in real-time pipeline classifi(7).pdf:pdf},
issn = {13665901},
journal = {International Journal of Remote Sensing},
mendeley-groups = {Scutigera},
number = {8-10},
pages = {2991--3002},
publisher = {Taylor {\&} Francis},
title = {{Vegetation filtering algorithm for UAV-borne lidar point clouds: a case study in the middle-lower Yangtze River riparian zone}},
url = {http://dx.doi.org/10.1080/01431161.2016.1252476},
volume = {38},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Thiel2017,
abstract = {Formation and excitation energies as well charge transition levels are determined for the substitutional nitrogen (Ns{\textless}math{\textgreater}{\textless}msub{\textgreater}{\textless}mrow{\textgreater}{\textless}mi mathvariant="normal"{\textgreater}s), the vacancy (V), and related point defects (NV, NVH, N2{\textless}math{\textgreater}{\textless}msub{\textgreater}{\textless}mrow{\textgreater}{\textless}mn{\textgreater}2, N2{\textless}math{\textgreater}{\textless}msub{\textgreater}{\textless}mrow{\textgreater}{\textless}mn{\textgreater}2V, and V2{\textless}math{\textgreater}{\textless}msub{\textgreater}{\textless}mrow{\textgreater}{\textless}mn{\textgreater}2) by screened nonlocal hybrid density functional supercell plane wave calculations in bulk diamond. In addition, the activation energy for V and NV diffusion is calculated. We find good agreement between theory and experiment for the previously well-established data and predict missing ones. Based on the calculated properties of these defects, the formation of the negatively charged NV center is studied, because it is a prominent candidate for application in quantum information processing and for nanosensors. Our results indicate that NV defects are predominantly created directly by irradiation, while simultaneously produced vacancies will form V2{\textless}math{\textgreater}{\textless}msub{\textgreater}{\textless}mrow{\textgreater}{\textless}mn{\textgreater}2 pairs during postirradiation annealing. Divacancies may pin the Fermi level, making the NV defects neutral.},
archivePrefix = {arXiv},
arxivId = {1311.6598},
author = {Thiel, Christian and Schmullius, Christiane},
doi = {10.1080/01431161.2016.1225181},
eprint = {1311.6598},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thiel, Schmullius - 2017 - Comparison of UAV photograph-based and airborne lidar-based point clouds over forest from a forestry applicat.pdf:pdf},
isbn = {1098-0121},
issn = {13665901},
journal = {International Journal of Remote Sensing},
mendeley-groups = {Scutigera},
number = {8-10},
pages = {2411--2426},
pmid = {25302780},
publisher = {Taylor {\&} Francis},
title = {{Comparison of UAV photograph-based and airborne lidar-based point clouds over forest from a forestry application perspective}},
url = {http://dx.doi.org/10.1080/01431161.2016.1225181},
volume = {38},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Gee2017,
abstract = {Lidars can be extremely useful tools for measuring outdoor geometry. However while lidar measurements are championed for their high accuracy their point clouds are individually rather sparse and lack colour information. In this work the sparse nature of lidar point clouds is addressed by merging multiple lidar scans into a single large point cloud. This is done by restricting the lidar motion to a single axis of translation and then using interpolation and iterative refinement to acquire a denser model by combining co-registered sets of point clouds. This newly constructed model is then used to guide a basic stereo SLAM (simultaneous localization and mapping) algorithm in order to produce a final dense coloured point cloud that preserves the accuracy of the original lidar measurements. Our experiments were performed at various locations using a 16 channel {\&}{\#}x201C;Puck{\&}{\#}x201D; Velodyne lidar and a stereo acquisition system consisting of a DJI Phantom quadcopter and a synchronized pair of GoPro HERO 3+ black edition cameras. Results of these experiments demonstrate that the produced reconstructions are both ascetically sound and quantitatively consistent with a set of individual measurements taken around the scene.},
author = {Gee, Trevor and James, Jason and {Van Der Mark}, Wannes and Delmas, Patrice and Gimel'Farb, Georgy},
doi = {10.1109/IVCNZ.2016.7804433},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gee et al. - 2017 - Lidar guided stereo simultaneous localization and mapping (SLAM) for UAV outdoor 3-D scene reconstruction.pdf:pdf},
isbn = {9781509027484},
issn = {21512205},
journal = {International Conference Image and Vision Computing New Zealand},
mendeley-groups = {Scutigera},
pages = {1--6},
publisher = {IEEE},
title = {{Lidar guided stereo simultaneous localization and mapping (SLAM) for UAV outdoor 3-D scene reconstruction}},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Teng2017,
abstract = {Light detection and ranging (LIDAR) system based on unmanned aerial vehicles (UAVs) recently are in rapid advancement, meanwhile portable and flexible mini-UAV-borne laser scanners have been a hot research field, especially for the complex terrain survey in the mountains and other areas. This study proposes a power line inspection system solution based on mini-UAV-borne LIDAR system—AOEagle, developed by Academy of Opto-Electronics, Chinese Academy of Sciences, which mounted on a Multi-rotor unmanned aerial vehicle for complex terrain survey according to real test. Furthermore, the point cloud data was explored to validate its applicability for power line inspection, in terms of corridor and line laser point clouds; deformation detection of power towers, etc. The feasibility and advantages of AOEagle have been demonstrated by the promising results based on the real-measured data in the field of power line inspection.},
author = {Teng, G. E. and Zhou, M. and Li, C. R. and Wu, H. H. and Li, W. and Meng, F. R. and Zhou, C. C. and Ma, L.},
doi = {10.5194/isprs-archives-XLII-2-W7-297-2017},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Teng et al. - 2017 - Mini-UAV LIDAR for power line inspection.pdf:pdf},
issn = {16821750},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {AOEagle,Mini-LIDAR,Pole,Power line inspection,Transmission line,UAV},
mendeley-groups = {Scutigera},
number = {2W7},
pages = {297--300},
title = {{Mini-UAV LIDAR for power line inspection}},
volume = {42},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Persad2017,
abstract = {The automatic alignment of 3D point clouds acquired or generated from different sensors is a challenging problem. The objective of the alignment is to estimate the 3D similarity transformation parameters, including a global scale factor, 3 rotations and 3 translations. To do so, corresponding anchor features are required in both data sets. There are two main types of alignment: i) Coarse alignment and ii) Refined Alignment. Coarse alignment issues include lack of any prior knowledge of the respective coordinate systems for a source and target point cloud pair and the difficulty to extract and match corresponding control features (e.g., points, lines or planes) co-located on both point cloud pairs to be aligned. With the increasing use of UAVs, there is a need to automatically co-register their generated point cloud-based digital surface models with those from other data acquisition systems such as terrestrial or airborne lidar point clouds. This works presents a comparative study of two independent feature matching techniques for addressing 3D conformal point cloud alignment of UAV and lidar data in different 3D coordinate systems without any prior knowledge of the seven transformation parameters.},
author = {Persad, Ravi Ancil and Armenakis, Costas},
doi = {10.5194/isprs-archives-XLII-2-W6-275-2017},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Persad, Armenakis - 2017 - Comparison of 2d and 3D approaches for the alignment of UAV and lidar point clouds.pdf:pdf},
isbn = {16821750 (ISSN)},
issn = {16821750},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {Alignment,Automation,Comparison,Lidar,Point clouds,UAV},
mendeley-groups = {Scutigera},
number = {2W6},
pages = {275--279},
title = {{Comparison of 2d and 3D approaches for the alignment of UAV and lidar point clouds}},
volume = {42},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Chiang2017,
abstract = {In disaster management, reconstructing the environment and quickly collecting the geospatial data of the impacted areas in a short time are crucial. In this letter, a light detection and ranging (LiDAR)-based unmanned aerial vehicle (UAV) is proposed to complete the reconstruction task. The UAV integrate an inertial navigation system (INS), a global navigation satellite system (GNSS) receiver, and a low-cost LiDAR. An unmanned helicopter is introduced and the multisensor payload architecture for direct georeferencing is designed to improve the capabilities of the vehicle. In addition, a new strategy of iterative closest point algorithm is proposed to solve the registration problems in the sparse and inhomogeneous derived point cloud. The proposed registration algorithm addresses the local minima problem by the use of direct-georeferenced points and the novel hierarchical structure as well as taking the feedback bias into INS/GNSS. The generated point cloud is compared with a more accurate one derived from a high-grade terrestrial LiDAR which uses real flight data. Results indicate that the proposed UAV system achieves meter-level accuracy and reconstructs the environment with dense point cloud.},
author = {Chiang, Kai Wei and Tsai, Guang Je and Li, Yu Hua and El-Sheimy, Naser},
doi = {10.1109/LGRS.2017.2736013},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chiang et al. - 2017 - Development of LiDAR-Based UAV System for Environment Reconstruction.pdf:pdf},
isbn = {1545-598X VO - PP},
issn = {1545598X},
journal = {IEEE Geoscience and Remote Sensing Letters},
keywords = {Direct georeferencing (DG),inertial navigation system and global navigation s,iterative closest point (ICP),light detection and ranging (LiDAR),unmanned aerial vehicle (UAV)},
mendeley-groups = {Scutigera},
number = {10},
pages = {1790--1794},
title = {{Development of LiDAR-Based UAV System for Environment Reconstruction}},
volume = {14},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Moore2017,
author = {Moore, Andrew J and Schubert, Matthew and Rymer, Nicholas and Balachandran, Swee and Consiglio, Maria and Munoz, Cesar and Smith, Joshua and Lewis, Dexter and {Schneider Georgia Power}, Paul},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - A LiDAR and IMU integrated indoor navigation system for UAVs and its application in real-time pipeline classifi(4).pdf:pdf},
isbn = {2017001104},
mendeley-groups = {Scutigera},
title = {{UAV Inspection of Electrical Transmission Infrastructure with Path Conformance Autonomy and Lidar-based Geofences NASA Report on UTM Reference Mission Flights at Southern Company Flights November 2016 NASA STI Program . . . in Profile}},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Edwards2017,
author = {Edwards, Author Stuart},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Edwards - 2017 - Autonomous 3D Mapping and Surveillance of Mines with MAVs.pdf:pdf},
mendeley-groups = {Scutigera},
number = {March},
title = {{Autonomous 3D Mapping and Surveillance of Mines with MAVs}},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Shetty2017,
abstract = {—Outdoor applications for small-scale Unmanned Aerial Vehicles (UAVs) commonly rely on Global Positioning System (GPS) receivers for continuous and accurate position estimates. However, in urban areas GPS satellite signals might be reflected or blocked by buildings, resulting in multipath or non-line-of-sight (NLOS) errors. In such cases, additional on-board sensors such as Light Detection and Ranging (LiDAR) are desirable. Kalman Filtering and its variations are commonly used to fuse GPS and LiDAR measurements. However, it is important, yet challenging, to accurately characterize the error covariance of the sensor measurements. In this paper, we propose a GPS-LiDAR fusion technique with a novel method for efficiently modeling the position error covari-ance based on LiDAR point clouds. We model the covariance as a function features distributed in the point cloud. We use the LiDAR point clouds in two ways: to estimate incremental motion by matching consecutive point clouds; and, to estimate global pose by matching with a 3-dimensional (3D) city model. For GPS measurements, we use the 3D city model to eliminate NLOS satellites and model the measurement covariance based on the received signal-to-noise-ratio (SNR) values. Finally, all the above measurements and error covariance matrices are input to an Unscented Kalman Filter (UKF), which estimates the globally referenced pose of the UAV. To validate our algorithm, we conduct UAV experiments in GPS-challenged urban environments on the University of Illinois at Urbana-Champaign campus. Keywords—Unmanned aerial vehicles (UAVs), light detection and ranging (LiDAR), 3-dimensional (3D) city model, global positioning system (GPS), unscented kalman filter (UKF)},
author = {Shetty, Akshay and Gao, Grace Xingxin},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shetty, Gao - 2017 - Covariance Estimation for GPS-LiDAR Sensor Fusion for UAVs.pdf:pdf},
isbn = {9781510853317},
keywords = {3-dimensional,3d,and ranging,city model,global,gps,lidar,light detection,positioning system,uavs,ukf,unmanned aerial vehicles,unscented kalman filter},
mendeley-groups = {Scutigera},
pages = {1--5},
title = {{Covariance Estimation for GPS-LiDAR Sensor Fusion for UAVs}},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Govedarica2018,
abstract = {Floods are one of the most serious and common natural disasters that cause fatalities and considerable economic losses worldwide every year. In order to reduce and manage risk that floods pose to human health, the environmental and economy flood risk map, as a crucial element of flood risk management, need to be generated. Most often flood risk is estimated based on Digital Elevation Model and projected water levels therefor DEM's resolution and accuracy highly influence on the reliability of flood risk map especially in lowlands area, where the offset of few decimeters in the elevation data have a significant impact. Airborne light detection and ranging (LiDAR) remote sensing has been a widely used method that provides high-resolution topographical datasets. However LiDAR data are expensive and hard to acquire, usually limited by availability of technology and legal constrains. The main aim of this paper is to present usability of DEM, crated based on UAV RGB images, for flood risk assessment in Vojvodina Porvince, Republic of Serbia therefor flood risk assessment by using the UAV DEM was compared with a flood risk assessment based on LiDAR DEM. Additionally, UAV point cloud was compared with high resolution LiDAR point cloud. {\textcopyright} (2018) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.},
author = {Govedarica, Miro and Jakovljevic, Gordana and {{\'{A}}lvarez Taboada}, Flor},
doi = {10.1117/12.2513278},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Govedarica, Jakovljevic, {\'{A}}lvarez Taboada - 2018 - Flood risk assessment based on LiDAR and UAV points clouds and DEM.pdf:pdf},
isbn = {9781510621497},
issn = {1996756X},
journal = {Remote Sensing for Agriculture, Ecosystems, and Hydrology XX},
mendeley-groups = {Scutigera},
number = {October 2018},
pages = {102},
title = {{Flood risk assessment based on LiDAR and UAV points clouds and DEM}},
url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10783/2513278/Flood-risk-assessment-based-on-LiDAR-and-UAV-points-clouds/10.1117/12.2513278.full},
year = {2018},
project = {survey-Lidar-UAV}
}
@article{Torresan2018,
author = {Torresan, Chiara and Berton, Andrea and Carotenuto, Federico and Chiavetta, Ugo and Miglietta, Franco and Zaldei, Alessandro and Gioli, Beniamino},
doi = {10.3390/rs10071094},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Torresan et al. - 2018 - Development and performance assessment of a low-cost UAV laser scanner system (LasUAV).pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Forest monitoring,Global Navigation Satellite System,LiDAR,Real-time kinematics technology,System designing,System testing},
mendeley-groups = {Scutigera},
number = {7},
pages = {1--17},
title = {{Development and performance assessment of a low-cost UAV laser scanner system (LasUAV)}},
volume = {10},
year = {2018},
project = {survey-Lidar-UAV}
}
@article{Chen2018,
abstract = {Transmission line corridor (i.e., Right-of-Ways (ROW)) clearance management plays a critically important role in power line risk management and is an important task of the routine power line inspection of the grid company. The clearance anomaly detection measures the distance between the power lines and the surrounding non-power-facility objects in the corridor such as trees, and buildings, to judge whether the clearance is within the safe range. To find the clearance hazards efficiently and flexibly, this study thus proposed an automatic clearance anomaly detection method utilizing LiDAR point clouds collected by unmanned aerial vehicle (UAV). Firstly, the terrain points were filtered out using two-step adaptive terrain filter and the pylons were detected in the non-terrain points following a feature map method. After dividing the ROW point clouds into spans based on the pylon detection results, the power line point clouds were extracted according to their geometric distribution in local span point clouds slices, and were further segmented into clusters by applying conditional Euclidean clustering with linear feature constraints. Secondly, the power line point clouds segments were iteratively fitted with 3D catenary curve model that is represented by a horizontal line and a vertical catenary curve defined by a hyperbolic cosine function, resulting in a continuous mathematical model of the discretely sampled points of the power line. Finally, a piecewise clearance calculation method which converts the point-to-catenary curve distance measurements to minimal distance calculation based on differential geometry was used to calculate the distance between the power line and the non-power-facility objects in the ROW. The clearance measurements were compared with the standard safe threshold to find the clearance anomalies in the ROWs. Multiple LiDAR point clouds datasets collected by a large-scale UAV power line inspection system were used to validate the effectiveness and accuracy of the proposed method. The detected results were validated through qualitatively visual inspection, quantitatively manual measurements in raw point clouds and on-site field survey. The experiments show that the automatic clearance anomaly detection method proposed in this paper effectively detects the clearance hazards such as tree encroachment, and the clearance measurement accuracy is decimeter level for the LiDAR point clouds collected by our UAV inspection system.},
author = {Chen, Chi and Yang, Bisheng and Song, Shuang and Peng, Xiangyang and Huang, Ronggang},
doi = {10.3390/rs10040613},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2018 - Automatic clearance anomaly detection for transmission line corridors utilizing UAV-Borne LIDAR data.pdf:pdf},
isbn = {8618571670588},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Clearance anomaly,Feature Extraction,LiDAR,Point clouds,Power transmission lines inspection,UAV},
mendeley-groups = {Scutigera},
number = {4},
title = {{Automatic clearance anomaly detection for transmission line corridors utilizing UAV-Borne LIDAR data}},
volume = {10},
year = {2018},
project = {survey-Lidar-UAV}
}
@article{Yan2018,
abstract = {{\textless}p{\textgreater}Forests play a key role in terrestrial ecosystems, and the variables extracted from single trees can be used in various fields and applications for evaluating forest production and assessing forest ecosystem services. In this study, we developed an automated hierarchical single-tree segmentation approach based on the high density three-dimensional (3D) Unmanned Aerial Vehicle (UAV) point clouds. First, this approach obtains normalized non-ground UAV points in data preprocessing; then, a voxel-based mean shift algorithm is used to roughly classify the non-ground UAV points into well-detected and under-segmentation clusters. Moreover, potential tree apices for each under-segmentation cluster are obtained with regard to profile shape curves and finally input to the normalized cut segmentation (NCut) algorithm to segment iteratively the under-segmentation cluster into single trees. We evaluated the proposed method using datasets acquired by a Velodyne 16E LiDAR system mounted on a multi-rotor UAV. The results showed that the proposed method achieves the average correctness, completeness, and overall accuracy of 0.90, 0.88, and 0.89, respectively, in delineating single trees. Comparative analysis demonstrated that our method provided a promising solution to reliable and robust segmentation of single trees from UAV LiDAR data with high point cloud density.{\textless}/p{\textgreater}},
author = {Yan, Wanqian and Guan, Haiyan and Cao, Lin and Yu, Yongtao and Gao, Sha and Lu, JianYong and Yan, Wanqian and Guan, Haiyan and Cao, Lin and Yu, Yongtao and Gao, Sha and Lu, JianYong},
doi = {10.3390/rs10121999},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yan et al. - 2018 - An Automated Hierarchical Approach for Three-Dimensional Segmentation of Single Trees Using UAV LiDAR Data.pdf:pdf},
issn = {2072-4292},
journal = {Remote Sensing},
keywords = {UAV LiDAR,improved normalized cut,mean shift,segmentation,single tree},
mendeley-groups = {Scutigera},
number = {12},
pages = {1999},
title = {{An Automated Hierarchical Approach for Three-Dimensional Segmentation of Single Trees Using UAV LiDAR Data}},
url = {http://www.mdpi.com/2072-4292/10/12/1999},
volume = {10},
year = {2018},
project = {survey-Lidar-UAV}
}
@article{Huang2018,
author = {Huang, Zhi Cheng and Yeh, Cheng Yang and Tseng, Kuo Hsin and Hsu, Wen Yang},
doi = {10.1175/JTECH-D-17-0199.1},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - A LiDAR and IMU integrated indoor navigation system for UAVs and its application in real-time pipeline classifi(2).pdf:pdf},
issn = {15200426},
journal = {Journal of Atmospheric and Oceanic Technology},
keywords = {Aircraft observations,Lidars/Lidar observations,Measurements},
mendeley-groups = {Scutigera},
number = {8},
pages = {1557--1570},
title = {{A UAV-RTK lidar system for wave and tide measurements in coastal zones}},
volume = {35},
year = {2018},
project = {survey-Lidar-UAV}
}
@article{Liu2018,
abstract = {Estimating forest structural attributes in planted forests is crucial for sustainably management of forests and helps to understand the contributions of forests to global carbon storage. The Unmanned Aerial Vehicle-Light Detecting and Ranging (UAV-LiDAR) has become a promising technology and attempts to be used for forest management, due to its capacity to provide highly accurate estimations of three-dimensional (3D) forest structural information with a lower cost, higher flexibility and finer resolution than airborne LiDAR. In this study, the effectiveness of plot-level metrics (i.e., distributional, canopy volume and Weibull-fitted metrics) and individual-tree-summarized metrics (i.e., maximum, minimum and mean height of trees and the number of trees from the individual tree detection (ITD) results) derived from UAV-LiDAR point clouds were assessed, then these metrics were used to fit estimation models of six forest structural attributes by parametric (i.e., partial least squares (PLS)) and non-parametric (i.e., k-Nearest Neighbors (k-NN) and Random Forest (RF)) approaches, within a Ginkgo plantation in east China. In addition, we assessed the effects of UAV-LiDAR point cloud density on the derived metrics and individual tree segmentation results, and evaluated the correlations of these metrics with aboveground biomass (AGB) by a sensitivity analysis. The results showed that, in general, models based on both plot-level and individual-tree-summarized metrics (CV-R2 = 0.66–0.97, rRMSE = 2.83–23.35{\%}) performed better than models based on the plot-level metrics only (CV-R2 = 0.62–0.97, rRMSE = 3.81–27.64{\%}). PLS had a relatively high prediction accuracy for Lorey's mean height (CV-R2 = 0.97, rRMSE = 2.83{\%}), whereas k-NN performed well for predicting volume (CV-R2 = 0.94, rRMSE = 8.95{\%}) and AGB (CV-R2 = 0.95, rRMSE = 8.81{\%}). For the point cloud density sensitivity analysis, the canopy volume metrics showed a higher dependence on point cloud density than other metrics. ITD results showed a relatively high accuracy (F1-score {\textgreater} 74.93{\%}) when the point cloud density was higher than 10{\%} (16 pts{\textperiodcentered}m−2). The correlations between AGB and the metrics of height percentiles, lower height level of canopy return densities and canopy cover appeared stable across different point cloud densities when the point cloud density was reduced from 50{\%} (80 pts{\textperiodcentered}m−2) to 5{\%} (8 pts{\textperiodcentered}m−2).},
author = {Liu, Kun and Shen, Xin and Cao, Lin and Wang, Guibin and Cao, Fuliang},
doi = {10.1016/j.isprsjprs.2018.11.001},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2018 - Estimating forest structural attributes using UAV-LiDAR data in Ginkgo plantations.pdf:pdf},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {Forest structural attributes,Ginkgo,LiDAR,Planted forest,Point cloud density,UAV},
mendeley-groups = {Scutigera},
number = {November},
pages = {465--482},
publisher = {Elsevier},
title = {{Estimating forest structural attributes using UAV-LiDAR data in Ginkgo plantations}},
url = {https://doi.org/10.1016/j.isprsjprs.2018.11.001},
volume = {146},
year = {2018},
project = {survey-Lidar-UAV}
}
@article{Youn2018,
abstract = {{\textless}p{\textgreater}{\textless}p{\textgreater}{\textless}strong{\textgreater}Abstract.{\textless}/strong{\textgreater} With the drastic development of low-altitude UAV (Unmanned Aerial Vehicle) technology, UAV will be used for long-distance logistics in the near future. Many countries begin to develop UTM (UAV Traffic Management) system, and one of the objectives for the system is preparation of UAV-logistics era. In that era, hundreds of drone will simultaneously fly at one area. To prevent UAV collision in the air, UAV air road should be designed. The Korean government have supported research projects related with UAV air roads. This paper deals with development of UAV air roads by using 3D grid system. First, detail 3D spatial information for UAV air roads is constructed. In many cases, 3D digital map does not include transmission towers, utility poles, power lines, or trees, since the interests of 3D digital map are focussed on digital elevation model and digital surface model with buildings. The transmission towers, utility poles, and power lines could be obstacles when UAV perform its logistics mission. Therefore, detail 3D information should be constructed for UAV air roads. We constructed such detail 3D information by using MMS (Mobile Mapping System) and aerial survey with Lidar and digital photograph. Next, 3D grid system is proposed to present such detail 3D information. Usual object based 3D information is huge size and hard to control. To provide 3D information to a flying UAV, data should be light. Therefore, light-weight 3D grid system is effective to provide air road information to UAV. Proposed 3D grid based air roads can be used for UAV flight plan, traffic management etc.{\textless}/p{\textgreater}{\textless}/p{\textgreater}},
author = {Youn, J. and Kim, D. and Kim, T. and Yoo, J. H. and Lee, B. J.},
doi = {10.5194/isprs-archives-XLII-4-731-2018},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Youn et al. - 2018 - Development of Uav Air Roads By Using 3D Grid System.pdf:pdf},
issn = {2194-9034},
journal = {ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
keywords = {1000 word,3d grid system,500,abstract,air road,and one of the,detail 3d information,develop utm,for long-distance,future,logistics,logistics in the near,many countries begin to,objectives for,of low-altitude uav,system,technology,uav,uav traffic management,uav will be used,unmanned aerial vehicle,with the drastic development},
mendeley-groups = {Scutigera},
number = {October},
pages = {731--735},
title = {{Development of Uav Air Roads By Using 3D Grid System}},
url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-4/731/2018/},
volume = {XLII-4},
year = {2018},
project = {survey-Lidar-UAV}
}
@article{Fuad2018,
abstract = {{\textcopyright} Published under licence by IOP Publishing Ltd. Unmanned Aerial Vehicle (UAV) with Light Detecting Radar (LiDAR) sensor can be used to obtained high ground resolution data and generate good quality of Digital Terrain Model (DTM) as much can decrease the cost of data acquisition and processing time. This study aims to evaluate the influences of flying altitude and terrain on DTM accuracies obtained with UAV-based LiDAR. In this study, point clouds from UAV AL3 S1000 and AL3 - 32 LiDAR were used for generating DTM on two different terrains (i.e. flat, slope and overall) with three different flying altitudes (i.e. 20m, 40m and 60m) and validate with ground control points by using 129 reference points which taken from ground survey technique (GPS, total station and optical levelling). The Root Mean Square Error (RMSE) of point clouds elevation obtained at different altitudes for the flat area are 0.015m, 0.027m and 0.105m at the altitudes of 20m, 40m and 60m, respectively. Meanwhile, RMSE values for slope area are 0.267m, 0.298m and 0.343m at the altitudes of 20m, 40m and 60m, respectively. Overall study area gives the RMSE values of 0.323m, 0.450m and 0.616m at 20m, 40m and 60m altitude, respectively. The result shows that the change of RMSE values influenced by the different of altitude and terrain, which provides accurate and faster results.},
author = {Fuad, N. A. and Ismail, Z. and Majid, Z. and Darwin, N. and Ariff, M. F.M. and Idris, K. M. and Yusoff, A. R.},
doi = {10.1088/1755-1315/169/1/012100},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fuad et al. - 2018 - Accuracy evaluation of digital terrain model based on different flying altitudes and conditional of terrain using U.pdf:pdf},
issn = {17551315},
journal = {IOP Conference Series: Earth and Environmental Science},
mendeley-groups = {Scutigera},
number = {1},
title = {{Accuracy evaluation of digital terrain model based on different flying altitudes and conditional of terrain using UAV LiDAR technology}},
volume = {169},
year = {2018},
project = {survey-Lidar-UAV}
}
@article{Mastrangelo2018,
author = {Mastrangelo, John and von Niederhausern, Kurt and Nelson, Roy D. and Fuller, Daniel},
doi = {10.1117/12.2304393},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - A LiDAR and IMU integrated indoor navigation system for UAVs and its application in real-time pipeline classifi(3).pdf:pdf},
isbn = {9781510617810},
journal = {Ground/Air Multisensor Interoperability, Integration, and Networking for Persistent ISR IX},
keywords = {3d,lidar,scaneagle,uav},
mendeley-groups = {Scutigera},
number = {May 2018},
pages = {33},
title = {{Real-time LIDAR from ScanEagle UAV}},
url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10635/2304393/Real-time-LIDAR-from-ScanEagle-UAV/10.1117/12.2304393.full},
year = {2018},
project = {survey-Lidar-UAV}
}
@article{Hinterhofer2018,
author = {Hinterhofer, Thomas and Ullrich, Andreas and Hofst{\"{a}}tter, Michael and Pfennigbauer, Martin and Schraml, Stephan and Rothbacher, Dieter},
doi = {10.1117/12.2304353},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hinterhofer et al. - 2018 - UAV-based LiDAR and gamma probe with real-time data processing and downlink for survey of nuclear disaster l.pdf:pdf},
isbn = {9781510617698},
journal = {Chemical, Biological, Radiological, Nuclear, and Explosives (CBRNE) Sensing XIX},
mendeley-groups = {Scutigera},
number = {May 2018},
pages = {11},
title = {{UAV-based LiDAR and gamma probe with real-time data processing and downlink for survey of nuclear disaster locations}},
url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10629/2304353/UAV-based-LiDAR-and-gamma-probe-with-real-time-data/10.1117/12.2304353.full},
year = {2018},
project = {survey-Lidar-UAV}
}
@article{Gomes2018,
abstract = {{\textcopyright} Springer International Publishing AG 2018. This paper addresses the problem of deriving attitude estimation and trajectory tracking strategies for unmanned aerial vehicles (UAVs) using exclusively on-board sensors. The perception of the vehicle position and attitude relative to a structure is achieved by robustly comparing a known pier geometry or map with the data provided by a LiDAR sensor, solving an optimization problem and also robustly identifying outliers. Building on this information, several methods are discussed for obtaining the attitude of the vehicle with respect to the structure, including a nonlinear observer to estimate the vehicle attitude on SO(3). A simple nonlinear control strategy is also designed with the objective of providing an accurate trajectory tracking control relative to the structure, and experimental results are provided for the performance evaluation of the proposed algorithms.},
author = {Gomes, Alexandre and Guerreiro, Bruno J. and Cunha, Rita and Silvestre, Carlos and Oliveira, Paulo},
doi = {10.1007/978-3-319-70833-1_58},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gomes et al. - 2018 - Sensor-based 3-D pose estimation and control of rotary-wing UAVs using a 2-D LiDAR.pdf:pdf},
issn = {21945357},
journal = {Advances in Intelligent Systems and Computing},
mendeley-groups = {Scutigera},
pages = {718--729},
title = {{Sensor-based 3-D pose estimation and control of rotary-wing UAVs using a 2-D LiDAR}},
volume = {693},
year = {2018},
project = {survey-Lidar-UAV}
}
@article{Cramer2018,
author = {Cramer, M and Haala, N and Laupheimer, D and Mandlburger, G and Havel, P},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cramer et al. - 2018 - Ultra-High Precision Uav-Based Lidar and Dense Image Matching.pdf:pdf},
keywords = {deformation monitoring,engineering geodetic,uav-based dense image matching,uav-based lidar},
mendeley-groups = {Scutigera},
number = {October},
pages = {10--12},
title = {{Ultra-High Precision Uav-Based Lidar and Dense Image Matching}},
volume = {XLII},
year = {2018},
project = {survey-Lidar-UAV}
}
@article{Polewski2019,
author = {Polewski, Przemyslaw and Yao, Wei and Cao, Lin and Gao, Sha},
doi = {10.1016/j.isprsjprs.2018.11.020},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Polewski et al. - 2019 - Marker-free coregistration of UAV and backpack LiDAR point clouds in forested areas.pdf:pdf},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {Backpack laser scanning,Coregistration,Graph matching,Precision forestry,Unmanned aerial vehicle},
mendeley-groups = {Scutigera},
number = {July 2018},
pages = {307--318},
publisher = {Elsevier},
title = {{Marker-free coregistration of UAV and backpack LiDAR point clouds in forested areas}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S092427161830323X},
volume = {147},
year = {2019},
project = {survey-Lidar-UAV}
}
@article{Park2019,
author = {Park, Jisoo and Kim, Pileun and Cho, Yong K. and Kang, Junsuk},
doi = {10.1016/j.autcon.2018.11.024},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Park et al. - 2019 - Framework for automated registration of UAV and UGV point clouds using local features in images.pdf:pdf},
issn = {09265805},
journal = {Automation in Construction},
keywords = {Automation,Drone,Mobile robot,Point cloud,Registration,UAV,UGV},
mendeley-groups = {Scutigera},
number = {November 2018},
pages = {175--182},
publisher = {Elsevier},
title = {{Framework for automated registration of UAV and UGV point clouds using local features in images}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0926580518308641},
volume = {98},
year = {2019},
project = {survey-Lidar-UAV}
}
@article{Koska2017,
abstract = {In this article, the autonomous mapping airship (AMA) equipped with lidar along with its basic properties is introduced. Other methods and technologies using unmanned aerial vehicles (UAVs) or conventional aircraft are then compared to the AMA. Specifically automatic reconstruction from photographs acquired with fixed wing UAVs and lidar taken from conventional aircraft. Comparison of technologies was realized in the locality of a brown coal mine spoil heap. The size of the spoil heap interest part is about three square kilometres and it is covered with wind-blown vegetation (trees, grass, bush). We also measured about 100 height check points (HCPs) using real-time kinematic Global Navigation Satellite System technology for the purpose of accuracy analysis in the locality. One group of the HCPs were measured on the vegetation-free ground and the second group on ground with low vegetation (grass). Other properties of the methods used and the data acquired were also compared. The most important of these were data density, vegetation penetrability, speed of data collection, and economical aspects. {\textcopyright} 2017 Informa UK Limited, trading as Taylor {\&} Francis Group},
author = {Koska, Bronislav and Jirka, Vladim{\'{i}}r and Urban, Rudolf and Křemen, Tom{\'{a}}{\v{s}} and Hesslerov{\'{a}}, Petra and Jon, Jakub and Posp{\'{i}}{\v{s}}il, Jiř{\'{i}} and Fogl, Michal},
doi = {10.1080/01431161.2017.1285086},
file = {:home/maxime/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koska et al. - 2017 - Suitability, characteristics, and comparison of an airship UAV with lidar for middle size area mapping.pdf:pdf},
issn = {13665901},
journal = {International Journal of Remote Sensing},
mendeley-groups = {Scutigera},
number = {8-10},
pages = {2973--2990},
publisher = {Taylor {\&} Francis},
title = {{Suitability, characteristics, and comparison of an airship UAV with lidar for middle size area mapping}},
url = {http://dx.doi.org/10.1080/01431161.2017.1285086},
volume = {38},
year = {2017},
project = {survey-Lidar-UAV}
}
@article{Liu2015,
abstract = {A simple hand is a robotic gripper that trades off generality in function for practicality in design and control. The long-term goal of our work is to explore that tradeoff and demonstrate broad manipulation capabilities with simple hands. This paper describes two prototype simple hands. Both hands have thin cylindrical fingers arranged symmetrically around a low friction circular palm. The fingers are compliantly coupled to a single actuator. Our experiments with both hands in a bin- picking scenario demonstrate that we can achieve robust grasp classification and in-hand localization using simple statistical techniques. We further show how the classification accuracy increases as the grasp proceeds by exploiting information obtained online. We finally evaluate the relative importance of observing the full state of the hand rather than just observing the state of the actuators.},
author = {Liu, Sikang and Mohta, Kartik and Shen, Shaojie and Kumar, Vijay},
doi = {10.1007/bfb0027579},
isbn = {978-3-319-23777-0},
journal = {Experimental Robotics III},
keywords = {attractive area of research,autonomously mapping and exploring,exploration,have significant impacts on,in particular,mapping,mavs,multi-robot,opment,potentials for devel-,quadrotor,robotics mapping is an,slam,systems with micro aerial,that are capable of,the field of search,vehicles,with a lot of},
title = {{Towards Collaborative Mapping and Exploration Using Multiple Micro Aerial Robots BT - Experimental Robotics: The 14th International Symposium on Experimental Robotics}},
year = {2015}
}
@article{Vempati2017,
abstract = {In this paper, we propose a GPU parallelized SLAM system capable of using photometric and inertial data together with depth data from an active RGB-D sensor to build accurate dense 3D maps of indoor environments. We describe several extensions to existing dense SLAM techniques that allow us to operate in real-time onboard memory constrained robotic platforms. Our primary contribution is a memory management algorithm that scales to large scenes without being limited by GPU memory resources. Moreover, by integrating a visual-inertial odometry system, we robustly track the camera pose even on an agile platform such as a quadrotor UAV. Our robust camera tracking framework can deal with fast camera motions and varying environments by relying on depth, color and inertial motion cues. Global consistency is achieved via regular checking for loop closures in conjunction with a pose graph, as a basis for corrective deformation of the 3D map. Our efficient SLAM system is capable of producing highly dense meshes up to 5mm resolution at rates close to 60Hz fully onboard a UAV. Experimental validations both in simulation and on a real-world platform, show that our approach is fast, more robust and more memory efficient than state-of-the-art techniques, while obtaining better or comparable accuracy.},
author = {Vempati, Anurag Sai and Gilitschenski, Igor and Nieto, Juan and Beardsley, Paul and Siegwart, Roland},
doi = {10.1109/IROS.2017.8206189},
isbn = {9781538626825},
issn = {21530866},
journal = {IEEE International Conference on Intelligent Robots and Systems},
keywords = {Aerial Systems: Perception and Autonomy,RGB-D Perception,SLAM},
pages = {3479--3486},
title = {{Onboard real-time dense reconstruction of large-scale environments for UAV}},
volume = {2017-September},
year = {2017}
}
@article{Nasrollahi2018,
abstract = {Efficient inspection and maintenance of bridges are vital for improving safety and sustainability of infrastructure systems. Recently, Light Detection and Ranging (LiDAR) scanners are used for detecting surface defects. The LiDAR scanner can be mounted on an Unmanned Aerial Vehicle (UAV), which provides easier accessibility to most parts of the structure and can fly close to the structure. There are two types of mobile LiDAR scanners: 2D and 3D. A 2D scanner is more affordable, but it can only scan points on a plane. However, a 2D scanner can be transferred into 3D scanner by rotating the scanner using a servo motor. This paper aims to design a platform for LiDAR-equipped UAV for structural inspection using an affordable 2D scanner. First, the requirements and other design considerations are introduced. Then, the design details and the hardware and software integration steps of the LiDAR-equipped UAV platform are discussed. The initial test of the platform showed that it can provide acceptable accuracy for detecting large defects. {\textcopyright} ISARC 2018 - 35th International Symposium on Automation and Robotics in Construction and International AEC/FM Hackathon: The Future of Building Things. All rights reserved.},
author = {Nasrollahi, Majid and Bolourian, Neshat and Zhu, Zhenhua and Hammad, Amin},
doi = {10.22260/isarc2018/0152},
journal = {Proceedings of the 35th International Symposium on Automation and Robotics in Construction (ISARC)},
number = {July},
title = {{Designing LiDAR-equipped UAV Platform for Structural Inspection}},
year = {2018}
}
@book{Papachristos2019,
abstract = {In this work we present an integrated approach for autonomous navigation and mapping in underground mines using aerial robots. Underground mines present a set of critical challenges as they are not only GPS-denied by nature, but their environmental circumstances also lead to severe sensor degradation (due to combinations of darkness, dust, and smoke), localizability problems (due to textureless surfaces and locally self-similar structure), while also presenting stringent navigation conditions as a result of certain very narrow geometries. To address these issues, the presented robotic systems integrate a multi-modal sensing suite and a set of associated fusion algorithms that enable simultaneous localization and mapping in the GPS-denied and visually-degraded environment of underground mines. More specifically, the fusion of visual and thermal cameras, LiDAR, as well as Inertial Measurement Unit cues is investigated in order to provide informative data in textureless, dark, and obscurants-filled settings. Provided the capacity for reliable pose estimation and mapping the surroundings despite the sensing degradation, autonomous navigation then becomes possible. Model Predictive Control is used to enable precise trajectory tracking and robustness against disturbances. Path planning for collision-avoidance and autonomous exploration is facilitated through a receding horizon sampling-based algorithm that further accounts for the vehicle dynamic constraints and its limited endurance. The integrated system is tested in field experiments inside underground metal mines in Northern Nevada. The presented results correspond to the navigation and mapping of mine drifts and headings and involve environments that are completely dark, dust-filled, and particularly textureless. As shown, the proposed approach ensures the robust and reliable autonomous navigation of aerial robots in underground mines, alongside consistent mapping.},
author = {Papachristos, Christos and Khattak, Shehryar and Mascarich, Frank and Alexis, Kostas},
month = {mar},
title = {{Autonomous Navigation and Mapping in Underground Mines Using Aerial Robots}},
year = {2019}
}
@article{Ozaslan2017,
abstract = {—In this paper, we address the estimation, control, navigation and mapping problems to achieve autonomous inspec-tion of penstocks and tunnels using aerial vehicles with on-board sensing and computation. Penstocks and tunnels have the shape of a generalized cylinder. They are generally dark and featureless. State estimation is challenging because range sensors do not yield adequate information and cameras do not work in the dark. We show that the six Degrees of Freedom (DOF) pose and velocity can be estimated by fusing information from an inertial measurement unit (IMU), a lidar and a set of cameras. This letter discusses in detail the range-based estimation part while leaving the details of vision component to our earlier work [1]. The proposed algorithm relies only on a model of the generalized cylinder and is robust to changes in shape of the tunnel. The approach is validated through real experiments showing autonomous and shared control, state estimation and environment mapping in the penstock at Center Hill Dam, TN. To our knowledge, this is the first time autonomous navigation and mapping has been achieved in a penstock without any external infrastructure such GPS or external cameras.},
author = {Ozaslan, Tolga and Taylor, Camillo J. and Kumar, Vijay and Keller, James and Wozencraft, Jennifer M. and Loianno, Giuseppe and Hood, Thomas},
doi = {10.1109/lra.2017.2699790},
issn = {2377-3766},
journal = {IEEE Robotics and Automation Letters},
number = {3},
pages = {1740--1747},
publisher = {IEEE},
title = {{Autonomous Navigation and Mapping for Inspection of Penstocks and Tunnels With MAVs}},
volume = {2},
year = {2017}
}
@article{Michael2012,
author = {Michael, Nathan and Shen, Shaojie and Motha, Kartik and Mulgaonkar, Yash and Kumar, Vijay and Nagatani, Keiji and Okada, Yoshito and Kiribayashi, Seiga and Otake, Kazuki and Yoshida, Kazuya and Ohno, Kazunori and Takeuchi, Eijiro and Tadokoro, Satoshi},
doi = {10.1002/rob},
journal = {{\ldots} of Field Robotics},
number = {5},
pages = {832--841},
title = {{Collaborative mapping of an earthquake‐damaged building via ground and aerial robots}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/rob.21436/full},
volume = {29},
year = {2012}
}
@article{Mascarich2018,
author = {Mascarich, Frank and Wilson, Taylor and Khattak, Shehryar and Dang, Tung and Papachristos, Christos and Alexis, Kostas},
file = {:home/maxime/T{\'{e}}l{\'{e}}chargements/finalpaper{\_}wm2018.pdf:pdf},
pages = {1--12},
title = {{WM2018 Conference, March 18 – 22, 2018, Phoenix, Arizona, USA Autonomous 3D and Radiation Mapping in Tunnel Environments Using Aerial Robots – 18156 Frank Mascarich, Taylor Wilson, Shehryar Khattak, Tung Dang, Christos Papachristos, Kostas Alexis Universi}},
year = {2018}
}



